{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "erfK8t1iuudL"
   },
   "source": [
    "## Task 1\n",
    "\n",
    "### 1.1 Write a function that returns Count number of lines in txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "id": "gfMPfvKluuD4"
   },
   "outputs": [],
   "source": [
    "def NumOfLines(filename):\n",
    "    \n",
    "    #Write your logic here\n",
    "    \n",
    "    count = 0 #Variable to track number of lines\n",
    "    file = open(filename, \"r\") #opening file in reading mode\n",
    "    for line in file: #traversing file line by line\n",
    "        if line != \"\": # I have used line !=\"\" instead of line != \"\\n\" to count empty lines also. \n",
    "            count += 1 #incresing count by 1 for each line\n",
    "    file.close() # closing file after counting lines \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "id": "vZK_nMSwz5I_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Lines are 4735\n"
     ]
    }
   ],
   "source": [
    "count = NumOfLines('Text_File.txt')\n",
    "print(\"Number of Lines are\", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CbKMN0PsvTc4"
   },
   "source": [
    "### 1.2 Write a function that returns Count number of words in txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "id": "-iWt8XAvuss3"
   },
   "outputs": [],
   "source": [
    "def NumOfWords(filename):\n",
    "  #Write your logic here\n",
    "    words = 0 #Variable to track number of words\n",
    "    file = open(filename, \"r\") #opening file in reading mode\n",
    "    for line in file:  #traversing file line by line\n",
    "        words += len(line.split()) # spliting line into word and then increamenting word count by number of words in line\n",
    "    file.close()\n",
    "    return words\n",
    "\n",
    "############# Explanantion ################## \n",
    "\n",
    "#split() method works fine when we dont have special characters in our file. If the file under consideration\n",
    "#happens to contain special characters we have to use some other method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "id": "EkHkdf1Svovt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words are  30368\n"
     ]
    }
   ],
   "source": [
    "num = NumOfWords('Text_File.txt')\n",
    "print(\"Number of words are \", num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j33bUTELvtQW"
   },
   "source": [
    "## Task 2\n",
    "Write a function that reurns a dataframe with two columns having stop words in one col and their count in the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "xEr9ZDyIvsQ-"
   },
   "outputs": [],
   "source": [
    "# importing pandas to make dataframe\n",
    "import pandas as pd \n",
    "\n",
    "# specifying list of stop words\n",
    "stop_words = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\",\n",
    "              'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers',\n",
    "              'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which',\n",
    "              'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been',\n",
    "              'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if',\n",
    "              'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between',\n",
    "              'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out',\n",
    "              'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why',\n",
    "              'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not',\n",
    "              'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should',\n",
    "              \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\",\n",
    "              'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma',\n",
    "              'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn',\n",
    "              \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "\n",
    "# initializing a dictionary to store count of each stop word\n",
    "dict_stop_words = dict.fromkeys(stop_words , 0)\n",
    "\n",
    "\n",
    "def CreateDF(fileName): \n",
    "    #Write your logic her  \n",
    "    \n",
    "    file = open(fileName, \"r\") # open file in reading mode\n",
    "    \n",
    "    for line in file:\n",
    "        for word in line.split():\n",
    "            if word in dict_stop_words: #if word is stop_word increament the value in dictionary for that word by 1\n",
    "                dict_stop_words[word] +=1\n",
    "    file.close()\n",
    "    \n",
    "    # convert dictionary to dataframe before returning\n",
    "    return pd.DataFrame(data = dict_stop_words.items(),columns = ['Stop Words', 'Count'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "Q1E80nKiwAos"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stop Words</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>me</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>myself</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>we</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>weren't</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>won</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>won't</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>wouldn</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>wouldn't</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Stop Words  Count\n",
       "0            i     33\n",
       "1           me      5\n",
       "2           my      3\n",
       "3       myself      0\n",
       "4           we    171\n",
       "..         ...    ...\n",
       "174    weren't      0\n",
       "175        won      0\n",
       "176      won't      0\n",
       "177     wouldn      0\n",
       "178   wouldn't      0\n",
       "\n",
       "[179 rows x 2 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = CreateDF('Text_File.txt')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRp5uBLKwD1I"
   },
   "source": [
    "## Task 3\n",
    "Now generate a txt file named RollnumberWS.txt having all content of the given file but excluding stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "id": "RZul2aEMwI5k"
   },
   "outputs": [],
   "source": [
    "def WithoutSW(filename, filetowritein):\n",
    "    \n",
    "    #Write your logic here\n",
    "    \n",
    "    \n",
    "    file = open(filename, \"r\") # open a file in reading mode\n",
    "    file1= open(filetowritein,\"w\") # open a file in writing mode\n",
    "\n",
    "    \n",
    "    \n",
    "    for line in file:\n",
    "        list_of_words = []\n",
    "        result = ''\n",
    "\n",
    "        for i,word in enumerate(line.split()):\n",
    "            \n",
    "            # if word is a stop_word dont add it in the list\n",
    "            if word in dict_stop_words:\n",
    "                pass \n",
    "            else:\n",
    "                list_of_words.append(word)\n",
    "        \n",
    "        # if line is empty write \"\\n\" in the output file to preserve total number of lines\n",
    "        if len(list_of_words) == 0:\n",
    "            result = \"\\n\"\n",
    "        # otherwise write line in output file without stop words\n",
    "        else:      \n",
    "            for j, word in enumerate(list_of_words):\n",
    "                if j == (len(list_of_words) - 1):\n",
    "                    result += word + \"\\n\" # add \"\\n\" at the end of line\n",
    "                else:\n",
    "                    result += word + \" \" #add \" \"(space) after each word\n",
    "\n",
    "        file1.write(result) \n",
    "\n",
    "    # close both files            \n",
    "    file.close()\n",
    "    file1.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "aAlyQTV2wXJj"
   },
   "outputs": [],
   "source": [
    "WithoutSW(\"Text_File.txt\", \"MSDS21001WS.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQu1uJqDwW00"
   },
   "source": [
    "## Task 4\n",
    "Write a function that displays all words having length greater than 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "QS8LuhQvwnbL"
   },
   "outputs": [],
   "source": [
    "def GreaterThan5(fileName):\n",
    "    \n",
    "    #Write your logic here\n",
    "    \n",
    "    file = open(fileName,\"r\")\n",
    "    words = []\n",
    "    for line in file:\n",
    "        for word in line.split():\n",
    "            # if length of word is greater than 5 add it in the list\n",
    "            if len(word)>5:\n",
    "                if word in words: # if word is already in list do nothing\n",
    "                    pass\n",
    "                else:\n",
    "                    words.append(word)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "id": "3K4JoLYrws-M"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BusTUC',\n",
       " 'natura',\n",
       " 'anguage',\n",
       " 'computer',\n",
       " 'information',\n",
       " 'science',\n",
       " 'University',\n",
       " 'Trondheim',\n",
       " 'Norway,',\n",
       " 'N-7491',\n",
       " 'amble@idi,',\n",
       " 'Abstract',\n",
       " 'describes',\n",
       " 'natural',\n",
       " 'expert',\n",
       " 'system',\n",
       " 'advisor',\n",
       " 'public',\n",
       " 'transport',\n",
       " 'Trondheim,',\n",
       " 'Norway.',\n",
       " 'available',\n",
       " 'Internet,and',\n",
       " 'intstalled',\n",
       " \"pany's\",\n",
       " 'server',\n",
       " 'beginning',\n",
       " 'bilingual,',\n",
       " 'relying',\n",
       " 'internal',\n",
       " 'independent',\n",
       " 'representation.',\n",
       " 'Introduct',\n",
       " 'interface',\n",
       " 'database',\n",
       " 'provides',\n",
       " 'capability',\n",
       " 'obtaining',\n",
       " 'formation',\n",
       " 'stored',\n",
       " 'querying',\n",
       " 'language',\n",
       " 'communication',\n",
       " 'system,',\n",
       " 'question',\n",
       " 'statement',\n",
       " 'normally',\n",
       " 'discussed,',\n",
       " 'freeing',\n",
       " 'stores',\n",
       " 'processes',\n",
       " 'information.',\n",
       " 'present',\n",
       " 'implementation',\n",
       " 'represents',\n",
       " 'effort',\n",
       " 'bringing',\n",
       " 'practical',\n",
       " 'developed',\n",
       " 'answer',\n",
       " 'queries',\n",
       " 'routes,',\n",
       " 'stated',\n",
       " 'texts,',\n",
       " 'through',\n",
       " 'Internet',\n",
       " '//www.',\n",
       " 'no/bustuc/).',\n",
       " 'university',\n",
       " '140000',\n",
       " 'inhabitants.',\n",
       " 'central',\n",
       " 'systems',\n",
       " 'lines,',\n",
       " 'serving',\n",
       " 'stations,',\n",
       " 'depar-',\n",
       " 'average).',\n",
       " 'approximately',\n",
       " 'scheduled',\n",
       " 'station',\n",
       " 'passings',\n",
       " 'somehow',\n",
       " 'represented',\n",
       " 'starting',\n",
       " 'automate',\n",
       " 'function',\n",
       " 'agent.',\n",
       " 'following',\n",
       " 'example',\n",
       " 'response',\n",
       " 'actual',\n",
       " 'request',\n",
       " 'telephone',\n",
       " 'company:',\n",
       " 'Nidarvoll',\n",
       " 'tonight',\n",
       " 'oclock.',\n",
       " 'typical',\n",
       " 'follow',\n",
       " 'quickly:',\n",
       " 'number',\n",
       " 'passes',\n",
       " 'arrives',\n",
       " 'Railway',\n",
       " 'Station',\n",
       " 'between',\n",
       " 'lexical',\n",
       " 'analysis,',\n",
       " 'syntax',\n",
       " 'semantic',\n",
       " 'pragmatic',\n",
       " 'reasoning',\n",
       " 'processing.',\n",
       " 'content',\n",
       " 'solved',\n",
       " 'interrogation,',\n",
       " 'whereby',\n",
       " 'customer',\n",
       " 'produce',\n",
       " 'items:',\n",
       " 'departure,',\n",
       " 'arrival,',\n",
       " 'earliest',\n",
       " 'departure',\n",
       " 'timeand/or',\n",
       " 'latest',\n",
       " 'arrival',\n",
       " 'better',\n",
       " 'because',\n",
       " '\"natural',\n",
       " 'language\".',\n",
       " 'challenge',\n",
       " 'demonstration',\n",
       " 'preferred',\n",
       " 'interrogative',\n",
       " 'correct,',\n",
       " 'friendly',\n",
       " 'almost',\n",
       " 'complete',\n",
       " 'within',\n",
       " 'domain.',\n",
       " 'Previous',\n",
       " 'Efforts,',\n",
       " 'CHAT-80,',\n",
       " 'PRAT-89',\n",
       " 'called',\n",
       " 'CHAT-80',\n",
       " '(Warren',\n",
       " 'Pereira,',\n",
       " '1982).',\n",
       " 'impressive',\n",
       " 'merits,',\n",
       " 'established',\n",
       " 'Prolog',\n",
       " 'viable',\n",
       " 'competitive',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " 'general.',\n",
       " 'brilliant',\n",
       " 'masterpiece',\n",
       " 'software,',\n",
       " 'efficient',\n",
       " 'sophisticated.',\n",
       " 'connected',\n",
       " 'international',\n",
       " 'geography.',\n",
       " 'analysed',\n",
       " 'answered',\n",
       " 'second:',\n",
       " 'country',\n",
       " 'bordering',\n",
       " 'Mediterranean',\n",
       " 'borders',\n",
       " 'bordered',\n",
       " 'population',\n",
       " 'exceeds',\n",
       " 'India?',\n",
       " \"'Turkey'\",\n",
       " 'become',\n",
       " 'incorrect',\n",
       " 'passed.',\n",
       " 'Geography',\n",
       " 'chosen',\n",
       " 'domain',\n",
       " 'without',\n",
       " 'time.)',\n",
       " 'abi!ity',\n",
       " 'ridiculously',\n",
       " 'course',\n",
       " 'lesson',\n",
       " 'complex',\n",
       " 'sentences',\n",
       " 'proper',\n",
       " 'under-',\n",
       " 'standing',\n",
       " 'sacrificing',\n",
       " 'efficiency.',\n",
       " 'superfi-',\n",
       " 'pattern',\n",
       " 'matching',\n",
       " 'technique',\n",
       " 'futile',\n",
       " 'sooner',\n",
       " 'later.',\n",
       " 'Making',\n",
       " 'Norwegian',\n",
       " '(NTNU),',\n",
       " 'version',\n",
       " 'CHAT-80,called',\n",
       " '(Teigen',\n",
       " 'Vetland,',\n",
       " '1988),(Teigen',\n",
       " '1989).',\n",
       " '(Also,',\n",
       " 'similar',\n",
       " 'Swedish',\n",
       " 'project',\n",
       " 'SNACK-85',\n",
       " 'reported).',\n",
       " 'dictionary',\n",
       " 'changed',\n",
       " 'English',\n",
       " 'wegian',\n",
       " 'together',\n",
       " 'morphological',\n",
       " 'analysis.',\n",
       " 'change',\n",
       " 'grammar',\n",
       " 'proved',\n",
       " 'amazingly',\n",
       " 'showed',\n",
       " 'langauges',\n",
       " 'believe,',\n",
       " 'languages',\n",
       " 'incomprehen-',\n",
       " \"other's\",\n",
       " 'communities.',\n",
       " 'changing',\n",
       " 'graramar,',\n",
       " 'correctly',\n",
       " 'seconds.',\n",
       " 'Hvilke',\n",
       " 'afrikanske',\n",
       " 'befolkning',\n",
       " 'stoerre',\n",
       " 'millioner',\n",
       " 'mindre',\n",
       " 'Botswana',\n",
       " 'hovedstad',\n",
       " 'tusen.',\n",
       " 'translation',\n",
       " 'beside',\n",
       " 'Norwegian.)',\n",
       " 'System',\n",
       " 'Nordic',\n",
       " 'accomplished',\n",
       " '1988-89',\n",
       " 'interfaces',\n",
       " 'databases.',\n",
       " 'Bureau',\n",
       " '(Statskontoret),',\n",
       " 'participants',\n",
       " 'Denmark,',\n",
       " 'Finland',\n",
       " 'Norway',\n",
       " '(Amble',\n",
       " '1990).',\n",
       " 'databases',\n",
       " 'Scandi-',\n",
       " 'navian',\n",
       " 'Swedish,',\n",
       " 'Danish',\n",
       " 'Norwegian.',\n",
       " 'similar,',\n",
       " 'Norwe-',\n",
       " 'easily',\n",
       " 'extended',\n",
       " 'Scandinavian',\n",
       " 'languages.',\n",
       " 'Instead',\n",
       " 'Geogra-',\n",
       " 'application',\n",
       " 'hospital',\n",
       " 'administration.',\n",
       " 'decided',\n",
       " 'target',\n",
       " 'ministration',\n",
       " 'already.',\n",
       " 'discourse',\n",
       " 'adminis-',\n",
       " 'tration,',\n",
       " 'knowledge',\n",
       " 'representation',\n",
       " 'techniques',\n",
       " 'CHAT-80.',\n",
       " 'implemented',\n",
       " 'framework.',\n",
       " 'modelling',\n",
       " 'adequate',\n",
       " 'Entity',\n",
       " 'Relationship',\n",
       " '(type)',\n",
       " 'hierarchy,',\n",
       " 'attributes',\n",
       " 'longing',\n",
       " 'class,',\n",
       " 'single',\n",
       " 'inheritance',\n",
       " 'ofattributes',\n",
       " 'relationships.',\n",
       " 'Coupling',\n",
       " 'database.',\n",
       " 'remodelling,',\n",
       " '\"Scandinavian\"',\n",
       " 'questions.',\n",
       " 'produced',\n",
       " 'Prolog-like',\n",
       " '(First',\n",
       " 'Logic)',\n",
       " 'execution.',\n",
       " 'mapping',\n",
       " 'Schema',\n",
       " 'defined,',\n",
       " 'translator',\n",
       " 'implemented.',\n",
       " 'ligger',\n",
       " 'kvinnes',\n",
       " '(Which',\n",
       " \"woman's\",\n",
       " 'translated',\n",
       " 'query:',\n",
       " 'SELECT',\n",
       " 'DISTINCT',\n",
       " 'T3.name,Tl.sex,T2.reg_no,T3.sex,',\n",
       " 'T4.reg_no,T4.bed_no,T5.hosp_no,T5.ward_no',\n",
       " 'PATIENT',\n",
       " 'TI,OCCUPANCY',\n",
       " 'T2,PATIENT',\n",
       " 'OCCUPANCY',\n",
       " 'T4,WARD',\n",
       " \"(Tl.sex='f')\",\n",
       " '(T2.reg_no=Tl.reg_no)',\n",
       " \"(T3.sex='m')\",\n",
       " '(T4.reg_no=T3.reg_no)',\n",
       " '(T4.bed_no=T2.bed_no)',\n",
       " '(T5.hosp_no=T4.hosp_no)',\n",
       " '(T5.ward_no=T4.ward_no)',\n",
       " 'Understanding',\n",
       " 'Computer',\n",
       " 'valuable',\n",
       " 'xperience',\n",
       " 'transportable',\n",
       " 'interfaces.',\n",
       " 'However,',\n",
       " 'underlying',\n",
       " 'restricted',\n",
       " 'further',\n",
       " 'development.',\n",
       " 'Project',\n",
       " 'finished,',\n",
       " 'inter-',\n",
       " 'reseach',\n",
       " 'puter)',\n",
       " 'initiated',\n",
       " 'results',\n",
       " 'differed',\n",
       " 'cerned',\n",
       " 'multimedia',\n",
       " 'portability',\n",
       " 'versatility',\n",
       " 'issues',\n",
       " 'concerning',\n",
       " 'generality',\n",
       " 'applications.',\n",
       " 'research',\n",
       " 'marised',\n",
       " 'computers',\n",
       " 'operational',\n",
       " 'understanding',\n",
       " 'language.',\n",
       " 'intelligent',\n",
       " 'capabilities.',\n",
       " 'common',\n",
       " 'guage.',\n",
       " 'criterion',\n",
       " 'capacity',\n",
       " 'definitions',\n",
       " 'Naturally',\n",
       " 'Logic,',\n",
       " \"system's\",\n",
       " 'should',\n",
       " 'conform',\n",
       " 'answers',\n",
       " 'idealised',\n",
       " 'rational',\n",
       " 'lives.',\n",
       " 'defined',\n",
       " 'closed',\n",
       " 'context.',\n",
       " 'terfaces',\n",
       " 'principle',\n",
       " 'simulating',\n",
       " 'environment',\n",
       " 'dialogue',\n",
       " 'partner.',\n",
       " 'prototypical',\n",
       " 'proces-',\n",
       " 'written',\n",
       " 'Prolog.',\n",
       " 'designed',\n",
       " 'general',\n",
       " 'purpose',\n",
       " 'adaptable',\n",
       " 'processor.',\n",
       " 'consists',\n",
       " 'subset',\n",
       " 'English,',\n",
       " 'modules',\n",
       " 'SQL-databases',\n",
       " 'textual',\n",
       " 'informa-',\n",
       " 'sources.',\n",
       " 'happened',\n",
       " 'Universtity',\n",
       " 'start-',\n",
       " 'Speech',\n",
       " 'building',\n",
       " 'automatic',\n",
       " 'oracle,',\n",
       " 'telephone.',\n",
       " 'project,',\n",
       " 'fresh,',\n",
       " 'widespread',\n",
       " 'today,',\n",
       " 'regarded',\n",
       " 'source',\n",
       " 'public.',\n",
       " 'became',\n",
       " 'dominant',\n",
       " 'medium,',\n",
       " 'likeley',\n",
       " 'connection,',\n",
       " 'busroute',\n",
       " 'table.',\n",
       " 'consequtive',\n",
       " 'spreading',\n",
       " 'cellular',\n",
       " 'phones',\n",
       " 'picture',\n",
       " 'favour',\n",
       " 'telephone,',\n",
       " 'another',\n",
       " 'story).',\n",
       " 'built,',\n",
       " 'regardless',\n",
       " 'status',\n",
       " 'speech',\n",
       " 'rocgnition',\n",
       " 'synthesis',\n",
       " 'effort,',\n",
       " 'behind',\n",
       " 'while.',\n",
       " 'resulting',\n",
       " 'prototype',\n",
       " 'months',\n",
       " '(Bratseth,',\n",
       " '1997).',\n",
       " 'summer',\n",
       " 'Internet,',\n",
       " 'tested',\n",
       " 'continually',\n",
       " 'today.',\n",
       " 'portant',\n",
       " 'extension',\n",
       " 'bilingual',\n",
       " '(Norwegian',\n",
       " 'English)',\n",
       " 'during',\n",
       " 'spring',\n",
       " 'finally',\n",
       " 'adopted',\n",
       " 'company',\n",
       " 'Trafikkselskap),',\n",
       " 'Linux).',\n",
       " '150.000',\n",
       " 'questions',\n",
       " 'swered,',\n",
       " 'stabilize',\n",
       " 'increasingly',\n",
       " 'popular.',\n",
       " 'Anatomy',\n",
       " 'components',\n",
       " 'parser',\n",
       " 'consisting',\n",
       " 'dictionary,',\n",
       " 'processor,',\n",
       " 'parser.',\n",
       " 'divided',\n",
       " 'contalng',\n",
       " 'routing',\n",
       " 'contains',\n",
       " 'double',\n",
       " 'morphology',\n",
       " 'grammar.',\n",
       " 'Actually,',\n",
       " 'detects',\n",
       " 'probable',\n",
       " 'count-',\n",
       " 'unknown',\n",
       " 'related',\n",
       " 'language,',\n",
       " 'accordingly.',\n",
       " 'grammars',\n",
       " 'surprisingly',\n",
       " 'slightly',\n",
       " 'grammar,',\n",
       " 'mostly',\n",
       " 'elaborated',\n",
       " 'allows',\n",
       " 'order.',\n",
       " 'Features',\n",
       " 'systems,',\n",
       " 'figures',\n",
       " 'dication',\n",
       " 'domain:',\n",
       " 'nouns,',\n",
       " 'verbs,',\n",
       " 'adjectives,',\n",
       " 'prepositions,',\n",
       " 'although',\n",
       " 'level.',\n",
       " 'described',\n",
       " 'entries.',\n",
       " 'addition',\n",
       " 'official',\n",
       " 'names,',\n",
       " 'required',\n",
       " 'capture',\n",
       " 'variety',\n",
       " 'naming.',\n",
       " 'simple',\n",
       " 'correction',\n",
       " 'essentially',\n",
       " 'character',\n",
       " 'errors).',\n",
       " 'needed',\n",
       " 'translate',\n",
       " 'output',\n",
       " 'production',\n",
       " 'Pragma,',\n",
       " 'advanced',\n",
       " 'rewrit-',\n",
       " 'rules.',\n",
       " 'addition,',\n",
       " 'actually',\n",
       " 'generating',\n",
       " 'rules).',\n",
       " 'mainly',\n",
       " '(Sicstus',\n",
       " 'programs',\n",
       " 'munication',\n",
       " 'CGI-scripts.',\n",
       " 'moment,',\n",
       " 'programmed',\n",
       " 'tables',\n",
       " 'Prolog).',\n",
       " 'Average',\n",
       " 'usually',\n",
       " 'demand',\n",
       " 'single,',\n",
       " 'relevant',\n",
       " 'percent.',\n",
       " 'Parser',\n",
       " 'Grammar',\n",
       " 'statements,',\n",
       " 'commands',\n",
       " 'movements.',\n",
       " 'formalism',\n",
       " 'Consensical',\n",
       " 'Grammar,',\n",
       " '(CONtext',\n",
       " 'SENSitive',\n",
       " 'CompositionAL',\n",
       " 'Grammar)',\n",
       " 'variant',\n",
       " 'Extraposition',\n",
       " '(Pereira',\n",
       " 'Warren,',\n",
       " '1980),',\n",
       " 'generalisa-',\n",
       " 'Definite',\n",
       " 'Clause',\n",
       " 'Grammars.',\n",
       " 'Compositional',\n",
       " 'semantics',\n",
       " 'phrase',\n",
       " 'composed',\n",
       " 'subphrases;',\n",
       " 'constituents',\n",
       " 'complements.',\n",
       " 'grammars,',\n",
       " 'trans-',\n",
       " 'Grammars,',\n",
       " 'executed',\n",
       " 'characteristic',\n",
       " 'syntactic',\n",
       " 'expression',\n",
       " 'Consen-',\n",
       " 'define',\n",
       " 'incomplete',\n",
       " 'construct',\n",
       " '\"difference',\n",
       " 'structs.',\n",
       " 'possible,',\n",
       " 'tracted',\n",
       " 'reading',\n",
       " 'input,',\n",
       " 'necessary.',\n",
       " 'effect',\n",
       " 'traposition',\n",
       " 'format',\n",
       " 'intuitive.',\n",
       " 'Examples',\n",
       " 'person',\n",
       " 'barked?',\n",
       " 'statement.',\n",
       " 'Movement',\n",
       " 'handled',\n",
       " 'making',\n",
       " 'special',\n",
       " 'movement.',\n",
       " 'manages',\n",
       " 'analyses',\n",
       " 'ments:',\n",
       " 'thought',\n",
       " 'believed',\n",
       " 'Barked.',\n",
       " 'statement(P)',\n",
       " 'noun_phrase(X,VP,P),',\n",
       " 'verb_phrase(X,VP).',\n",
       " 'statement(Q)',\n",
       " 'verb_complementsO(VC),',\n",
       " 'initial',\n",
       " 'optional',\n",
       " 'complements',\n",
       " 'verb_complementsO(VC).',\n",
       " 'inserted',\n",
       " 'whoseq(P)',\n",
       " '\\\\[whose\\\\],',\n",
       " 'hOlm(N),',\n",
       " 'whoq(P)',\n",
       " '(\\\\[who\\\\],\\\\[has\\\\],\\\\[a\\\\],noun(N),\\\\[that\\\\]).',\n",
       " '\\\\[who\\\\],',\n",
       " 'whichq(P)',\n",
       " '(\\\\[which\\\\],\\\\[person\\\\]).',\n",
       " 'whichq(which(X)::P)',\n",
       " '\\\\[which\\\\],',\n",
       " 'the(X).',\n",
       " 'Example:',\n",
       " 'sentence',\n",
       " 'experiences',\n",
       " 'however.',\n",
       " 'problem',\n",
       " 'parsing',\n",
       " 'method',\n",
       " 'itself,',\n",
       " 'backtracking.',\n",
       " 'principles',\n",
       " 'elegant',\n",
       " 'domains',\n",
       " 'turned',\n",
       " 'costly',\n",
       " 'larger',\n",
       " 'mains,',\n",
       " 'expres-',\n",
       " 'sions,',\n",
       " 'incredible',\n",
       " 'ambiguities',\n",
       " 'covered',\n",
       " 'disambiguation',\n",
       " 'languages,',\n",
       " 'guidelines:',\n",
       " 'checking',\n",
       " 'integrated',\n",
       " 'parser,',\n",
       " 'discard',\n",
       " 'sematica/ly',\n",
       " 'parses',\n",
       " 'start.',\n",
       " 'heuristics',\n",
       " 'followed',\n",
       " 'reproachable:',\n",
       " 'longest',\n",
       " 'possible',\n",
       " 'category',\n",
       " 'semantically',\n",
       " 'correct',\n",
       " 'interpretation.',\n",
       " 'perplexity',\n",
       " 'committed',\n",
       " 'choices',\n",
       " '(cuts)',\n",
       " 'strategic',\n",
       " 'places.',\n",
       " 'however,',\n",
       " 'implied',\n",
       " 'recovered',\n",
       " 'problems',\n",
       " 'imperative',\n",
       " 'intro-',\n",
       " 'timeout',\n",
       " 'process',\n",
       " 'embarass-',\n",
       " 'Although',\n",
       " 'sentences,',\n",
       " 'parsed',\n",
       " 'second,',\n",
       " 'ofmod-',\n",
       " 'Adaptability',\n",
       " 'reprogrammed',\n",
       " 'foreach',\n",
       " 'application.',\n",
       " 'design',\n",
       " 'changes',\n",
       " 'tabular',\n",
       " 'dictio-',\n",
       " 'general,',\n",
       " 'generated',\n",
       " 'automatically',\n",
       " 'constitute',\n",
       " 'hierarchy.',\n",
       " 'a-kind-of',\n",
       " 'hierarchy',\n",
       " 'tree-structured',\n",
       " 'inheritance.',\n",
       " 'ontology',\n",
       " 'world.',\n",
       " 'compliances',\n",
       " 'adjectives',\n",
       " 'prepositions',\n",
       " 'neces-',\n",
       " 'processing',\n",
       " 'essential',\n",
       " 'analysis',\n",
       " 'aswell.',\n",
       " 'combinations',\n",
       " 'carefully',\n",
       " 'assem-',\n",
       " 'network,',\n",
       " 'serves',\n",
       " 'purpose.',\n",
       " 'necessary',\n",
       " 'instance',\n",
       " 'telescope.',\n",
       " 'treated',\n",
       " 'differently',\n",
       " 'telescope',\n",
       " 'modify',\n",
       " 'modifies',\n",
       " 'stricted',\n",
       " 'person.',\n",
       " 'Processor',\n",
       " 'Calculus',\n",
       " 'phrases',\n",
       " 'complements,',\n",
       " 'Natural',\n",
       " '(Temporal',\n",
       " 'Language/',\n",
       " 'Language)',\n",
       " 'calculus',\n",
       " 'expression,',\n",
       " 'contained',\n",
       " 'taining',\n",
       " 'literal',\n",
       " 'meaning',\n",
       " 'utterance.',\n",
       " 'inspired',\n",
       " 'Kowalski',\n",
       " 'Sergot',\n",
       " '(Kowal-',\n",
       " 'Sergot,',\n",
       " '1986).',\n",
       " 'expressions',\n",
       " 'consist',\n",
       " 'predicates,',\n",
       " 'tions,',\n",
       " 'constants',\n",
       " 'variables.',\n",
       " 'generic',\n",
       " 'predi-',\n",
       " 'selected',\n",
       " 'follow-',\n",
       " 'whether',\n",
       " 'Saturday',\n",
       " 'below.',\n",
       " 'Typically,',\n",
       " 'equivalent',\n",
       " 'bussen',\n",
       " 'soendag',\n",
       " 'exactly',\n",
       " 'test::',\n",
       " 'isa(real,program,tuc),',\n",
       " 'isa(real,bus,A),',\n",
       " 'isa(real,saturday,B),',\n",
       " 'isa(real,place,nidar),',\n",
       " 'event(real,D),',\n",
       " 'program',\n",
       " 'saturday',\n",
       " 'know(whether,tuc,C,D),',\n",
       " 'action(go,E),',\n",
       " 'action',\n",
       " 'actor(A,E),',\n",
       " 'srel(to,place,nidar,E),Y.',\n",
       " 'srel(on,time,B,E),',\n",
       " 'parameter',\n",
       " 'important',\n",
       " 'semantics.',\n",
       " 'various',\n",
       " 'purposes.',\n",
       " 'salient',\n",
       " 'identify',\n",
       " 'occured.',\n",
       " 'coordinates',\n",
       " 'actions',\n",
       " 'parameter.',\n",
       " 'Pragmatic',\n",
       " '(BusLOG)',\n",
       " 'rewriting',\n",
       " 'approach',\n",
       " 'creation',\n",
       " 'minimum',\n",
       " 'explicit',\n",
       " 'programming.',\n",
       " 'worth,',\n",
       " 'interesting',\n",
       " 'reason.',\n",
       " 'increasing',\n",
       " 'interest',\n",
       " 'compa-',\n",
       " 'companies',\n",
       " 'customers.',\n",
       " 'Further',\n",
       " 'remains',\n",
       " 'really',\n",
       " 'efficient,',\n",
       " 'coverage',\n",
       " 'reasonable',\n",
       " 'imits.',\n",
       " 'offering',\n",
       " 'amount',\n",
       " 'portable',\n",
       " 'lsewhere,',\n",
       " 'connecting',\n",
       " 'travelling',\n",
       " 'agencies.',\n",
       " 'remain',\n",
       " 'curiosity.',\n",
       " 'anyway,',\n",
       " 'contribution',\n",
       " 'devel-',\n",
       " 'opment',\n",
       " 'systems.',\n",
       " 'ferences',\n",
       " 'Amble,',\n",
       " 'Knudsen,',\n",
       " 'Lehtola,',\n",
       " 'Ljungberg,',\n",
       " 'Ravnholt.',\n",
       " 'Naturlig',\n",
       " 'Grafik',\n",
       " 'databaser.',\n",
       " 'Statskontoret.',\n",
       " 'Rapport',\n",
       " 'kunskaps-',\n",
       " 'baseret',\n",
       " 'hj~lpsystem',\n",
       " 'Bratseth.',\n",
       " 'Traffic',\n",
       " 'Informations',\n",
       " 'System.',\n",
       " \"Master's\",\n",
       " 'thesis,',\n",
       " 'Science',\n",
       " 'Technology.',\n",
       " 'Sergot.',\n",
       " 'events.',\n",
       " 'Generation',\n",
       " 'Computing,',\n",
       " '8(0):67-95.',\n",
       " 'F.C.N.',\n",
       " 'Pereira',\n",
       " 'D.H.D.',\n",
       " 'Warren.',\n",
       " 'clause',\n",
       " 'Intelligence,',\n",
       " 'Teigen',\n",
       " 'Vetland.',\n",
       " 'Syntax',\n",
       " 'norwegian',\n",
       " 'Technical',\n",
       " 'report,',\n",
       " 'Institute',\n",
       " 'Handling',\n",
       " 'reason-',\n",
       " 'beyond',\n",
       " 'linguistic',\n",
       " 'conceptual',\n",
       " 'Warren',\n",
       " 'Pereira.',\n",
       " 'interpreting',\n",
       " 'queries.',\n",
       " 'Computational',\n",
       " 'Linguis-',\n",
       " '8(3-4).',\n",
       " 'Machine',\n",
       " 'Translation',\n",
       " 'Languages',\n",
       " 'HAJI(~',\n",
       " 'Hopkins',\n",
       " 'Charles',\n",
       " 'Baltimore,',\n",
       " '21218,',\n",
       " 'hajic@cs.jhu.edu',\n",
       " 'Malostransk6',\n",
       " 'nfim.25',\n",
       " 'Republic,',\n",
       " 'hric@barbora.m',\n",
       " 'ff.cuni.cz',\n",
       " 'Vladislav',\n",
       " 'mim.25',\n",
       " 'vk@ufal.mff.cuni.cz',\n",
       " 'examples',\n",
       " 'transfer-based',\n",
       " 'Russian',\n",
       " 'RUSLAN',\n",
       " 'word-for-word',\n",
       " 'Slovak',\n",
       " '(~ESILKO',\n",
       " 'obtain',\n",
       " 'quality',\n",
       " 'simpler',\n",
       " 'methods.',\n",
       " 'typologically',\n",
       " 'discussed',\n",
       " 'Introduction',\n",
       " 'machine',\n",
       " 'history,',\n",
       " 'successful',\n",
       " 'impressive.',\n",
       " 'invested',\n",
       " 'development',\n",
       " 'wasted',\n",
       " 'stimulated',\n",
       " 'technical',\n",
       " 'certain',\n",
       " 'limited',\n",
       " 'course,',\n",
       " 'exceptions,',\n",
       " 'demonstrated',\n",
       " 'conditions',\n",
       " 'develop',\n",
       " 'efforts',\n",
       " 'translation.',\n",
       " 'reason',\n",
       " 'expectations',\n",
       " 'sci-fi',\n",
       " 'literature,',\n",
       " 'scientific',\n",
       " 'community,',\n",
       " 'complexity',\n",
       " 'itself.',\n",
       " 'requires',\n",
       " 'several',\n",
       " 'computational',\n",
       " 'inguistics',\n",
       " '(morphology,',\n",
       " 'syntax,',\n",
       " 'semantics,',\n",
       " 'necessary,',\n",
       " 'sufficient',\n",
       " 'condition.',\n",
       " 'opinion',\n",
       " 'easier',\n",
       " 'create',\n",
       " 'demonstrate',\n",
       " 'assumption',\n",
       " 'closely',\n",
       " 'Czech-to-Russian',\n",
       " 'History',\n",
       " 'attempt',\n",
       " 'verify',\n",
       " 'hypothesis',\n",
       " 'started',\n",
       " 'Prague.',\n",
       " 'documentation',\n",
       " 'operating',\n",
       " 'mainframe',\n",
       " 'computers.',\n",
       " ...]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " GreaterThan5(\"Text_File.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5Lc-EQuwxRj"
   },
   "source": [
    "## Task 5\n",
    "Write a function that returns the count of all words which end at y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "id": "dJzEZ9AFxKul"
   },
   "outputs": [],
   "source": [
    "def EndAty(filename):\n",
    "    \n",
    "    #Write your logic here\n",
    "\n",
    "    file = open(filename,\"r\")\n",
    "    words = {}\n",
    "    for line in file:\n",
    "        for word in line.split():\n",
    "            # if word end in 'y' add it in the dict\n",
    "            if word[-1] == 'y': \n",
    "                if word in words:\n",
    "                    words[word] += 1 # if word is already in dict increase its value by 1\n",
    "                else:\n",
    "                    words[word] = 1 #if word is not in the list add it in the dictionary and make its value 1\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "id": "Hkrp_W4sxPDc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'University': 7,\n",
       " 'capability': 2,\n",
       " 'by': 163,\n",
       " 'way': 15,\n",
       " 'they': 28,\n",
       " 'normally': 5,\n",
       " 'city': 2,\n",
       " 'university': 1,\n",
       " 'day': 1,\n",
       " 'approximately': 7,\n",
       " 'Railway': 1,\n",
       " 'query': 20,\n",
       " 'whereby': 2,\n",
       " 'friendly': 1,\n",
       " 'country': 3,\n",
       " 'irony': 1,\n",
       " 'Geography': 2,\n",
       " 'abi!ity': 1,\n",
       " 'ridiculously': 1,\n",
       " 'Any': 1,\n",
       " 'dictionary': 46,\n",
       " 'amazingly': 1,\n",
       " 'correctly': 3,\n",
       " 'Norway': 1,\n",
       " 'very': 20,\n",
       " 'easily': 12,\n",
       " 'Entity': 1,\n",
       " 'raphy': 1,\n",
       " 'ryly': 1,\n",
       " 'carry': 1,\n",
       " 'portability': 1,\n",
       " 'versatility': 1,\n",
       " 'generality': 1,\n",
       " 'Study': 1,\n",
       " 'capacity': 3,\n",
       " 'Naturally': 1,\n",
       " 'Every': 2,\n",
       " 'Universtity': 1,\n",
       " 'likeley': 1,\n",
       " 'continually': 1,\n",
       " 'finally': 2,\n",
       " 'company': 2,\n",
       " 'increasingly': 2,\n",
       " 'Anatomy': 1,\n",
       " 'morphology': 1,\n",
       " 'surprisingly': 1,\n",
       " 'slightly': 4,\n",
       " 'mostly': 2,\n",
       " 'variety': 9,\n",
       " 'essentially': 1,\n",
       " 'actually': 9,\n",
       " 'mainly': 3,\n",
       " 'usually': 8,\n",
       " 'easy': 5,\n",
       " 'may': 31,\n",
       " 'say': 11,\n",
       " 'Many': 2,\n",
       " 'costly': 1,\n",
       " 'sematica/ly': 1,\n",
       " 'category': 1,\n",
       " 'semantically': 4,\n",
       " 'perplexity': 1,\n",
       " 'Adaptability': 1,\n",
       " 'automatically': 7,\n",
       " 'play': 7,\n",
       " 'key': 9,\n",
       " 'hierarchy': 2,\n",
       " 'ontology': 1,\n",
       " 'only': 27,\n",
       " 'sary': 1,\n",
       " 'carefully': 3,\n",
       " 'necessary': 9,\n",
       " 'differently': 1,\n",
       " 'modify': 6,\n",
       " 'Query': 7,\n",
       " 'Saturday': 1,\n",
       " 'exactly': 7,\n",
       " 'saturday': 2,\n",
       " 'identify': 3,\n",
       " 'really': 7,\n",
       " 'Very': 2,\n",
       " 'quality': 9,\n",
       " 'typologically': 3,\n",
       " 'money': 5,\n",
       " 'why': 7,\n",
       " 'complexity': 3,\n",
       " 'closely': 8,\n",
       " 'History': 1,\n",
       " 'verify': 1,\n",
       " 'obligatory': 1,\n",
       " 'any': 28,\n",
       " 'empty': 2,\n",
       " 'majority': 1,\n",
       " 'generally': 3,\n",
       " 'substantially': 1,\n",
       " 'roughly': 2,\n",
       " 'typically': 2,\n",
       " 'inability': 1,\n",
       " 'relatively': 5,\n",
       " 'every': 3,\n",
       " 'many': 14,\n",
       " 'unreliability': 1,\n",
       " 'equally': 1,\n",
       " 'especially': 5,\n",
       " 'directly': 1,\n",
       " 'memory': 15,\n",
       " 'previously': 6,\n",
       " 'already': 7,\n",
       " 'priority': 1,\n",
       " 'apply': 4,\n",
       " 'similarity': 3,\n",
       " 'currently': 3,\n",
       " 'primary': 2,\n",
       " 'ambiguity': 7,\n",
       " '(majority': 1,\n",
       " 'property': 3,\n",
       " 'stochastically': 1,\n",
       " '(help/by': 1,\n",
       " 'purely': 1,\n",
       " 'probability': 5,\n",
       " 'manually': 3,\n",
       " '(mostly': 1,\n",
       " 'accuracy': 8,\n",
       " 'immediately': 1,\n",
       " 'rarely': 1,\n",
       " 'simplicity': 1,\n",
       " 'linguistically': 1,\n",
       " 'glossary': 1,\n",
       " 'entry': 3,\n",
       " 'Currently': 2,\n",
       " 'lexically': 1,\n",
       " 'homonymy': 1,\n",
       " 'enjoy': 1,\n",
       " 'many-to-many': 1,\n",
       " 'unnecessary': 1,\n",
       " 'possibility': 1,\n",
       " 'namely': 1,\n",
       " 'partially': 1,\n",
       " 'Ministry': 1,\n",
       " 'Syntactially': 1,\n",
       " 'Dependency': 1,\n",
       " 'Technology': 5,\n",
       " 'high-accuracy': 2,\n",
       " 'body': 5,\n",
       " 'particularly': 2,\n",
       " 'dramatically': 2,\n",
       " 'instantly': 2,\n",
       " 'history': 1,\n",
       " 'freely': 1,\n",
       " 'vocabulary': 1,\n",
       " '(particularly': 1,\n",
       " 'Dictionary': 3,\n",
       " 'inherently': 1,\n",
       " 'successfully': 7,\n",
       " 'likely': 6,\n",
       " 'hey': 1,\n",
       " 'Yarowsky': 1,\n",
       " 'considerably': 1,\n",
       " 'ssentially': 1,\n",
       " 'Kelledy': 2,\n",
       " 'extremely': 6,\n",
       " 'Quigley': 2,\n",
       " 'proprietary': 1,\n",
       " 'thirty': 5,\n",
       " 'Methodology': 1,\n",
       " 'preliminary': 4,\n",
       " 'Certainly': 1,\n",
       " 'methodology': 1,\n",
       " 'heavily': 1,\n",
       " 'mistakenly': 1,\n",
       " 'simply': 2,\n",
       " 'greatly': 4,\n",
       " 'user-friendly': 1,\n",
       " 'commercially': 1,\n",
       " 'buy': 1,\n",
       " 'highway': 1,\n",
       " 'freeway': 1,\n",
       " 'expressway': 1,\n",
       " 'separately': 2,\n",
       " 'originally': 1,\n",
       " 'bunny': 1,\n",
       " 'energy': 2,\n",
       " 'Gregory': 1,\n",
       " 'City': 1,\n",
       " '\"Query': 1,\n",
       " 'certainly': 1,\n",
       " 'ity': 2,\n",
       " 'strongly': 2,\n",
       " 'Only': 1,\n",
       " 'largely': 1,\n",
       " 'ly': 6,\n",
       " 'oughly': 1,\n",
       " 'try': 4,\n",
       " 'By': 3,\n",
       " 'ally': 2,\n",
       " 'commonly': 2,\n",
       " 'probably': 6,\n",
       " 'matically': 1,\n",
       " 'satisfy': 1,\n",
       " 'explicitly': 4,\n",
       " 'laboratory': 1,\n",
       " 'thoroughly': 1,\n",
       " 'randomly': 3,\n",
       " 'Primary': 6,\n",
       " 'absolutely': 1,\n",
       " 'highly': 3,\n",
       " '(Kay': 1,\n",
       " 'They': 5,\n",
       " 'monly': 1,\n",
       " 'mally': 1,\n",
       " 'reasonably': 3,\n",
       " 'Probability': 2,\n",
       " 'bility': 1,\n",
       " 'possibly': 1,\n",
       " 'noisy': 2,\n",
       " 'poorly': 1,\n",
       " 'variability': 1,\n",
       " 'strictly': 1,\n",
       " 'Daily': 1,\n",
       " 'Summary': 2,\n",
       " 'Kay': 1,\n",
       " 'statistically': 2,\n",
       " 'Laboratory': 2,\n",
       " 'security': 1,\n",
       " 'unwieldy': 1,\n",
       " 'rapidly': 1,\n",
       " 'functionality': 1,\n",
       " 'initially': 1,\n",
       " '(approximately': 1,\n",
       " 'customer-friendly': 1,\n",
       " 'clarify': 2,\n",
       " 'my': 3,\n",
       " 'introductory': 1,\n",
       " 'away': 1,\n",
       " 'completely': 1,\n",
       " 'thereby': 2,\n",
       " 'difficulty': 1,\n",
       " 'fully': 2,\n",
       " '\"key': 1,\n",
       " 'specially': 1,\n",
       " 'subsequently': 1,\n",
       " 'unlikely': 1,\n",
       " 'specify': 1,\n",
       " 'occasionally': 1,\n",
       " 'Display': 1,\n",
       " 'study': 1,\n",
       " 'Curry': 1,\n",
       " 'theory': 1,\n",
       " 'Industry': 1,\n",
       " 'technology': 1,\n",
       " 'smoothly': 3,\n",
       " 'LuperFoy': 3,\n",
       " 'perFoy': 1,\n",
       " 'preliminarily': 1,\n",
       " 'ily': 1,\n",
       " 'nary': 2,\n",
       " 'respectively': 1,\n",
       " 'appropriately': 1,\n",
       " 'locally': 1,\n",
       " 'boundary': 3,\n",
       " 'auxiliary': 1,\n",
       " 'credit-card-by': 1,\n",
       " '(y': 5,\n",
       " '((y': 2,\n",
       " '\"Very': 1,\n",
       " 'Necessity': 2,\n",
       " 'necessity': 1,\n",
       " 'ably': 1,\n",
       " 'propriately': 1,\n",
       " 'ety': 1,\n",
       " 'Manny': 1,\n",
       " 'ty': 1,\n",
       " 'speech-only': 3,\n",
       " 'eliability': 1,\n",
       " 'validity': 3,\n",
       " 'artificiality': 1,\n",
       " 'holiday': 1,\n",
       " 'stay': 3,\n",
       " 'primarily': 1,\n",
       " 'heavy': 1,\n",
       " 'consistently': 1,\n",
       " 'quickly': 1,\n",
       " 'Friday': 1,\n",
       " 'party': 1,\n",
       " 'ability': 1,\n",
       " 'significantly': 1,\n",
       " 'sunday': 3,\n",
       " 'MjSlby': 5,\n",
       " 'mjSlby': 1,\n",
       " 'preferably': 1,\n",
       " 'twenty': 4,\n",
       " 'sixty': 3,\n",
       " 'forty': 2,\n",
       " 'okey': 2,\n",
       " 'Sunday': 1,\n",
       " 'fy': 1,\n",
       " 'fifty': 2,\n",
       " 'multi-modality': 1,\n",
       " 'Jeremy': 1,\n",
       " 'Literary': 3,\n",
       " 'Maybury': 2,\n",
       " 'survey': 1,\n",
       " 'Geoffrey': 1,\n",
       " 'Anthony': 1,\n",
       " 'Usability': 1}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = EndAty(\"Text_File.txt\")\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DxvGHnwaxS9u"
   },
   "source": [
    "## Task 6\n",
    "Write a function that prints the count of lowercase letters in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "LuCPakz4xYuC"
   },
   "outputs": [],
   "source": [
    "def CountLower(filename):\n",
    "\n",
    "    #Write your logic here\n",
    "    \n",
    "    file = open(filename,\"r\")\n",
    "    letters = {}\n",
    "    for line in file:\n",
    "        for word in line.split():\n",
    "            for letter in word:\n",
    "                if letter>='a' and letter<='z': # check if letter is betwee [a,z]\n",
    "                    if letter in letters:\n",
    "                        letters[letter] += 1 #if letter is already in dict increse its value by 1\n",
    "                    else:\n",
    "                        letters[letter] = 1  #if letter is not in dict, add it in dict and assign it value of 1        \n",
    "    \n",
    "    #sort the dict before printing\n",
    "    letters = sorted(letters.items())\n",
    "    letters = dict(letters)\n",
    "    print(letters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "7mB_Cx0CxdXb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 12006, 'b': 1698, 'c': 4565, 'd': 4579, 'e': 17300, 'f': 2932, 'g': 3091, 'h': 5744, 'i': 10066, 'j': 172, 'k': 788, 'l': 5934, 'm': 3597, 'n': 10499, 'o': 10245, 'p': 3167, 'q': 190, 'r': 9073, 's': 10167, 't': 12700, 'u': 4221, 'v': 1179, 'w': 1823, 'x': 551, 'y': 1944, 'z': 179}\n"
     ]
    }
   ],
   "source": [
    "CountLower(\"Text_File.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzAQ3voGxenV"
   },
   "source": [
    "## Task 7 \n",
    "Write a function to replace all \"the\" with \"thee\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "EEY79-N1xeUT"
   },
   "outputs": [],
   "source": [
    "def ReplaceThe(filename):\n",
    "    \n",
    "    #Write your logic here\n",
    "    \n",
    "    # open the file and save all the content in it ina variable\n",
    "    file = open(filename,\"r\")\n",
    "    file_data = file.read()\n",
    "    file.close()\n",
    "    \n",
    "    # replace 'the' with 'thee' in the data\n",
    "    file_data = file_data.replace(\"the\",\"thee\")\n",
    "    \n",
    "    # write edited data in the file\n",
    "    file = open(filename,\"w\")\n",
    "    file.write(file_data)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "id": "paxgYJEkxo73"
   },
   "outputs": [],
   "source": [
    "ReplaceThe(\"Text_File.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gHtVLQzHxqDa"
   },
   "source": [
    "## Task 8\n",
    "Write a function ZICount() that prints the count of all occurences of Z and I (including small cases a and i too)\n",
    "For example: Hi! I am Zenia. It was so good to see you! \n",
    "#### Output: \n",
    "I or i : 4\n",
    "\n",
    "Z or z : 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "id": "AzuW9kPmxpvS"
   },
   "outputs": [],
   "source": [
    "def ZICount(filename):\n",
    "\n",
    "    #Write your logic here\n",
    "    \n",
    "    file = open(filename,\"r\")\n",
    "    z_count = 0\n",
    "    i_count = 0 \n",
    "    \n",
    "    for line in file:\n",
    "        for word in line.split():\n",
    "            for letter in word:\n",
    "                if letter in['z','Z']: #if letter is 'z' or 'Z' increase z_count by 1\n",
    "                    z_count +=1\n",
    "                if letter in ['i','I']:#if letter is 'i' or 'I' increase i_count by 1\n",
    "                    i_count +=1\n",
    "                    \n",
    "    print(\"I or i : {}\".format(i_count))\n",
    "    print(\"Z or z : {}\".format(z_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "id": "hRqosNj-yE1s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I or i : 10605\n",
      "Z or z : 190\n"
     ]
    }
   ],
   "source": [
    "ZICount(\"Text_File.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pcwK-ALVyHlQ"
   },
   "source": [
    "## Task 9\n",
    "Write a function to display the content of a file in aescending order (based on the word count)\n",
    "\n",
    "Content: I am confused to start it but it won't be done until I give it a try\n",
    "\n",
    "Output: I it to a am be confused done give start try until wont.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YShxmMDFyLbw"
   },
   "outputs": [],
   "source": [
    "def CountAsc(filename):\n",
    "    \n",
    "    #Write your logic here\n",
    "    \n",
    "    file = open(filename,\"r\") # open file in reading mode\n",
    "    \n",
    "    d={}\n",
    "    #count the occurance of each word and store it in a dict\n",
    "    for line in file:\n",
    "        for word in line.split(): \n",
    "            if word in d:\n",
    "                d[word]+=1\n",
    "            else:\n",
    "                d[word]=1\n",
    "    \n",
    "    # sort the dict so that words have same count are printed in ascending order\n",
    "    d = sorted(d.items())\n",
    "    d = dict(d)\n",
    "    result = ''  \n",
    "    \n",
    "    # print the result in aescending order\n",
    "    for i in range(len(d)):\n",
    "        MinKey = min(d, key=d.get) # use mas insted of min to print in descending order\n",
    "        result += MinKey +\" \"\n",
    "        d.pop(MinKey)\n",
    "    \n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "m7Erk1_0yYkm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"(\"Mr.\" \"), \"- \".../chinese/.../fi \".../en- \":default\" \":h-gender \":pattern-cond.\" \":s- \":s-gender \":word-cond \":word-cond\" \"> \"A \"An \"Distinguishing \"Does \"How \"I \"Mr.\" \"Ms.\" \"No\"). \"No.\" \"Phrasal \"Please \"Query \"S>\", \"Scandinavian\" \"Should \"Soubor \"TREC-4 \"U>\", \"V>\". \"Very \"Yes\" \"Yes\") \"accept \"byt6\" \"b~\" \"confidently\" \"difference \"diskriminace\" \"e\" \"engl \"file-ch.html\" \"file-en.html\" \"form-for-form\" \"hi\" \"in \"javljat6sja\"; \"key \"lokalizace\" \"natural \"ni\" \"operator\" \"operator,\" \"oukesuru.\" \"payment,\" \"po- \"polite,\" \"polite- \"politeness\" \"pomoci\" \"quit\" \"quit.\" \"sama\" \"sama\") \"san.\" \"shi- \"shouchiitashimasita \"similar\" \"situational \"soredekekkoudesu \"spoken \"stop,\" \"train\" \"train\". \"translation\" \"una,\" \"unir\" \"wa\" \"watashidomo \"~ \"~\" \"~ld. #1; #2) #3 #4 #4, $11 $11: $13 $15: $3 $7, $9, %2f0601%2 %~!,~:,.' '% '98, '99, 'A' 'AM'. 'AMX3' 'Amex 'Amex110'. 'IR 'SFD', 'Turkey' 'computer- 'distilling 'empty' 'product' 'product__ids' 'product_descriptions' 'programs' 'realistic' 'scenarios'. 'sys- 'system', 'to 'wiz- (\"Mr-ms.\" (\"Ms.\" (\"bus\")) (\"oshiharai\") (\"oukesuru\"):s-role (\"pay- (\"payment\") (\"shiharai\")) (\"sunstroke\"))) (\"uketsukeru') (\"watashidomo\") (\"watashltachi\"))) (\"we\") (#17 ('wizards') ((\"get\") ((\"room ((\"we\") (((\"Mr.\" (((\"payment\") (((\"take\") ((target (0.1427) (0.1804) (0.2232). (0003 (0; (1, (11s) (13 (166) (18 (1981) (1985) (1986) (1988)). (1989)) (1989). (199 (1990) (1990)). (1990). (1991)). (1991), (1991-99), (1992). (1993) (1993), (1994) (1996)) (1998) (1998)). (1999)). (2), (2). (2000) (3) (35.9%mono) (39.0%mono) (39.6%mono) (46.3%mono) (5 (55% (56.1%mono) (59% (6 (6) (66.9%mono) (68% (7) (7), (83% (952) (ANLP), (ASR) (Ahrenberg (Allen (Also, (Amble (Anony- (Anonymous, (Babelfish); (Bagga (Biermann (Bratseth, (Brown (Bub (BusLOG) (C (C/M%). (CLIR) (CLIR). (CONtext (Carberry, (Carletta, (DM) (Dahlb/ick (Dahlb~ick (Denisowski, (ER) (ETRW) (English/Czech, (Fellbaum (First (Flank (Flycht-Eriksson, (Furuse (Garside (Georgila (HSFR/NUTEK) (Help (Horiguchi, (IRS), (IVR) (Intertran) (Isabelle (JSnsson, (KB), (KFB) (Kay (Kowal- (Langenscheidt (Langlais (Lu- (Machine-aided (Mima (NL). (NTNU), (Norwegian (Our (Pereira (Q-systems) (Quebec), (Qvarfordt (RIAO'00). (Resnik, (Rosen (Sicstus (Statskontoret), (Sumita (T2.reg_no=Tl.reg_no) (T3.sex='m') (T4.bed_no=T2.bed_no) (T4.reg_no=T3.reg_no) (T5.hosp_no=T4.hosp_no) (T5.ward_no=T4.ward_no) (TDMT (TREC- (TREC-4), (Takezawa (Teigen (Temporal (Tl.sex='f') (Transparent (Unlike (V (V- (Walker (Warren (Which (X) (\\[which\\],\\[person\\]). (\\[who\\],\\[has\\],\\[a\\],noun(N),\\[that\\]). (although (approximately (because (bigrams) (chinese-english (cuts) (details (each (economical (ed.) (examples (features) (font) (freetranslation.com): (from (help/by (http://trec.nist.gov/pubs/trec4/t4_proceedings.html) (http://www.clis.umd.edu/dlrg/filter/sss/papers) (human (if (illustrated (incl. (lo4) (machine (majority (maybe (model (more (morphological (morphology, (most- (mostly (non (normalize (not (novels) (of) (one-nation-two- (or, (particularly (product_word, (re-writing) (regular) (see, (situation). (source/target). (technical (template) (templates) (this (though (to (top-frequency) (transducing (type) (user (very) (we (which (with (word (www.intertran.net:2000): (www.lhs.com). (www.nuance.com) (www.speechworks.com) (~:~h-fv-c?.JLJl) (~ESILKO, (~ESiLKO (~t~-~Ã‚Â¢-#cJL.~) *Current ,-~Ã‚Â¢~. ,average ,~- -* -+ --- ---* -... -: -A -CN) -Ch -Yun -ace. -ation -~-~ ... ...... ............... ........................ ...\\]. ...}. .category, .n //www. /1996 /cis /~ke 0(3). 0+3+0)). 0.023685 0.044959 0.071705 0.093012 0.107304 0.136319 0.1427 0.15011 0.1504 0.1530 0.16608 0.171769 0.176695 0.179633 0.1841 0.189513 0.19448 0.2001, 0.201472 0.2232 0.224902 0.231637 0.2583 0.309642 0.313676 0.317435 0.343071 0.344001 0.358592 0.36569 0.367518 0.375868 0.3861 0.3976 0.401997 0.421837 0.445453 0.467034 0.467646 000 0002, 0003, 0003; 0004, 0005 0005; 0006 0006; 0007) 1(1), 1), 1). 1): 1,409 1,500 1-1 1-16. 1.1 1.2 1.3 1.65 1.7Ã‚Â°/'o 10,000 10-14 100% 100%) 100%, 100) 102-104. 104 106---132. 107-110, 11,\" 110'. 111-114, 1129-1135, 117.2Mb 11I 12(3): 12309 13. 1300 1325; 136.5Mb 14 140000 142. 145 14820 150 150.000 159-160 16-23, 163 165 166 171-180. 1710 1725. 175-204. 176-183, 177-184, 18(6): 185 19% 19-27\\]~ 1900 1980), 1980. 1981). 1982). 1982. 1985. 1986). 1986. 1986; 1988),(Teigen 1988-89 1988-99 1989). 1989, 1989. 1990). 1990, 1990. 1990; 1991) 1991; 1992; 1993)). 1993). 1994, 1995), 1995). 1995, 1996 1996; 1998 1998Ã¢â‚¬Â¢ 1999 1999a) 1999a. 1999b), 1999b. 1999Ã¢â‚¬Â¢ 19:121- 19:263-311. 1:1 1:2, 1; 1An 1The 1to 1~,\" 1~tA~ 2, 2-2, 2.2. 2.2.1 2.2.2 2.2.3 2.2.4 2.2.5 2.2.6 2.35 2.5.1 2.5.2 2.5.3 2.7 2.9 20% 2000 201/99/0236 21) 21218, 2168983. 22 22(2):249-254. 22180 2229005\" 229- 235, 24 25 25(30), 26 2600 27 27% 27-times 2779-2782, 28)) 29 2:1 2:2, 2fi 3). 3, 3,000 3- 3.5 3.58 3.7 3.7), 3050 31 31th 32 32nd 333333 3400 34th 35 35000 36 361-388. 367 36th 38 3:3, 3J7 3MlaserCam, 4.2.1 4.2.2 4.3 400,000 4000 405/96/K214 40E? 41 412-417, 420 43 44% 45438628. 46 47 48 483- 49 490. 4J~'~ 4~ 5.1 5.1.1 5.1.2 5.2 5.3 50% 50%, 50.3% 500-236: 51 53 53% 54% 55 56% 56.1%. 59 590 5gonblick 5h 5ndh~llplatsen 5vet 6) 6, 6,No 60,000 60000 61-70. 6128, 619-0288, 62% 62-70. 628-636. 63 66 66% 67 68% 6gonblick 7(1):1-16. 7) 7). 7-48. 700 7000 71-74, 73% 74-81, 77%. 79% 794-801, 7: 8(0):67-95. 8(3-4). 8(4):244-257. 8(4):259-265. 8) 8, 80' 80-87, 8000 80s 81.5%. 810 83 83, 86 87-90, 89-94, 8: 9 9(3-4):285-313. 9, 9-16, 90%. 90(#3 91 92Ã‚Â°/'0. 93% 95% 98%. 99% 9: :$5 :/ ://humanities.uchicago.edu/ARTFL/proj :<TITLE> :default)\\[ :s-gender :~,,~ ; </$> </H </HI> </s>. <CEHTEIL~ <CRD>23051999 <CrD>23051999 <CrU> <CrU>MT! <CrU>VK <H <H2>~ <H2>~k <H3>.~ <HI>Journal <I-1R> <TITLE> <\\]s> ==~ >Journal >n/a @crd.ge.com @iro. @itl.atr.co.jp @slt. A., A.Tsopanoglou, A.W.; A/S ACL, ACL- ACL-9$: AI, ALT=\"~\" ALT=\"~k\" AMTA AMX3, AMXl ANGIXM2004, AP APAC3-2: ASCII ASR AT&T, ATR- ATR-MATRIX ATR-MATRIX. Aarno Abella. About Access Acknowledgments Acoustic Acoustical Actually, Ad- Adaptability African, Again, Agency, Ahrenberg, Ahrenberg. Akira Al Alevtina Alexander Algorithm Alicia Alignment Allen. Ambiguities Amble Amble, Amit Anatomy And Annotated Annotation. Anthony Any App Appendix: Applicable Application Applied Aspects. Assessing Assoc. Assuming Atkins Atkins, Attentions, August, August. Aus- Automation Average B. B.J. B6movfi, B6mov~, BAGGA, BGCOLOR=\"#fffffff> BISTABLE BOARD BORDER=0 BORDER={) Bagga, Ballesteros Ballesteros, Baltimore, Barbora Barbora; Barked. Be- Before Below, Bennett, Beside Between Biber, Biber. Bilingual Board Botswana Bowden Bratseth. Breach Brennan, Bridges: Brill, Bruce Bu- Bub Budapest, Build Building Builds Bulgarian Bureau C., C.L. C.P. C: CEDICT CENTRE-V CESILKO CESiLKO. CGI-scripts. CHAT-80,called CHAT-80. CI104 CL CL'98, CL-97 CL/EA CLIR) CLSP CN) COLING COLING-96, COLING-A COLING-ACL'98, COLING-ACL, CONTENT=\"Westem\"> CONTENT=\"Western\"> CRD CUR Can Canada Candace Caption Carberry, Carletta. Carnegie-Mellon Carolyn Carpenter Carpenter. Carter, Carter. Case, Cat Categories Cedict Centre Certainly Chances Character Chen Chen, Chen. China. Chinese\". Chinese) Chinese), Chinese, Christi- Christiane, Christoph; Chu-Carroll Chu-Carroll, Church Church, Church. Circle City Clear, Clerk: Close Cognates Cognitive Coling'98, College Collins, Colmerauer's Colum- Com- Commerce, Common Communication Communicator, Comparing Comparison CompositionAL Compositional Compu- Computa- Computation- Con- Conceptual Consen- Consequently, Constantinides, Content-Based Control. Control? Conversely, Copenhagen. Coprus: Core Corporate Coupling Crawling Croatian Croft Croft, Cross Cross- Cross-language Crowdy, Crowdy. Cruces, Cruz, Current Curry Customer Customer: Customizing Cynthia; Czech- Czech-to Czech-to-Polish Czech/Russian Czech/Russian) Czechoto-Slovak D.; D.H.D D.H.D. D.M.; DISTINCT DM, Dah Dahlb/ick Dahlb~ck Dahlb~ck, Daily Daniel: Danish Database,\" Database. Datamation, David, De- December Denisowski. Denmark, Depar Dependency Desoxynribonukleinsaeure Dia Dialogue, Dialogue-Based Dialogues Diane Dictionary) Dictionary; Different Directions Dis Disambiguate Disambiguation,\" Discuss Display Distances Disti Distilled Distinguishing Documents Domain-related Dong Doug Douglas Douglas; Dr Dr., Driven Dublin Durand. D~partement E) E, ECAI'96 ESCA Efforts, Eiichiro Either Eng Engiish-Chinese Engineering. Engl English). English, English-chinese English-to- English-to-Czech English. Enrique Entity Entr Eric; Erik Eskenazi, EuroWordNet Eva Example: Exchanging Expectation Exper Experimental Experiments Export FROM Face? Failure Fe. Features Felisa Fellbaum, Festschrifi Fetching FidelityXPress: Filler Filtering Final Financial Finite-state Finland First; Five Flycht-Eriksson, Flycht-Eriksson. Following. Fourth French), French-French\\] French-speaking, Friday Fulkerson, Furuse G.A.; G.Kokkinakis. GA(~R GAt~R GSteborg, Gaithersburg, Galliers Galliers. Gaps Garside, Gender, Generated Generation Generation, Geoffrey Geog- Geogra- George Georgila, German, German-speaking German. Germany. Given Giving Go Goal-orientedMultimedia Gordon Grafik Gram- Grammar) Grammar, Grammars, Grammars. Greek Greenemeier Greenemeier, Grego- Gregory Gregory, Grosz Grosz, Guinn, H'ITP-EQUW=\"Content-type\" H'lTP-EQUIV=\"Content-language\" H3C HAJI(~ HREF=\"/erdpej/b2g__pej.phtml?URL=%2fen%2fp HREF=\"/ergpej/b2g_pej.phtml?URL=%2fen%2fp HRIC HSQL, HSQL. HTI'P-EQUIV=\"Content-language\" HTTP-EQUIV=\"Content-type\" Haji~ Hana Handling Hansard Harman, Harvard Has Hauspie Heidlage, Help Helsinki Hence, Here, Hi, Hideki Hikaridai, History Hitoshi Hladkfi Hopkins Horiguchi Horiguchi. How- Hsu Hull Hull, Hy- Hyon I!! I.; I00 IBM's ICLSP'98, ICSLP-98, ID, II:th ILLE INKOPING IRS' IV-CN) IVRish IVRs Identification Identifying Iida, Iida. Implemented Import Improve In) In- India? Industry Inflective Informa- Informations Initially, Initiative. Instead Instrument Integrated Intelligence, InterUigence, Interactive Interestingly, Internal Internet, Internet,and Interpreting Intertran Introduct Is- I~:~ J, J.Hric J.R. JAPAN JHU. JJ~ Jae-Woo Jan; Jang, Japan, Japanese). Japanese- Japanese-to- Jarmila Jean Jeremy Jg Jgif/pejbg.jpg\" Jgiffpejbg.jpg\" Jianyun Jim JllL~ Johns Jon Jones, Julia Julio Julio, Jun June. Jwan K., K.; KTI KUBON Kamm, Karel Karen Karin Karolinum Kashioka Kay Keiko Keim, Kenneth Kirschner Kirschner, Kluwer. Knudsen, Korean-to- Korean-to-English Kubofi Kubofi, Kuo, Kwok. Kyoto, L=CS_01>, L=SK_01 L=SK_01>, L=SK_01>Pomoci Laboratories Laboratories* Lai, Lan- Lance; Langlais, Language/ Languages Lapalme. Large-scale Larsson, Las Latin Layered Lecture Leech, Left Lehtola, Lena Length Lessons Letus Levin, Levin. Lex Lexical Lexical-Semantic Lexicon Liang, Libya Limited Lin- LinkSpin9 LinkSping. Linux). Lisa Lisa, Listed Lists, Litman, Ljungberg, Localization Logic) Logic, Longman. Looking Lori M M.: MAHT MATRIX. MD MD, MEMORY') MHz MT. Ma- Machines Madrid. Making Manny Marilyn Mary. Mary? Maryland. Masaki Mass.: Massachusetts. Matching Mathematical Maxi- Maxine May. McCarley, MeEnery. Measuring Mediterranean Meisel Meisel, Melamed, Method Methodology Methods Michael; Miller, Ministry Mod Mode Modifying Module Modules Mono-Lingual Morimoto, Morimoto. Movement Multiple Mutual Myaeng, Myung-Gil, N-7491 N. N.Fakotakis NFP2 NIST NL NLP NLP- NLP-professional. NM, NRL, NTNU NY Name National Naturally Naturlig Naughton Neither News News, Nicholas Nie, Niskayuna, None Nor Norway Norway, Norway. Norwe- Norwegian. Norwegian.) Norwell, Not Note Note, Noun. Nouns November. Now Ntis Nuance Nuance's Number, N~ir O'Donnell O'Donnell, O.</H2> O0 O01/. OCCUPANCY OFAL Oard Obviously, October, October. Of Often Oh Ohio. Ole Oliva Oliva, Once Only Op~rationnel Order Oren; Osamu Oslo Ostler. Owing Oz-Dialogues Oz-and Oz-dialogues, Oz-phase. Oz-studies. PATIENT POS Painful Pairs Panevov~i, Para Paradise: Parameter Park Park. Participants Penstein Peo- Pereira Pereira, Pereira. Perl Ph.D. PhD PicmreQuest-internal PictureQuest's Plain-speaking: Plamondon. Plan Planning Pleasures Po Posting Practical Pragmatic Pragmatics Prediction Presentation Press, Pro- Problems Proceedin Processing, Processor Program Project: Prolog). Prolog-like Prolog. Publication Publishers. Q-systems. Q; Quebec. Queries Quigley, Qvarfordt Qvarfordt, R R--2 R.. R.; RALI RECEIVER REtrieval RSscheisen, RSscheisen. Railway Rajagopalan, Ramshaw, Ranking Rapport Ravnholt. Read- RealSpeak Reason- Recent Recently, Recherche Refl. Reinke, Related Relations,\" Relationship Relevant Remove Report. Representations Representativeness Resnik Resnik, Resnik. Resolve Resu Retrieval. Revenue Review, Rich, Richard Ringer, Ro Robert Robust Robustness Rochester Rodman, Roger Rosen, Rossheim Rossheim, Routing. Rubin, Rudnicki, Rules Ryds S-581 S13. S5: SELECT SENSitive SGML SGML-Iike SID SILC SILC: SIovak, SNACK-85 SQL) SQL-databases SQL. SRC=\"/en/gif/kan.gif\" SRC=\"/erdgif/kan.gif\" STRAND STRZALKOWSKI, SWEDEN Sample Santamarta, Saturday Sc Scan Schema Schwartz, Scott, Se Seattle, Sec- Seika-cho, Sense Sense: Senses Serbian Sergot Sergot, Sergot. Server Service Service. Services. Set Setsuo Sharon Sikorski, Similarly, Simple Siovak, Sites Skoumalov~i Sl1: Slovak, Smart So So, Soc Soci- Solutions Soraku-gun, Spanish,\" Spanish-English Spanish-speaking, Spanish. Special Speechworks Springer Springer-Verlag, Spr~k St., Staffan Standards Starting State States, States. Station Statistical Statskontoret. Stein Steve Stock- Stop-list Stop-words Structure Structured Strzalkowski, Study Sub-String Such Sue Sum- Sumi Summit Sunday Sung Sunrain.net Susann Suzuki Suzuki,\" Swe- Sweden, Swedish) Swedish, Sydney. Syntactially Syntax System. System; Systems. Systran T2,PATIENT T3, T3.name,Tl.sex,T2.reg_no,T3.sex, T4,WARD T4.reg_no,T4.bed_no,T5.hosp_no,T5.ward_no T5 TDMT, TEXT=\"#000(3(O\" TEXT=\"#O00000\" TI,OCCUPANCY TMI-92, TMI-97, TRADOS) TRAINS/TRIPS TREC-7 TREC5 TREC7. TRIPS TUC's TV TV- Tagset. Takezawa Taking Talking Talking. Technical Techniques Telecommunications Telephones Template Term Text-translation Their Then, Theoretical This, Thomas Thresholding Thur~e. Tierney, Tillman, Todd Tomek Toshiyuki Total Towards Tower Tra Traffic Trafikkselskap), Trans- Transactions. Transducing Transla- Translate Translated Translation, Translation. Translations Translmion Transparent Transper- Transperfect Transperfect, Transport Travel Treebank. Trondheim, Tsuyoshi Tutorial Tutoring TvomsÃ‚Â¢. Two Type Typically, U10: U14: U4. UNIX, URL, URLs; USA, USA: Un Under Unfortunately, Unit University: Universitz, Universit~ Universtity Unlike Until Upon Us Usability VA VI- VS96151. Vector- Verb Verbmobih Verdejo Verdejo. Verlag. Version\" Vet Vi- Vidal. Vienna, VoI., Voice Voice-Recognition VoiceXPress W WHERE WISE Walker, Warren Warren, Warren. Washington, We-TOP Week, Weighting,\" Well, Whose Wi William With Without WordNet: Words Work Work- Workbench) Workbench. Working Workshop'98 XII1, XIV:th XVI, Xinhua Xlllth Y). Yamada, Yarowsky Yarowsky, Yeah Yees York; You Young Z Z.; Zden~k Zeman, \\[ \\[\"in \\[French \\[doreille\\]' \\[horneando-removed\\] \\[lit.: \\[manx\\] \\[signes\\] \\[spring\\] \\[three/rub(imperative)\\]), \\[which\\], \\[who\\], \\[whose\\], \\[woman/chasing\\] \\] \\]00,000 \\]NFS7 \\]Srtisex \\]aan \\]emti/em \\]jorton \\]yrahundra \\]~ _e.htm. a, a-kind-of abbreviations, abelle. abi!ity abilistic abilities ability ably absolute absolutely abstract accelerate accents accept- acceptable accompanied accord- accordingly. account\" account, ach, achieve achieved, achieved. achieving acid acquire across acting action(go,E), actor actor(A,E), actu- ad- adapt adaptation\" adapting added. adding addresses addressing adequate adjectives, adjust adjustment adjustments: adminis- administration. adopt adopted, adu advances advantage, advantages advantages, advertising advertising, advisor affected affected, affecting affiliation affirmative affixes affixes, afresh. africana, afrikanske again) agencies. agents. ago, agree al al- alTle alf algorithm, algorithm: alike all: allel allowed alogne alpha-numeric already. also, altered alternative alternatives. amazingly ambiguous). amble@idi, amendment amined among ample, amples an, analogical analysing analyze analyzed analyzes anaphora, anatano ance anchor: ang anks anning anoth- another. answered, antecedent anticipate anyway). anyway, appearance, appliance applica- applicable. applications applied, applied. approach. approached appropriately appropriately. ar- architec- architecture. ard' are. area. areas ariraasu arnjo@ida.liu.se arrival, arrives artificiality aspects, assem- assess assessment assets assign assistance assuming assumptions asthose aswell. at- at: ata ated ates atio atr. attached attempts attendance attention attributes auditor authors. automates automobile automobiles auxiliary av average). average. averaging avoid avoids away a~ b ba- back-end background backs back~restart bad bagga, bake baking ball bank's barn barriers. base_on baseline. baseret basis basis. be, be. be\\] bear. became become bed? before. begins behaviour. behhver belief belong below). below, benchmark. beneficial beside besides bet beyond big- bilingual, bility bill bit ble bled block blocked blocks blond blonde bogus bombarded bordered bordering borders bottlenecks bottom-up bound boundaries boxes boys breadth-first breaks brid bridge brief brilliant bringing broken built, bunny burden bureau bus, bus. businesses. busroute bussar button). button. buy by-word byta byter c.f. ca calculations, call, calling camera camera) candi- cant capabili- capabilities, capabilities. capable captions, car car, care cares carnegie carpenter's carry cart case) cases, category cates cau- causes centers. centrum cerned certainly cessing ch challenge challenge. chances change. changed. charac- character), character. characterise characterising characteristic characteristics. characterized charset--iso-8859-1\"> charset=big5\"> charset=bigS\"> charset=iso-8859-1 chart charter child child, chitecture choose chooses chose chunks cient circuit circumstances, claiming class, class. classi- classic classified clause cleaning clerk\" clerk) clerk), clicked close, closeness closer clothe clothes cluded co-occur co-occurrence co.jp coa- codage, code. coexistence cog- cognateness cognates collec- collect collecting collection. collections collimator) collimator), collimator). colorful colors colour combine comfort- coming commands comments comments. commercial commercially committed commu- communities. community, compa- company. company: comparing comparison competitive complements complements, complements. completely completely. completion compliances complicated. component component, component. components components. composed compositional comprehended comprehensible computer-aided computer-l computer-like computer. computers. computing con con:firm concatenates conceivable conceptual concerning concludes conclusion, condi- condition. conducting conference conference, confh'm confi- confirmation conform confounded confounding connecting connection connection, connects cons conse- consequence consequtive considerable considerably consideration considerations considerations. considers consis- consistently constants constituent's constituents constitutes constrained, constructions constructions, constructions. consuming contalng content. contents. context, contextual continually continue. continues continuing contrast contributors: control controlled controversial, conveniently, conversa- conversation. conversational conversations conveys cooperation coordinates cording core corporate corpus. correctable corrected correction corrections correctly, correctly. correspond correspondences cost costly costs count- counterpart countries countries. cover craft crawlers crawls cre- create created. creation credit, credit-card-by cremental cri- cross-linguistic crosses crossing cues, curiosity. cus- cussed cussion customer'(which customer) customer-friendly customers customers. d'identification dal, dapest, dark database), database, databaser. databases databases. date. day day, dd dealing debug decade, decides decision deemed deep defeated define degree deliberate- delight demand demanding: demo demonstration den, dence deno dents depar- department, departure, depend. dependencies, dependencies; dependent. depending deriva- derivational derive descendant description. description; descriptions, desoxyribonucleic destination detail. details detects deterioration determine, development: device diacritics.) dialogue-based dialogue/discourse. dialogues', dication dictionaries dictionaries). didn't differ differed difference, differently difficult. difficulty dimension. direction. directly disadvantages, disambiguating disambiguator disconnects) discounts. discovered discrete discrimination discuss- discussed, disposal disregard distance distilla- distillations. distilling. distinctions, distinguish distinguishable distressing distributed distribution ditionally, dka dkte dle do. document, document. does, dog, domain). domain-driven domain: domain? dominant done, dou double douitta downloaded downloading drafted drawbacks drawbacks. drawn dressed driving dropping dtta dual duce dune' dwelling e.g., eMotion eMotion, eUer e_, ea ear earlier, earliest earns eas- easily, easy-to-implement easy. eating eceives eco- ecological ects/academie/1835.searchform.html: ed ed- ed? eded edge editing editors, editors. ef- effect. effective, effectiveness effectiveness. effects effi- efficiency. efficient efficient, effort, effort. efforts eighth eiichiro.sumita, ej ej%2f0601%2f0601019c.htm\"> elaborate elaborated elegant eliability elicit elied eliminate eliminates elliptical. els, else embarass- emotion, empirically, employs empty. en, en_, enable ence ences encod- encoded encouraged endeavor. engine) engineer engines, engines. engines: engines; english\", enhance enhances enhancing enjoy ensuring enter entered entetion entries, environ- environment. epending episode equally equests equivalent equivalents equivalents: er. erate erms error, error. errors). errors, errors. ers es essentially establish establishes estimation. esting etc.), etermine ett ety eval- evaluation. event(real,D), events. ever ever, evil exact exakt examine examining example): example-based example: examples. exceeding exceeds exceptions, executed execution. exist, exist. exists, exit, expansion, expectation experience, experiment, experiment. experimental experiments. expert expert's explain explains exploited explored export expressbussar expression, expressions, expressway ext extension extent, extra-system extracting extraction extraction. extracts extraneous e~ter f0601019c.htm\"> fSrslag fac- face face-to-face faces fail-soft failure failures failures. fall false. fan fashion, fast. fault favored-nation) favour fe- fear feasibil- feature, features, fect fect, fects feedback feedback. female female,\" females. feminine femti/em femton fer fere ference fetching fewer ff.cuni.cz fication ficult field. fig- file\\]. files. filing fille filtered. filtering finally, finds fine-tune fine-tuned fined finest finished, fire firm first. fix fixed fixed, fixes, fixing fly, fo focuses focusing follow- following: for? force forcing foreach forget form, formal formation formed forms forms). forms. fort found). frameworks free free, freedom freeing freely freer freeway fresh, friend friend. friendly fu- ful. full-blown full-fledged func- functional functionality funding. funds further. futile fy g gSra gSrna gSt gaar gamble gamla ganize gas gather gdr genders genders, genders. gener- general. generalisa- generality generic genitive) geography. ger ggirna gian gin girl, girl. given. glected glish/.../f global, glossary goal. gone) good. governing goyoukendeshouka gozaimasu gram. grammar, grammar-based. grammar. graramar, grateful greatest grew grounded grounding groups growing. grown gu guage, guages guarantees guess guideline guidelines: guistic g~ hOlm(N), hade hair. hajic@cs.jhu.edu half halld han- handle, handle. handle? happened har hav- he/she heater's heavily heavy heir hell help- helped helping hen her heuristic, heuristics heuristics, hey heya-ga hhr hideki.kashioka} hierarchy, high. highest highest. highway hiking hindrance history history, hj~lpsystem hk hk. holds holiday holm. hombre homonymous homonyms homonymy hone hort hostname hovedstad hover how-part how. howed however however. hric@barbora.m http://sunrain.net/r_ecdict http://www- http://www.ida.l http://www.mindspring.com/ http://www.readworld.com/translate.htm. http:llwww.clsp.jhu.edulws981projectslnlplreport. human-like human-made human-translated humans humor, hunt hur hut h~ir i!, i!~ ialogues, ian ic icon id=\"0007\"> id=\"00~\"> id=\"xxxx\"> ide ideal idealised ideas idek identification, identified identifies idi. ie ience ies iff ification ifjeune igen)) ignment ignored ignores iihh ike il- ilar illustra- illustrates illustration ily images, imits. immediately imperative implemented. implements implied important, importantly, impressive impressive. inability included includes inclusion income incomplete incompleteness incomprehen- inconveniences incorpo- incorporated incorporated. incorporates incorporating increasing incredible indebted indeed independently, index index. ines inese infer inflection information\" inguistics inhabitants. inherent inherently inheritance inheritance. initially initiated inkSp inked inn innumerable insight inspired instrument instrumental instrumental, insulted. intact intact, inte integrated intend intentions, intentions. inter-rater interest, interest. interested interfere interlocuter, interlocuters interlocuters. interlocutors internals international interpreter interpreting interrogation, interrogative interrup- interrupt interrupting interruption. interruptions interrupts intersection, intersection. intertwined, intervention. into- intonation intonation, intonation. intro- introduced introduces introductory intstalled intuitive. investigate involved ions ious ipant ipants, ique ir- irony irony, irrational irrelevant. irrespective is- is; isa isa(real,bus,A), isa(real,place,nidar), isa(real,program,tuc), isa(real,saturday,B), iscuss issue, istence it, itadakimasu itadakimasu\" itarget item items items: ities. itineraries itors. itself itself, itself. iu.se/~arnjo/kfb/dialoger.html iven ivers ix i~.~I i~: jaa jam\\[ jar~ jednoducho jednoduge jednodu~e jokes, journal ju judge jungle jungle, justified justifies kaado kappa kashioka} keeping keeps keyword/phrase keywords. know(whether,tuc,C,D), knowl- known, knows kudasai\" kunskaps- kurejitlo-kaado-deno kurejitto kurejitto-kaado-deno kvinnes k~4Vt l0 lJCAI-99 lO0 laboratory lag land langauges language\". langue large- large. largely lasted lat lat- late laughter lay-persons' lb~ick le.html\" le.html'. leading leads learn learning learns leave? leaves leaving lect left-to-right lemma lemma. lems length. lengths lengths. lesce lesson lessons letters level. lexi- lexicalized lexically lexicographers lexicon, lexicons. lgor licensing, lie lies life, like' like: likeley likes limitation limitations lines lines, lingual linguis- linguistically linguistics linguistics, linguistics. linje linked links' lion listening listing lit- liteness,\" literal literature, little lives. living lk) lm) loan. loca localized locally location log-linear logical logues long. longing looking lose loss lost. lot, low. lower- lowering ls) lse lsewhere, lt) luat lustrated l~ngfiirdsbussarna l~ngf~irdsbussarna m m65ete m6~ete ma- machine- machine. made, magazine mail mainframe mainland mains, maintains majority make-OBJ male male), males males. mally man-machine man. management, manages mance manipulation manner. manual manually. many-to-many mapped mapping mar marble marised marker markers. market, markup, markup. markups, masterpiece match. matched. matcher matches, matches: mathematics matic matically maximal mean meaningful meant. measure measuring mechanical medium, meet mellon memories memorize memory, menn ment\")), ment, ment. ments, ments: merits, met methodologies. methodology methods, methods; mfi~ete mid middle migrations mim.25 mindre mined minimal. minimize minimized minimum mining, ministration minutes mis-spellings, mismatching missed missed, misses mistake mistakenly mistranslations. mit mix mixed mization mjSlby mo- modal modal- modalities mode. model's modelling models, models. modes: modifications modifications. modifier-head modifies modify. module) modules: monly mono- mono-lingual months more. morphemic morphology motivations, mous, move, move- moved. movement. movements. moves moves, multi- multi-modality multiword, munication municator. mysterious, myth na naive nal name, named namely names). naming. nary. nates nation. native natura nature navigates nd ndgra nding ndnstans ndsta ndtt ne- near neces- necessari- necessity necessity. nection, need- needs, needs. negation). negative) negocios neighboring nej nepodafilo ness ness\" network, nevertheless newspaper nfim.25 nformation, ni nicative nidar nies nie} nilda@ida.liu.se, no-diff: no/bustuc/). nodes noise. noisy. noll nominal non-English- non-empty, non-parallel non-standard non-stop-word non-systematic none nonetheless nonexistent) nor- nord normal- normalize norwegian not, notation nothing notice noticed noun. noun; noun_phrase(X,VP,P), nouns, novel, now, nternational ntries nu null number\"))) number-so number. numerically. nya n~gra n~nting n~ra o*. o.f o_shiharai-wo o_shiharaininarimasu-ka oad obj obligatory observation: observations. observe, observed obstacles obtain. obtained, obtained. obtained: obtaining occasion, occasionally occured. ocial ocksd oclock. ocument oest ofA ofDiscourse, ofEnglish ofWeb ofa ofattributes off-line off-line, offers office' office', official ofmod- oh oheya-ga ok) okyakusamano oldness omething omitted once once, ond, onds, one's one- onegaishimasu onegaishirnasu ones). only. onset onto ontology oo opera- operating operational operator) operator.\" operators. opic, opinion opment opposed optimally, optimize optional options, options/descriptions. options: or, or- orac oracle, order. order; ordering organized original. originally orincorrect oshi- oshiharaininarimasu-ka otev~it.\" other's other), other. otherwise oughly oukeshimasu\" oun ous out, out. outcome outline outlined output, outputs over- over-all overcome overlap overview, oz p p(tls p(tls), pa- paa package. page, pages, pages. pages; pair, pair. paired pairing pairs, pairs; pand pands pant's pants. pany's paper). paperÃ¢â‚¬Â¢ paradiese paradise paragraph-long parailel parameter parameter. parking pars- parsed parses part? partial partially partic- participant participant, participants. partner. parts: party passed. passes passings past pat- path, pattern. pattern; paul_denisowski/cedict.html. pay-QUESTION paying payment payment,\" payment-OBJ pects peech penalized. penalties peo- people, per. perFoy percent percent. perfect. perfor- performace performance, performed. performing periods, perplexity personal persons phase phase, phone phone, phones photographs, photos phrase, phrase. phy, picked pieces pivot/target place: placed places places, placing plagues planned planning plans, plays ple's plete plural point, pointed points, polite, politeness, political pomoci: poor. poorer poorly popular popular. portability portable ported portion pos- pose posed posed. position positional positions possibilities possibility possibly post-editor powerful practice, pragmatics pre-described pre-recorded pre-requisite precision, precisions predi- predicates, prefer preferable preferably prefixes preliminarily prepare preposition prepositions prepositions, preprocessing preprocessing, present, presentation presented, presenting preserved. press) press. pressions pret price primarily principal principles priori, priority priority) proach probabilis- probabilities. probability, problems, problems. procedure. procedures proceeded proces- processed processes processing. processor. produces producing product, products, profit program. programmed programming programming. programs. project). prompts pronoun pronoun- pronoun-antecedent proper properties proportionally. proposals proposed, proposes propriately proprietary protection prototypical proven provide, provide. provided, provider provider, provider. proving provocated prudent publications published publishing publishing, pur- purchasing purely purpose. purposes pus. put puter) puter. qual- quality, quence queried queries, query: question-generation question. questions. quests quickly quickly: quired quit quit~stop ract raise rali.iro.umontreal.ca/ProjetSILC.en.html. rances ranging rank, rans ranslation, raphy rapidly rarely rated rational raw re re-enter re-translation. re-writing realistic rearranged reason. reasons, receipt receive received received. recognition. recognition: recognized recourse recovered recurring reduced reduced. referred referring refined refining reflects regerge. regular reject relations. relationships. relevance relevant, relevant. relies remains. remembers reminded remodelling, removes repair repeats report, reported reported). representation. representative representative- represented representing represents reproachable: reprogrammed request. requested requested, required. requirements. reseach research, research. researchers researchers, resecentrum resemble resolve resolved resources, respec- respect, respectively respectively, respond responding response, responses) responses, responses. rest restricted resulted results; retain retained retrieval: retrieved) returns, returns. revised rewrit- rewriting rich ridiculously ries rigorous rill rings rived rmat rms ro robust. robust: rocgnition role, role,\" roles. rom room-TOP rooms routed routes routes, routine rule-based rule-based, rules, run' running running. runs ry, ryly r~chio sSnda sSndagar sSndagen sStt sacrificing said. sale salient same: sample. samples, sampling sary sase~e satisfies satisfy save saving savings say, say. scale scanned. scans scheduled scheme sci-fi science scientific scope score, screen scribed searched searching season sec- second: section). security segmentation, self self-contained self-evident selva semantics, semantics. sematica/ly sen seng? senses ser- series servation servations. serve server. service. serving set. sets. setsuo.yarnada, settings. sh shaded shallow sharon.flank@emotion.com she sheer shift shiharai-wo shimashitaka shiteitadakemasu shopping short). short, shorter. shouchiitashimasita show. shows. sic side, sider sifted sig sig)) sign signals signed signifi- significantly similar. simpler. simplest simplicity simplification simplified simulated simulating simultaneously, single, singular, sion, sions, sis, sistent sites, situation situation) situation, situation-based sixhundred sju ski skole skulle slight smaller smoothly. so. soendag software, software. solitude solve solves some- somehow sometime somewhat somewhere sooner sophisticated. sor soredekekkoudesu sound sounds source/pivot sources. spatial speak- speakers, specially specification, specify speech, speech-based speech-to- spell spell- spelling spending spite splits spoken-language spond sponds spreading spring srel(on,time,B,E), srel(to,place,nidar,E),Y. ssentially stabilize stage stage, stand standard; standing stands: start start- start. stat- state\\], stated statement statement. statements, stating stations, statis- statistic. statistical, status stay/the stems, step, steps steps. stimulated stituent's stochastically stop-list. stops stopwords\" store stores story). strategic strategy, strax strengthen stricted strictly strong structs. structural strzalkowski, stu- students study study, study. stumbling style, sub-dialogues, sub-menus sub-segments submit submitting subphrases; subsequent subsequently substantial substantially substitution succursale such. sue. sufficient sufficient. suffixes, suffixes. suggest suggestion suggestions suggests suitable sults sum- sumita, summarize; summarized summer superfi- suppliers, support, supported supporting sure surfaced surprisingly surprisingly, surukotogadekimasu survey suzuki-Mr. suzuki-sama suzuki-sama\" suzuki-san suzuki-san.\" swered, syamada, symbol syntax, syntax. systematic syst~me s~na tables, tabular tached tactic tag). tagged tagger tagger) tagging; tags. tagsets. tained taking talked talks tannefors tanne~orsvSgen tant tant, tasks: tational tax tdg te team technology technology, telephone, telephone. tem' tem, tem. templates) tems, tence tences tences, tency, tend teness tense tep, terance terances terances). terances, terface terfaces teria, term terminology) tern, terrupted tersection. test. test:: tested, text) text, text-based texts). thanks thanksgiving that?. the(X). the, the- thejungle them\" them, themselves themselves. then, theory there) thesaurus. these, thirteen this. thm thor- thoroughly thrown. tical ticipants ticipants, ticket tickets, tie ties. til tilled time-table. time-tables time.) timeand/or timeout times timetables: tion\" tion, tional tionary) tionary, titles, titta tivations tively. tjuge tjugonie tl__I tle tment to-English to-Russian to. to_open. today. toeach token tolerated. tomer tonight too-low toother topic topic. topwords tor tors total total) tothe track. tracking, tractable. tracted tradeoff. trafficking train- training, tralia. transaction transaction. transferred. transformation translate. translated, translation) translation). translator. transportable traposition tration, traveled traveller travelling treated treating tree tree-structured tremendous tretti/em trettisju tretton tri tri-grams. tries. trieval trieval, trip trouble trying ts tuc tuple. tuples, tures tusen. tutoring tvd tv~hundrafjorton tv~hundratio two-types-of two. ty typ typ- type) type, types, types: typically, t~g t~t uation ukelsukemasu ukeshimasu uketsukeru.\" ules. umber, umontreal, un un-distilled uncommon under- undergo understands understood. undra undrar unexplored ungefgir ungrammatical union. unit, unit. university unless unlikely unnecessary unreliability unwieldy up-coming upper upport upported ur ures uring usability. usable usage. useful, useful. usefulness user) user). user- user-friendly user; users, usu- utilising utilized utters vSgar validity. values var- vari- variability variables. variant vat vehicle, veloping velopment verb. verb_complementsO(VC), verb_complementsO(VC). verb_phrase(X,VP). verbal verbs verify verifying versatility versation version. vetegatan vetegatan. via vice. vide vided vides viewpoint ville vironment visit vk@ufal.mff.cuni.cz vocabulary voice volume vytvhrat' v~kazov wa wagon wakarimasita wants was_not._possible waste wasted watashidomo-wa watashitachi-wa way, ways we, weakness weaknesses web. webmasters week. weights weights. well-designed were, whatever when-part whereas whichq(P) whichq(which(X)::P) while. whole whom whoseq(P) widespread wins. wisegb wishes with, with- with. with/without wizard woman's women word- word-by-word word-by-word, word-for- word-form words) work. workflow workshop world world. worse: worth, writing written. wrong, wrong. www. www.ep.liu.se x)\" x)) x), x, xicon. xperience xplain- xpressions xts. years yes/no your ypes ystem ystems, zena zodiaque {chen, {e, | } ~!~ ~\" ~$ ~'\" ~',1~ ~'~- ~, ~,, ~,-\\]'Ã‚Â¢~.. ~- ~4\\[- ~5rtisex ~:s~:: ~; ~<.~ ~J ~Sr ~\\[1.</H2> ~f~.,~ ~i ~ii ~ii~l! ~r ~r~n ~t Ã‚Â£ka? Ã‚Â°o* Ã‚Â°Ã‚Â° \":s-role \"Experiments \"Using \"donoyouni \"payment\" \"politeness.\" \"railway\" \"shiharai\" \"source \"uketsukeru\" $ $3: $5 $50 $7 $9 'System' 'cause 'systems' 'the (\"picture\"))) ((\"take\") (((source (((target ((Telefonisten ((y (1), (100% (120 (15s) (1987). (1995) (1996) (1999). (2 (25s) (2s) (4 (4s) (68 (70% (= (Dahlb~ck (May, (Nie (SIGIR96) (The (Wu, (and (but (cf. (description_word, (example: (examples: (hs) (indicated (of (operator (see (words (~ESILKO )) *~ --+ --~ 0002 0002. 0004 1\" 1, 10% 11) 11800 13 16 18 1988. 1990 1992. 1993, 1993; 1994). 1994. 1995. 1996) 1996), 1998) 1998, 1999), 1999, 2), 2.3 2.4 200 2000. 21 24-26, 28 29th 3.3 3.4 300 34 344 37 4). 4.1 4.2 42 44 580 5th 63% 6: 7, 70 70% 75 8,000 8000BUCKY, :cond :default) :h-gender :s-role :word-cond </A> </TrU> <A <B>Volume <H3>Principles <IMG <RTF <TITLE>Journal <TrU> AAAI ALIGN=R ATR Abst Allen, Also AltaVista, AltaVista: Alternatively, Alto, Anna Anonymous. Approach Architecture August Australia. Automatic B BACKGROUND=\".Jgif/pejbg.jpg\" BACKGROUND=-\". Berkeley, Beschreibung Biermann, Brown Brown, Bus Business C/M CHAT-80, COMECON CONTENT=\"zh\"> Cable Calculus Calif. California, Call Calls Canada, Center. Chinese- Chinese-English, Circuit-Fixit- Clause Communications Conc Conclusions Control Cradle Currently Czech. Dahlb/ick, Dahlb/ick. David Dekai Della Department Dept. Despite Dialogue. Donna Download Due Duke's Effect Effects Electronic English) European Eurospeech'99, Evaluating Event Every Ex- Examples Explizite Extraposition F F., F.C.N. Figures Flank Flank, French, Further General Geography Gilarranz, Give Gonzalo Grefenstette Grefenstette, H HKUST HTTP-EQUIV=\"Content-language\" HTrP-EQUIV=\"Content-type\" Haji6 Harman Hauspie's Hladk~t Hong Host Hungary. Hvilke I. ICSLP'98, IGHT> Image In: Inc. Intelligence Intelligent Interfaces. Is Isabelle, Its Jang Japanese. Jones J~ KB Kaufmann. Kelledy Knowledge Kong Kowalski Kurematsu L=CS_01>Pomoci Laboratory Ladies Language) Languages. Lars Let Linguis- Linguistic Linguistics Lost MA: MIT Mach Malostransk6 Many March Mark Maybury Mercer. Michel Model Montreal Moreover, Morgan Mr. Mu- Multi-Modal Multilingual Munich. NRL Naito Necessity Nidarvoll Nilsson Nor- Notes November Other Otherwise, Out Oz-studies P PC Page Pair Palo Par Part-of-speech, PartslD: Pascal Paul Philip Pierre Pietra, Please Polish Pragma, Praha Preamble> Preamble>...</RTF Press. Previous Probability Proceed- Processing Quigley Qvarfordt. Raw Rayner Re- Readings Redesigning Reichman, Republic, Retrieval?\" Ros~ S S13: Santa Scandi- Scandinavian Science Science, Search Second, Semantic Sharon. Shoppe Sidner, Simard Simard, Similar Singapore. Smeaton Spanish, Sparck Sprache Stanford Sumita Summary Switzerland. Symposium Systems, T. TABOR TEXT=\"#000000\" TRAINS TREC TREC6 TUC, Tab. Tagging Tannefors Teacher Teigen Textbearbeitung Thus, Tore Trans Typical U12: U2: USA Ugglegatan Understanding United University. Utterances VII, Variable Very Vetland, Vetland. Vladislav Voorhees W.; Wahlster, Web-collected Welcome What Wide Will Wiz- Wolfgang Workbench World Wu Wu. Yang Your ZZ Zurich, \\[to abbreviations ac- accents. accept accomplished accounted accuracy. accurate action, adaptable adaptation adapted af- affect affects afternoon again agents agreement aid aimed aims airline aiteiru aligning alignment, alignments. all, all. ally alogue alone, ambiguities an- analyse analyses analyzing ances and, and/or another, answered ap- appeared appears applications, approach, approaches approaches. ard argue arrangement. art articles aspect aspects assigned auto auto- automated automatische automobile, back backtracking. balls bangou-wo bank base, befolkning beginning behaves behaviour behind believe believe, below below. ber better. big black blue building business buss bussen c cable calculates calculus can, canned capability caption card careful categories cause cellular cess character-based children chine choices circumstances city clarify clas- clean clerk, clerk. code cognate cognates. col- collimator combination combinations commenting commonly communication. company company, comparable complement comput- computers concepts concern concerns condition connected constituent constitute constraints construct content contents context. continue contributions correct, correspondence counts covering cradle crawling creates criteria criteria. criterion. cross- customer), date daughter defined, demonstrate demonstrated den departure describing design. determines determining develop- dialogue, dic- dictation dictionary) dictionary-based dictionary. differences different, disadvantage disadvantages discard discourse. discusses discussing distillation. distortion do- domain, domain-dependent domain-related domains domains. donoyouni dr dramatically e earaches ed., editor, eftermidda elephant emerges, empty encoding end energy engineers ent environment error errors essential established estimated evaluates evaluating exam- examined example. existence exit expand exper- experiences experiments exploitation expres- express expression. expressions. extended extract f5 fSr factor fax features. female, fetch fifteen fifty figures file, filler. finally financial finding fine-grained fjorton fledged followed foreign foreign-language former forty four framework framework. from, front-end full- fully function funding future. generating generation go goals, goes golf good, grammars, grant greater grow guage. g~r hSr handles harai hard hdllplatsen hearer's hello helpful, hence heter heuristic heya hi hierarchy hierarchy. high-accuracy high-end his/her hit home home. honorific hosts hould hown hu- human- human-computer human. hunting ia identifying impact implausible implement impor- impression in. inadequate included, incorporate increase increasingly ind independent. indicated ine ings initial innan input, input. instantly intact. interact interacting interactive interstate introducing invested investigation involves ipants irrelevant ish ity ized) just kaimono-wo kinds kopplar kudasai languages) languages: latest latter lead learned leave lected legal lel lemmas lemmatization let's lieve like. likelihood line link linking links lions lite literature live loan logue. loneliness longest looks lost loves lus male\" male, manager manager. marbles markups matches matches) mation, measure, measured mention microphones). millioner minimal mis-recognized mod- mode modes modifying moment, mostly multi-term multimedia multiple-word n names, nary natu- navian ndings necessary, necessary. nere net never nformation ni-shurui-no nich. nine no-diff noisy ntnu. num- obstacle obvious occur of) off. offering okey ome on, on. once. one, ones online open operator, oping order, others out- overall page. painful paper. paral- partici- participants' particularly parts. passed pattern) patterns patterns. paying, perform. person. phases phenomena pitfalls places. plan plausible pleasures po- point. population pora pora. portant post-processing potential pre- pre-specified presented presents preserve pressing primary prob- proba- processor, produce production programs project. proposal pros prototype provid- public. purpose, puter query, querying rac ral ranked ranslation ranslations rare rates. re,erie. reach reading reason- rececentrum recent recognise recogniser recognize recognizer recognizes reducing reflect regarded regardless relationship relative relying remain remainder removing repairing repeat report representation requesting requirement resource respect restrict results, returns rid risk road role\" room roughly rules). run rychle said? same, saturday saw scan sd se- searches section, seem segmentation selected, selection sent sentence, sentences. separately service, services setting sexhundrasexti sexton shared shiharaimasu-ka sible sical signs simpler simply simulation single- situations situations, sixteen solar solution someone sometimes source. sources speak speakers speaking specialized split sponding spontaneous state statement(P) statement(Q) statistically stead stem. stituent stoerre stop-lists stopwords. stored string. strings strongly sub- subject submitted successful, sumption sundays supplement suppose supposed suujikan systems) t/f tag talking tance tapes. technique technology. telescope telescope. tell template, tems tends terminated terms. tests tests, text-to-speech that, that. thereby thesaurus think third threshold tic ticipant's tics, time-table tion. tions, tions. title today, too. took tool tools. top-ranked transactions transcription transferred transfers translation: translators transport treatment trettifem tried tries tuple ture twice typically u un- und underlying unigram until us- used, used. utilization utilizing utterance, valuable value values. varies varying vehicle ven verb, vi viable vise vs. vytv~i~et v~kazu wan ways, wearing web wegian whereby which, whoq(P) wires word) word, word-by-word: word-order words\" work, worse written xicon y, zoo ~.~ ~jorton ~ka \":pattern-cond \"Chinese \"participant's $5-U6 $5: $9: ' (\"payment\")) ((\"accept\") (((\"accept\") ((source (1997) (344 (AltaVista) (Fig. (Human) (V-CN) (c.f. (i.e. (such (the ,~ .... 12) 17 19 1991. 1998), 1999) 2.5 2000). 2M 3) 4) 4, 40 40% 40E 4: 5. 54 5: 7. 74 8 86%. 90% 96%, :pattern-cond </CENTER> </H3> </I> <B> <CENTER> <I> > Acknowledgements African Apart BGCOLOR=\"#ffffff\"> Based Both By Cambridge, Charles Consensical Czech, Dahlb~ick Definite Dictionary Distilling E. Ellen English-to-Japanese Eskenazi Expansion FOL File First Flycht-Eriksson Foster, French. From GE Gale Grammar If, Internet Introduction J JSnsson John L Langenscheidt, Lernout Literary LuperFoy Manager Master's Medical Mima Montreal, Montreal. More N Next, Nidar No Nordic Oz- PRAT-89 Park, Part Parts Pernilla PictureQuest. PictureQuest: Prague Prague. Project Re Recall Recognition Resecentrum Results Russian Ryd SIGIR Several Slovak. Smeaton, Spring Sunshine Sydney, TOM That Thus U8: URLs University, Users V. Vadstena Vol., Voorhees, W. WebTran Which Word Y Y) above, access act actions acts ad-hoc adjective adjectives age agent. aha aim aligned alignment. alignments along am amounts ample analysis. answers appear approximation are, are: arrival artificial as- ask assumption attempt automate aware balance base. boundary bread build businessman but, capacity capture carefully carpenter cars cat caused center center. central changing check checking clear communication compare compares complexity computes conclude concluded conditions conduct confidence considering consist consisting contribution corpus, corre- correctly country course, covered crawler. credit cur- currently customer, customer. data. definitions der derived det detail determined devel- develop development. di- dictio- discuss discussions diverse documents. d~ earlier eats effective employed empty, en- enabling encouraging engine enn ensure entry etc.). every exist exists expect expectations explicit explore extent extracted factors fair feel ferences file. filter first, focus follows follows: for. formalism frdn future gender, general, generally great handling having hearer hej helps here, here. highly his hope hours http huge hypothesis i.e., id=\"0000\"> id=\"0006\"> idea identical identify iment implementation impressions improvements independent indexed indicate intelligent interac- interfaces. interpretation. investigated issue issues. it. jaha juggler kan keyword kitchen knew larger last later. led left lexicons life ligger linguistic low mainly manually marked markup mation meaning meant measures ment method, method. microphone minor modified moment mother multiword my name. news noise non- note noted number, numbers ob- objects och office og old om on-line ones. parser, parser. part, part. participants, pattern, pd phenomenon phrases, piece playing politeness poor possible, power practical precison preferred preserves previous proceed process. products project, projects property prove providers pure purpose puts queries. query. r rabbit randomly rates reasonable reasonably recall. receives reduces regarding remaining rent require requires research respects responses retrieve retrieves roduct routing s. said second, seconds. see, seems seen segment segments selected. sen- sequences server serves set, seven shop show sim- similarity simplifies sixty size, smoothly so- software solved som something space specified speech-only started starting starts stay step stop stop-list structure, structures. success sunday system) system: ta table. tables tagging taining tasks, tems. ter testing text. texts, textual thank things thus, time. timetable training. transcribed transducing transfer-based transferring transla- translations, translations. tuned tuples typologically umbers unknown use. usual utilise utilised utter- utterances). valid validity variables verbs, view well. who will, wish wo wonder wood word-for-word worse. zodiac { ~'~ \"accept\" \"target $7: (%) (11 (1998). (8 (a (as (e.g. * -~ / 10 11 12 15 1996). 1997 1998). 1998; 1999; 2.1 2.2 2: 3.1 3.2 39 3: 5) 5, 50 6. 65% 68 80% 97, </HEAD> </TITLE> <BODY <HEAD> <HTML> <P> ==> => ACM AFM Acoustics, Aligning Annika Artificial Bill C. COMPAX CONTENT=\"text/html; Computing, Corpus Czech-to-Russian D Each English- Fido First, Furthermore, Haji~, How ICASSP Impression Institute JSnsson. Joe Journal K. Kwok L. Langenscheidt MFF Max Morphological Most Multimedia PTMiner Parser PartslD Precision References Russian. Signal Speech, Technology. Translator's U6: UK Workshop X Y. adopted advanced align- almost although ambiguous analysis, anchor apply as, asking assigns associated average basic believed bring buying captions. carried chosen cial collected collection comes companies complete computational conducted consider context criterion decided designed desired detailed developing dialogue. differ- direct discourse distillation divided document documentation down ears effect effort eft entire er etc.) existing expansion expecting explicitly exported external fact, ferent fields final fish follow fruit gap girl goals grammars greatly group handled hospital house id=\"0001\"> id=\"0002\"> id=\"0003\"> id=\"0004\"> id=\"0005\"> illustrate im- images. improve incorrect indicates individual interaction. interest la lated later length-based let levels logic longer lower makes making manner memory. men methods. non-projective normal not. nouns observe one. operator. option pairs. paper, percentage perform person phrases. picture place possible. preliminary probabilistic probable problem. proceeds processing productive program public purposes. pus p~ quality. questions ranks rate ratio red remains request requests retrieval, retrieval. role. roles rules. sasete se select semantically semantics sequence short side similar, site, site. six slightly smooth so-called sore speaker's special studies subset support techniques ten texts. thesis, thought tions to, translates try turned tween twenty uch under understand understanding union upon users' users. ut- violin wanted water woman word. works wrong xample young & (14 (2) (X (or (y ---> 1997). 1997; 1999). 4. 45 60 7 86% 90 </B> <Is> ? A. After Association Because C-E CLIR, Computer Data Development English-French Fig. G. German MjSlby New Nils No. P. Parallel Processing: Prolog Retrieval, Retrieval,\" S. Slavic Spanish Swedish TQL Technology They Type: U4: When Who Yes above. addition align application, application. architecture around asked assumed before best bigram body calls captions changes characters checked checks choice class close closed compared complex considered construction context-based database. de- deal depends description, design dialogues. dif- discussion domain. due during easy en engines entries. especially evaluate far few find forest form full get gets gives guidelines helpful hundred i.e. implemented including infor- information, inserted instance, interaction, interesting interface internal inverted jag kakunin le length lexicon limited lives me money multi-modal multimodal needs normally obtain operators options own par- part-of-speech people ple point points pragmatic preci- probability proposed rather reasons relatively remove response. result, results. right rule showed single sion site sites. specific standard successful synthesis tags taken task. technical terms thirty travel turn unseen us utterance. utterances, va well wide \" \"wo\" % 'n' (7 + --* 11\" 1993. 1996, 1: 2) 23 3. 80 95 <Seg AND Alan AltaVista Another C CHAT-80 CLIR. Chi- Cross-Language E-C Evaluation Finally, French IR IVR Jan M. Machine On PCB Polite: Primary R. Retrieval SQL Section Slovak Spoken TDMT TRADOS TUC Trondheim User While actual after agent allowing applications. appropriate available come corpora. corresponds coverage crawler created described describes descriptions difficult dis- documents domain-specific e.g. easier experiment extremely feature field files give hand, include instead known l&2, lack lexical likely lists local localization logue ly methods might mm model, modify modules must nese normalized) now per performed previously principle probably problem, process produced reasoning removed. retrieved robust s selected sense sentences, significant size small speaker stopwords structure structures sub-string syntax system's systems, table takes tem test thus till together top translating unique utterances. within (1 (1) (1999) (source 19-27 65 <HR> = Abstract Annual But Do Eng: Even F. Gloss: JSnsson, Query Score Some Source Speech Standard: University Web. above ad add added allow allows already ambiguity amount analysed applied approximately area automatic automatically base be- buses capabilities centers character confirm course d dia- disambiguation dog enough etc. evaluated exactly examples filler format fourteen gender glossaries goal going here higher informa- issues joint keywords level long medical mentioned model. needed new next off others, parsing pivot play please pro- proved re- really removed required result resulting sample station successfully tasks template th though trained translation, true why (for , 30 <META At BusTUC Meeting Since Systems accuracy action additional always answer barked? built call closely com- consists contain containing conversation corpora dictionary, distilled event expression extra-linguistic file frequent generated guage hash hat host image interfaces kind languages, machine models output outside over participants precision. present section sets simple string them. therefore train translator type types typical ule ules user's usually uttered verb version x) (in (target 1996. 2. 6 Although Arne Chinese-English Education HSQL International J. RUSLAN Text V> Wizard account actually alignment asks cannot case, certain changed contained de determine developed development dialogues, discussed either ex- features handle high images improved in- instance inter- key lation major match mining much necessary noun order page problems quality statistical still training useful user, variety words, words. : Computational IntrTran Japanese Lang. Linguistics, LinkSping Norwegian Research TrLang achieved advantage cases current data defined describe help information. lan- large look man matching module monolingual original participant's pp. question response second shows ska tested three user. whether ID One S> To Transfer U> assume called cor- correct difference done expressions fact five further general identification interaction intersection know language, languages. least names particular providing relevant say sentence spoken systems. want while whose 'system' 1999. E PictureQuest Table WordNet con- distilling du easily entries evaluation fragment good he is, name pair parser project provide quite real sites so social those trans- various 1) 1997. Natural according approach better bilingual common did expected figure given ja language. less polite provides reason recall route since system, telephone too translate translations yes 1998. CLIR Dialogue HTML These Using able addition, anguage found had many operator role syntactic sys- templates through time tion ( 4 As English-Chinese Example Our There algorithm database even f important ion knowledge list memory provided see way without 1 5 An Conference Translation another change computer domain grammar pairs paper performance phrase related rules task translation. up ) analysis case clerk description morphological often sentences should 0 Language System al., candidate contains corresponding cross-language does however, means o obtained search uses utterance 1. application first languages made main make out phrases several shown them 3 Information Therefore, al. query recognition service take very </s> However, following similar 2 Proceedings being like parts queries speech Web because between customer need precision texts work MT about different possible problem Ã¢â‚¬Â¢ both do example ing pattern retrieval semantic Czech all could set Chinese its l only any input no pages results text they <s AV DM I corpus their translated 20 target where would example, may Human been how system. users what 100 bad) i product these ~ Figure based bus source same when you If number utterances but systems use dialogues method part transfer et most there each were human such our words English model - dictionary (.) This parallel some t than two natural other into then word more using For at has if also used It A We one will user information language have or can dialogue . which In was this an it not from with by translation we system as be are on that for The in is and to a of the \n"
     ]
    }
   ],
   "source": [
    "CountAsc(\"Text_File.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rjdfcoodyZSl"
   },
   "source": [
    "## Task 10\n",
    "Write a function alter_Upper that prints the content in a way that the first line is in Upper case, second in lower case and so on.\n",
    "\n",
    "Example: \n",
    "I am Zenia\n",
    "I love painting\n",
    "I live in Pakistan\n",
    "\n",
    "Output:\n",
    "i am zenia\n",
    "I LOVE PAINTING\n",
    "i live in pakistan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9uG9Nid_ygSJ"
   },
   "outputs": [],
   "source": [
    "def alter_Upper(filename):\n",
    "\n",
    "    #Write your logic here\n",
    "    \n",
    "    file = open(filename,\"r\")\n",
    "    \n",
    "    # print line on odd and even index as upper and lower case respectively\n",
    "    for i,line in enumerate(file):\n",
    "        if i%2 ==0:\n",
    "            print(line.lower())\n",
    "        else:\n",
    "            print(line.upper())     \n",
    "    \n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "uxkfWjC6ymnd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bustuc - a natura l  l anguage bus  route  o rac le  \n",
      "\n",
      "TORE AMBLE \n",
      "\n",
      "dept. of computer and information science \n",
      "\n",
      "UNIVERSITY OF TRONDHEIM \n",
      "\n",
      "norway, n-7491 \n",
      "\n",
      "AMBLE@IDI, NTNU. NO \n",
      "\n",
      "abstract \n",
      "\n",
      "THE PAPER DESCRIBES A NATURAL ANGUAGE BASED EXPERT \n",
      "\n",
      "system route advisor for the public bus transport \n",
      "\n",
      "IN TRONDHEIM, NORWAY. THE SYSTEM IS AVAILABLE ON \n",
      "\n",
      "the internet,and has been intstalled at the bus com- \n",
      "\n",
      "PANY'S WEB SERVER SINCE THE BEGINNING OF 1999. THE \n",
      "\n",
      "system is bilingual, relying on an internal anguage \n",
      "\n",
      "INDEPENDENT LOGIC REPRESENTATION. \n",
      "\n",
      "1 introduct ion \n",
      "\n",
      "A NATURAL ANGUAGE INTERFACE TO A COMPUTER DATABASE \n",
      "\n",
      "provides users with the capability of obtaining in- \n",
      "\n",
      "FORMATION STORED IN THE DATABASE BY QUERYING THE \n",
      "\n",
      "system in a natural language (nl). with a natural \n",
      "\n",
      "LANGUAGE AS A MEANS OF COMMUNICATION WITH A COM- \n",
      "\n",
      "puter system, the users can make a question or a \n",
      "\n",
      "STATEMENT IN THE WAY THEY NORMALLY THINK ABOUT THE \n",
      "\n",
      "information being discussed, freeing them from hav- \n",
      "\n",
      "ING TO KNOW HOW THE COMPUTER STORES OR PROCESSES \n",
      "\n",
      "the information. \n",
      "\n",
      "THE PRESENT IMPLEMENTATION REPRESENTS A A MAJOR \n",
      "\n",
      "effort in bringing natural anguage into practical use. \n",
      "\n",
      "A SYSTEM IS DEVELOPED THAT CAN ANSWER QUERIES ABOUT \n",
      "\n",
      "bus routes, stated as natural language texts, and \n",
      "\n",
      "MADE PUBLIC THROUGH THE INTERNET WORLD WIDE WEB \n",
      "\n",
      "( http : //www. idi. ntnu. no/bustuc/). \n",
      "\n",
      "TRONDHEIM IS A SMALL CITY WITH A UNIVERSITY AND \n",
      "\n",
      "140000 inhabitants. its central bus systems has 42 \n",
      "\n",
      "BUS LINES, SERVING 590 STATIONS, WITH 1900 DEPAR- \n",
      "\n",
      "tures per day (in average). that gives approximately \n",
      "\n",
      "60000 SCHEDULED BUS STATION PASSINGS PER DAY, WHICH \n",
      "\n",
      "is somehow represented in the route data base. \n",
      "\n",
      "THE STARTING POINT IS TO AUTOMATE THE FUNCTION OF \n",
      "\n",
      "a route information agent. the following example \n",
      "\n",
      "OF A SYSTEM RESPONSE IS USING AN ACTUAL REQUEST OVER \n",
      "\n",
      "telephone to the local route information company: \n",
      "\n",
      "HI, I LIVE IN NIDARVOLL AND TONIGHT I \n",
      "\n",
      "must reach a train to oslo at 6 oclock. \n",
      "\n",
      "AND A TYPICAL ANSWER WOULD FOLLOW QUICKLY: \n",
      "\n",
      "bus number 54 passes by nidarvoll skole \n",
      "\n",
      "AT 1710 AND ARRIVES AT TRONDHEIM RAILWAY \n",
      "\n",
      "station at 1725. \n",
      "\n",
      "IN BETWEEN THE QUESTION AND THE ANSWER IS A PRO- \n",
      "\n",
      "cess of lexical analysis, syntax analysis, semantic \n",
      "\n",
      "ANALYSIS, PRAGMATIC REASONING AND DATABASE QUERY \n",
      "\n",
      "processing. \n",
      "\n",
      "ONE COULD ARGUE THAT THE INFORMATION CONTENT \n",
      "\n",
      "could be solved by an interrogation, whereby the \n",
      "\n",
      "CUSTOMER IS ASKED TO PRODUCE 4 ITEMS: S TA T ION  \n",
      "\n",
      "of departure, station of arrival, earliest \n",
      "\n",
      "DEPARTURE TIMEAND/OR LATEST ARRIVAL TIME. IT \n",
      "\n",
      "is a myth that natural language is a better way of \n",
      "\n",
      "COMMUNICATION BECAUSE IT IS \"NATURAL LANGUAGE\". \n",
      "\n",
      "the challenge is to prove by demonstration that \n",
      "\n",
      "AN NL SYSTEM CAN BE MADE THAT WILL BE PREFERRED \n",
      "\n",
      "to the interrogative mode. to do that, the system \n",
      "\n",
      "HAS TO BE CORRECT, USER FRIENDLY AND ALMOST COMPLETE \n",
      "\n",
      "within the actual domain. \n",
      "\n",
      "2 PREVIOUS EFFORTS, CHAT-80, \n",
      "\n",
      "prat-89 and hsql \n",
      "\n",
      "THE SYSTEM, CALLED BUSTUC IS BUILT UPON THE CLAS- \n",
      "\n",
      "sical system chat-80 (warren and pereira, 1982). \n",
      "\n",
      "CHAT-80 WAS A STATE OF THE ART NATURAL ANGUAGE SYS- \n",
      "\n",
      "tem that was impressive on its own merits, but also \n",
      "\n",
      "ESTABLISHED PROLOG AS A VIABLE AND COMPETITIVE LAN- \n",
      "\n",
      "guage for artificial intelligence in general. the sys- \n",
      "\n",
      "TEM WAS A BRILLIANT MASTERPIECE OF SOFTWARE, EFFICIENT \n",
      "\n",
      "and sophisticated. the natural anguage system was \n",
      "\n",
      "CONNECTED TO A SMALL QUERY SYSTEM FOR INTERNATIONAL \n",
      "\n",
      "geography. the following query could be analysed \n",
      "\n",
      "AND ANSWERED IN A SPLIT SECOND: \n",
      "\n",
      "which country bordering the mediterranean \n",
      "\n",
      "BORDERS A COUNTRY THAT IS BORDERED BY A \n",
      "\n",
      "country whose population exceeds the \n",
      "\n",
      "POPULATION OF INDIA? \n",
      "\n",
      "(the answer 'turkey' has become incorrect as \n",
      "\n",
      "TIME HAS PASSED. THE IRONY IS THAT GEOGRAPHY WAS \n",
      "\n",
      "chosen as a domain without time.) \n",
      "\n",
      "THE ABI!ITY TO ANSWER RIDICULOUSLY LONG QUERIES IS \n",
      "\n",
      "of course not the main goal. the main lesson is that \n",
      "\n",
      "COMPLEX SENTENCES ARE ANALYSED WITH A PROPER UNDER- \n",
      "\n",
      "standing without sacrificing efficiency. any superfi- \n",
      "\n",
      "CIAL PATTERN MATCHING TECHNIQUE WOULD PROVE FUTILE \n",
      "\n",
      "sooner or later. \n",
      "\n",
      "2.1 MAKING A NORWEGIAN CHAT-80, \n",
      "\n",
      "prat-89 \n",
      "\n",
      "AT THE UNIVERSITY OF TRONDHEIM (NTNU), TWO STU- \n",
      "\n",
      "dents made a norwegian version of chat-80,called \n",
      "\n",
      "PRAT-89 (TEIGEN AND VETLAND, 1988),(TEIGEN AND \n",
      "\n",
      "vetland, 1989). (also, a similar swedish project \n",
      "\n",
      "SNACK-85 WAS REPORTED). \n",
      "\n",
      "the dictionary was changed from english to nor- \n",
      "\n",
      "WEGIAN TOGETHER WITH NEW RULES FOR MORPHOLOGICAL \n",
      "\n",
      "analysis. the change of grammar from english to \n",
      "\n",
      "NORWEGIAN PROVED TO BE AMAZINGLY EASY. IT SHOWED \n",
      "\n",
      "that the langauges were more similar than one would \n",
      "\n",
      "BELIEVE, GIVEN THAT THE LANGUAGES ARE INCOMPREHEN- \n",
      "\n",
      "sible to each other's communities. \n",
      "\n",
      "AFTER CHANGING THE DICTIONARY AND GRARAMAR, THE \n",
      "\n",
      "following norwegian query about the same domain \n",
      "\n",
      "COULD BE ANSWERED CORRECTLY IN A FEW SECONDS. \n",
      "\n",
      "hvilke afrikanske land som hat en \n",
      "\n",
      "BEFOLKNING STOERRE ENN 3 MILLIONER \n",
      "\n",
      "og mindre enn 50 millioner og er nord \n",
      "\n",
      "FOR BOTSWANA OG OEST FOR LIBYA HAT EN \n",
      "\n",
      "hovedstad som hat en befolkning stoerre \n",
      "\n",
      "ENN 100 TUSEN. \n",
      "\n",
      "( a translation is beside the point o.f being a long \n",
      "\n",
      "QUERY IN NORWEGIAN.) \n",
      "\n",
      "2.2 hsql - help system for sql \n",
      "\n",
      "A NORDIC PROJECT HSQL (HELP SYSTEM FOR SQL) WAS \n",
      "\n",
      "accomplished in 1988-89 to make a joint nordic ef- \n",
      "\n",
      "FORT INTERFACES TO DATABASES. \n",
      "\n",
      "the hsql project was led by the swedish state \n",
      "\n",
      "BUREAU (STATSKONTORET), WITH PARTICIPANTS FROM SWE- \n",
      "\n",
      "den, denmark, finland and norway (amble et al., \n",
      "\n",
      "1990). THE AIM OF HSQL WAS TO BUILD A NATURAL \n",
      "\n",
      "language interface to sql databases for the scandi- \n",
      "\n",
      "NAVIAN LANGUAGES SWEDISH, DANISH AND NORWEGIAN. \n",
      "\n",
      "these languages are very similar, and the norwe- \n",
      "\n",
      "GIAN VERSION OF CHAT-80 WAS EASILY EXTENDED TO THE \n",
      "\n",
      "other scandinavian languages. instead of geogra- \n",
      "\n",
      "PHY, A MORE TYPICAL APPLICATION AREA WAS CHOSEN TO \n",
      "\n",
      "be a query system for hospital administration. we \n",
      "\n",
      "DECIDED TO TARGET AN SQL DATABASE OF A HOSPITAL AD- \n",
      "\n",
      "ministration which had been developed already. \n",
      "\n",
      "THE NEXT STEP WAS THEN TO CHANGE THE DOMAIN \n",
      "\n",
      "of discourse from geography to hospital adminis- \n",
      "\n",
      "TRATION, USING THE SAME KNOWLEDGE REPRESENTATION \n",
      "\n",
      "techniques used in chat-80. a semantic model of \n",
      "\n",
      "THIS DOMAIN WAS MADE, AND THEN IMPLEMENTED IN THE \n",
      "\n",
      "chat-80 framework. \n",
      "\n",
      "THE MODELLING TECHNIQUE THAT PROVED ADEQUATE \n",
      "\n",
      "was to use an extended entity relationship (er) \n",
      "\n",
      "MODEL WITH A CLASS (TYPE) HIERARCHY, ATTRIBUTES BE- \n",
      "\n",
      "longing to each class, single inheritance ofattributes \n",
      "\n",
      "AND RELATIONSHIPS. \n",
      "\n",
      "coupling the system to an sql database. \n",
      "\n",
      "AFTER THE REMODELLING, THE SYSTEM COULD ANSWER \n",
      "\n",
      "queries in \"scandinavian\" to an internal hospital \n",
      "\n",
      "DATABASE AS WELL AS CHAT-80 COULD ANSWER GEOG- \n",
      "\n",
      "raphy questions. hsql produced a prolog-like code \n",
      "\n",
      "FOL (FIRST ORDER LOGIC) FOR EXECUTION. A MAPPING \n",
      "\n",
      "from fol to the data base schema was defined, and \n",
      "\n",
      "A TRANSLATOR FROM FOL TO SQL WAS IMPLEMENTED. \n",
      "\n",
      "the example \n",
      "\n",
      "HVILKE MENN LIGGER I EN KVINNES SENG? \n",
      "\n",
      "(which men lie in a woman's bed? ) \n",
      "\n",
      "WOULD BE TRANSLATED RYLY INTO THE SQL QUERY: \n",
      "\n",
      "select distinct \n",
      "\n",
      "T3.NAME,TL.SEX,T2.REG_NO,T3.SEX, \n",
      "\n",
      "t4.reg_no,t4.bed_no,t5.hosp_no,t5.ward_no \n",
      "\n",
      "FROM PATIENT TI,OCCUPANCY T2,PATIENT T3, \n",
      "\n",
      "occupancy t4,ward t5 \n",
      "\n",
      "WHERE \n",
      "\n",
      "(tl.sex='f') and \n",
      "\n",
      "(T2.REG_NO=TL.REG_NO) AND \n",
      "\n",
      "(t3.sex='m') and \n",
      "\n",
      "(T4.REG_NO=T3.REG_NO) AND \n",
      "\n",
      "(t4.bed_no=t2.bed_no) and \n",
      "\n",
      "(T5.HOSP_NO=T4.HOSP_NO) AND \n",
      "\n",
      "(t5.ward_no=t4.ward_no) \n",
      "\n",
      "2.3 THE THE UNDERSTANDING COMPUTER \n",
      "\n",
      "the hsql was a valuable xperience in the effort \n",
      "\n",
      "TO MAKE TRANSPORTABLE NATURAL ANGUAGE INTERFACES. \n",
      "\n",
      "however, the underlying system chat-80 restricted \n",
      "\n",
      "THE FURTHER DEVELOPMENT. \n",
      "\n",
      "after the hsql project was finished, an inter- \n",
      "\n",
      "NAL RESEACH PROJECT TUC (THE UNDERSTANDING COM- \n",
      "\n",
      "puter) was initiated at ntnu to carry on the results \n",
      "\n",
      "FROM HSQL. THE PROJECT GOALS DIFFERED FROM THOSE OF \n",
      "\n",
      "hsql in a number of ways, and would not be con- \n",
      "\n",
      "CERNED WITH MULTIMEDIA INTERFACES . ON THE OTHER \n",
      "\n",
      "hand, portability and versatility were made central \n",
      "\n",
      "ISSUES CONCERNING THE GENERALITY OF THE LANGUAGE AND \n",
      "\n",
      "its applications. the research goals could be sum- \n",
      "\n",
      "MARISED AS TO \n",
      "\n",
      "Ã¢â‚¬Â¢ give computers an operational understanding \n",
      "\n",
      "OF NATURAL LANGUAGE. \n",
      "\n",
      "Ã¢â‚¬Â¢ build intelligent systems with natural language \n",
      "\n",
      "CAPABILITIES. \n",
      "\n",
      "Ã¢â‚¬Â¢ study common sense reasoning in natural an- \n",
      "\n",
      "GUAGE. \n",
      "\n",
      "a test criterion for the understanding capacity is \n",
      "\n",
      "THAT AFTER A SET OF DEFINITIONS IN A NATURALLY READ- \n",
      "\n",
      "able logic, nrl, the system's answer to queries in \n",
      "\n",
      "NRL SHOULD CONFORM TO THE ANSWERS OF AN IDEALISED \n",
      "\n",
      "rational agent. \n",
      "\n",
      "EVERY MAN THAT LIVES LOVES MARY. \n",
      "\n",
      "john is a man. john lives. \n",
      "\n",
      "WHO LOVES MARY? \n",
      "\n",
      "==> john \n",
      "\n",
      "NRL IS DEFINED IN A CLOSED CONTEXT. THUS IN- \n",
      "\n",
      "terfaces to other systems are in principle defined \n",
      "\n",
      "THROUGH SIMULATING THE ENVIRONMENT AS A DIALOGUE \n",
      "\n",
      "partner. \n",
      "\n",
      "TUC IS A PROTOTYPICAL NATURAL LANGUAGE PROCES- \n",
      "\n",
      "sor for english written in prolog. it is designed to \n",
      "\n",
      "BE A GENERAL PURPOSE EASILY ADAPTABLE NATURAL LAN- \n",
      "\n",
      "guage processor. it consists of a general grammar \n",
      "\n",
      "FOR A SUBSET OF ENGLISH, A SEMANTIC KNOWLEDGE BASE, \n",
      "\n",
      "and modules for interfaces to other interfaces like \n",
      "\n",
      "UNIX, SQL-DATABASES AND GENERAL TEXTUAL INFORMA- \n",
      "\n",
      "tion sources. \n",
      "\n",
      "2.4 THE  TABOR PROJECT \n",
      "\n",
      "it so happened that a universtity project was start- \n",
      "\n",
      "EDED IN 1996, CALLED TABOR ( \" SPEECH BASED USER \n",
      "\n",
      "interfaces and reasoning systems \"), with the aim of \n",
      "\n",
      "BUILDING AN AUTOMATIC PUBLIC TRANSPORT ROUTE ORACLE, \n",
      "\n",
      "available over the public telephone. at the onset of \n",
      "\n",
      "THE PROJECT, THE WORLD WIDE WEB WAS FRESH, AND NOT \n",
      "\n",
      "as widespread as today, and the telephone was still \n",
      "\n",
      "REGARDED AS THE MAIN SOURCE OF INFORMATION FOR THE \n",
      "\n",
      "public. \n",
      "\n",
      "SINCE THEN, THE INTERNET BECAME THE DOMINANT \n",
      "\n",
      "medium, and it is as likeley to find a computer with \n",
      "\n",
      "INTERNET CONNECTION, AS TO FIND A LOCAL BUSROUTE TABLE. \n",
      "\n",
      "( the consequtive wide spreading of cellular phones \n",
      "\n",
      "CHANGED THE PICTURE IN FAVOUR OF THE TELEPHONE, BUT \n",
      "\n",
      "that is another story). \n",
      "\n",
      "IT WAS DECIDED THAT A TEXT BASED INFORMATION SYS- \n",
      "\n",
      "tem should be built, regardless of the status of the \n",
      "\n",
      "SPEECH ROCGNITION AND SPEECH SYNTHESIS EFFORT, WHICH \n",
      "\n",
      "proved to lag behind after a while. \n",
      "\n",
      "THE BUSTUC SYSTEM \n",
      "\n",
      "the resulting system bustuc grew out as a natural \n",
      "\n",
      "APPLICATION OF TUC, AND AN ENGLISH PROTOTYPE COULD \n",
      "\n",
      "be built within a few months (bratseth, 1997). \n",
      "\n",
      "SINCE THE SUMMER 1996, THE PROTOTYPE WAS PUT \n",
      "\n",
      "onto the internet, and been developed and tested \n",
      "\n",
      "MORE OR LESS CONTINUALLY UNTIL TODAY. THE MOST IM- \n",
      "\n",
      "portant extension was that the system was made \n",
      "\n",
      "BILINGUAL (NORWEGIAN AND ENGLISH) DURING THE FALL \n",
      "\n",
      "1996. \n",
      "\n",
      "IN SPRING 1999, THE BUSTUC WAS FINALLY ADOPTED \n",
      "\n",
      "by the local bus company in trondheim ( a/s \n",
      "\n",
      "TRONDHEIM TRAFIKKSELSKAP), WHICH SET UP A SERVER ( \n",
      "\n",
      "a 300 mhz pc with linux). \n",
      "\n",
      "UNTIL TODAY, OVER 150.000 QUESTIONS HAVE BEEN AN- \n",
      "\n",
      "swered, and bustuc seems to stabilize and grow \n",
      "\n",
      "INCREASINGLY POPULAR. \n",
      "\n",
      "3 \n",
      "\n",
      "3 ANATOMY O F  THE  BUS  ROUTE  ORAC LE  \n",
      "\n",
      "the main components of the bus route information \n",
      "\n",
      "SYSTEMS ARE: \n",
      "\n",
      "Ã¢â‚¬Â¢ a parser system, consisting of a dictionary, a \n",
      "\n",
      "LEXICAL PROCESSOR, A GRAMMAR AND A PARSER. \n",
      "\n",
      "Ã¢â‚¬Â¢ a knowledge base (kb), divided into a semantic \n",
      "\n",
      "KB AND AN APPLICATION KB \n",
      "\n",
      "Ã¢â‚¬Â¢ a query processor, contalng a routing logic sys- \n",
      "\n",
      "TEM, AND A ROUTE DATA BASE. \n",
      "\n",
      "the system is bilingual and contains a double set \n",
      "\n",
      "OF DICTIONARY, MORPHOLOGY AND GRAMMAR. ACTUALLY, IT \n",
      "\n",
      "detects which language is most probable by count- \n",
      "\n",
      "ING THE NUMBER OF UNKNOWN WORDS RELATED TO EACH \n",
      "\n",
      "language, and acts accordingly. the grammars are \n",
      "\n",
      "SURPRISINGLY SIMILAR, BUT NO EFFORT IS MADE TO COA- \n",
      "\n",
      "lesce them. the norwegian grammar is slightly big- \n",
      "\n",
      "GER THAN THE ENGLISH GRAMMAR, MOSTLY BECAUSE IT IS \n",
      "\n",
      "more elaborated but also because norwegian allows \n",
      "\n",
      "A FREER WORD ORDER. \n",
      "\n",
      "3.1 features  of  bustuc \n",
      "\n",
      "FOR THE NORWEGIAN SYSTEMS, THE FIGURES GIVE AN IN- \n",
      "\n",
      "dication of the size of the domain: 420 nouns, 150 \n",
      "\n",
      "VERBS, 165 ADJECTIVES, 60 PREPOSITIONS, ETC. \n",
      "\n",
      "there are 1300 grammar ules ( 810 for english) \n",
      "\n",
      "ALTHOUGH ALF OF THE RULES ARE VERY LOW LEVEL. \n",
      "\n",
      "the semantic net described below contains about \n",
      "\n",
      "4000 ENTRIES. \n",
      "\n",
      "a big name table of 3050 names in addition to \n",
      "\n",
      "THE OFFICIAL STATION NAMES, IS REQUIRED TO CAPTURE THE \n",
      "\n",
      "variety of naming. a simple spell correction is a part \n",
      "\n",
      "OF THE SYSTEM ( ESSENTIALLY 1 CHARACTER ERRORS). \n",
      "\n",
      "the pragmatic reasoning is needed to translate the \n",
      "\n",
      "OUTPUT FROM THE PARSER TO A ROUTE DATABASE QUERY \n",
      "\n",
      "language . this is done by a production system \n",
      "\n",
      "CALLED PRAGMA, WHICH ACTS LIKE AN ADVANCED REWRIT- \n",
      "\n",
      "ing system with 580 rules. \n",
      "\n",
      "IN ADDITION, THERE IS ANOTHER ULE BASE FOR ACTUALLY \n",
      "\n",
      "generating the natural anguage answers (120 rules). \n",
      "\n",
      "THE SYSTEM IS MAINLY WRITTEN IN PROLOG (SICSTUS \n",
      "\n",
      "prolog 3.7), with some perl programs for the com- \n",
      "\n",
      "MUNICATION AND CGI-SCRIPTS. \n",
      "\n",
      "at the moment, there are about 35000 lines of \n",
      "\n",
      "PROGRAMMED PROLOG CODE (IN ADDITION TO ROUTE TABLES \n",
      "\n",
      "which are also in prolog). \n",
      "\n",
      "AVERAGE RESPONSE TIME IS USUALLY LESS THAN 2 SEC- \n",
      "\n",
      "onds, but there are queries that demand up to 10 \n",
      "\n",
      "SECONDS. \n",
      "\n",
      "the error rate for single, correct, complete and \n",
      "\n",
      "RELEVANT QUESTIONS IS ABOUT 2 PERCENT. \n",
      "\n",
      "3.2 the parser system \n",
      "\n",
      "THE GRAMMAR SYSTEM \n",
      "\n",
      "the grammar is based on a simple grammar for \n",
      "\n",
      "STATEMENTS, WHILE QUESTIONS AND COMMANDS ARE DE- \n",
      "\n",
      "rived by the use of movements. the grammar \n",
      "\n",
      "FORMALISM WHICH IS CALLED CONSENSICAL GRAMMAR, \n",
      "\n",
      "(context sensitive compositional grammar) is \n",
      "\n",
      "AN EASY TO USE VARIANT OF EXTRAPOSITION GRAMMAR \n",
      "\n",
      "(pereira and warren, 1980), which is a generalisa- \n",
      "\n",
      "TION OF DEFINITE CLAUSE GRAMMARS. COMPOSITIONAL \n",
      "\n",
      "grammar means that the semantics of a a phrase is \n",
      "\n",
      "COMPOSED OF THE SEMANTICS OF THE SUBPHRASES; THE BA- \n",
      "\n",
      "sic constituents being a form of verb complements. \n",
      "\n",
      "AS FOR EXTRAPOSITION GRAMMARS, A GRAMMAR IS TRANS- \n",
      "\n",
      "lated to definite clause grammars, and executed as \n",
      "\n",
      "SUCH. \n",
      "\n",
      "a characteristic syntactic expression in consen- \n",
      "\n",
      "SICAL GRAMMAR  MAY DEFINE AN INCOMPLETE CONSTRUCT \n",
      "\n",
      "in terms of a \"difference \" between complete con- \n",
      "\n",
      "STRUCTS. WHEN POSSIBLE, THE PARSER WILL USE THE SUB- \n",
      "\n",
      "tracted part in stead of reading from the input, after \n",
      "\n",
      "A GAP IF NECESSARY. THE EFFECT IS THE SAME AS FOR EX- \n",
      "\n",
      "traposition grammars, but the this format is more \n",
      "\n",
      "INTUITIVE. \n",
      "\n",
      "examples of grammar rules. \n",
      "\n",
      "WHICH IS ANALYSED AS \n",
      "\n",
      "for which x is it true that \n",
      "\n",
      "THE (X) PERSON HAS A DOG THAT BARKED? \n",
      "\n",
      "where the last line is analysed as a statement. \n",
      "\n",
      "MOVEMENT IS EASILY HANDLED IN CONSENSICAL GRAM- \n",
      "\n",
      "mar without making special phrase rules for each \n",
      "\n",
      "KIND OF MOVEMENT. THE FOLLOWING EXAMPLE SHOWS \n",
      "\n",
      "how tuc manages a variety of analyses using move- \n",
      "\n",
      "MENTS: \n",
      "\n",
      "max said bill thought \n",
      "\n",
      "JOE BELIEVED FIDO BARKED. \n",
      "\n",
      "who said bill thought \n",
      "\n",
      "JOE BELIEVED FIDO BARKED? ==> MAX \n",
      "\n",
      "who did max say thought \n",
      "\n",
      "JOE BELIEVED FIDO BARKED? ==> BILL \n",
      "\n",
      "statement(p) ---> \n",
      "\n",
      "NOUN_PHRASE(X,VP,P), \n",
      "\n",
      "verb_phrase(x,vp). \n",
      "\n",
      "STATEMENT(Q) ---> \n",
      "\n",
      "verb_complementso(vc), \n",
      "\n",
      "ZZ INITIAL OPTIONAL VERB COMPLEMENTS \n",
      "\n",
      "statement(q) -... \n",
      "\n",
      "VERB_COMPLEMENTSO(VC). \n",
      "\n",
      "zz may be inserted after a gap \n",
      "\n",
      "WHOSEQ(P) ---> Z WHOSE DOG BARKED? \n",
      "\n",
      "\\[whose\\], \n",
      "\n",
      "HOLM(N), \n",
      "\n",
      "whoq(p) - ~ without gap \n",
      "\n",
      "(\\[WHO\\],\\[HAS\\],\\[A\\],NOUN(N),\\[THAT\\]). \n",
      "\n",
      "whoq(p) ---> \n",
      "\n",
      "\\[WHO\\], \n",
      "\n",
      "whichq(p) - (\\[which\\],\\[person\\]). \n",
      "\n",
      "WHICHQ(WHICH(X)::P) ---> \n",
      "\n",
      "\\[which\\], \n",
      "\n",
      "STATEMENT(P) - THE(X). \n",
      "\n",
      "example: \n",
      "\n",
      "WHOSE DOG BARKED? \n",
      "\n",
      "is analysed as if the sentence had been \n",
      "\n",
      "WHO HAS A DOG THAT  BARKED? \n",
      "\n",
      "which is analysed as \n",
      "\n",
      "WHICH PERSON HAS A DOG THAT  BARKED? \n",
      "\n",
      "who did max say bill thought \n",
      "\n",
      "BELIEVED FIDO BARKED? ==> JOE \n",
      "\n",
      "the parser \n",
      "\n",
      "THE EXPERIENCES WITH CONSENSICAL GRAMMARS ARE A \n",
      "\n",
      "bit mixed however. the main problem is the parsing \n",
      "\n",
      "METHOD ITSELF, WHICH IS TOP DOWN WITH BACKTRACKING. \n",
      "\n",
      "many principles that would prove elegant for small \n",
      "\n",
      "DOMAINS TURNED OUT TO BE TOO COSTLY FOR LARGER DO- \n",
      "\n",
      "mains, due to the wide variety of modes of expres- \n",
      "\n",
      "SIONS, INCREDIBLE AMBIGUITIES AND THE SHEER SIZE OF THE \n",
      "\n",
      "covered language. \n",
      "\n",
      "THE DISAMBIGUATION IS A MAJOR PROBLEM FOR SMALL \n",
      "\n",
      "grammars and large languages, and was solved by \n",
      "\n",
      "THE FOLLOWING GUIDELINES: \n",
      "\n",
      "Ã¢â‚¬Â¢ a semantic type checking was integrated into the \n",
      "\n",
      "PARSER, AND WOULD HELP TO DISCARD SEMATICA/LY \n",
      "\n",
      "wrong parses from the start. \n",
      "\n",
      "Ã‚â‚¬Â¢ A HEURISTICS WAS FOLLOWED THAT PROVED ALMOST IR- \n",
      "\n",
      "reproachable: the longest possible phrase of a \n",
      "\n",
      "CATEGORY THAT IS SEMANTICALLY CORRECT IS IN MOST \n",
      "\n",
      "cases the preferred interpretation. \n",
      "\n",
      "Ã‚â‚¬Â¢ DUE TO THE PERPLEXITY OF THE LANGUAGE, SOME \n",
      "\n",
      "committed choices (cuts) had to be inserted into \n",
      "\n",
      "THE GRAMMAR AT STRATEGIC PLACES. AS ONE COULD \n",
      "\n",
      "fear however, this implied that wrong choices \n",
      "\n",
      "BEING MADE AT SOME POINT IN THE PARSING COULD \n",
      "\n",
      "not be recovered by backtracking. \n",
      "\n",
      "THESE PROBLEMS ALSO MADE IT IMPERATIVE TO INTRO- \n",
      "\n",
      "duce a timeout on the parsing process of embarass- \n",
      "\n",
      "ING 10 SECONDS. ALTHOUGH MOST SENTENCES, WOULD BE \n",
      "\n",
      "parsed within a second, some legal sentences ofmod- \n",
      "\n",
      "ERATE SIZE ACTUALLY NEED THIS TIME. \n",
      "\n",
      "4 \n",
      "\n",
      "3.3 THE SEMANTIC KNOWLEDGE BASE \n",
      "\n",
      "adaptability means that the system does not need \n",
      "\n",
      "TO BE REPROGRAMMED FOREACH NEW APPLICATION. \n",
      "\n",
      "the design principle of tuc is that most of the \n",
      "\n",
      "CHANGES ARE MADE IN A TABULAR SEMANTIC KNOWLEDGE \n",
      "\n",
      "base, while there is one general grammar and dictio- \n",
      "\n",
      "NARY. IN GENERAL, THE LOGIC IS GENERATED AUTOMATICALLY \n",
      "\n",
      "from the semantic knowledge base. \n",
      "\n",
      "THE NOUNS PLAY A KEY ROLE IN THE UNDERSTANDING \n",
      "\n",
      "part as they constitute the class or type hierarchy. \n",
      "\n",
      "NOUNS ARE DEFINED IN AN A-KIND-OF HIERARCHY. THE \n",
      "\n",
      "hierarchy is tree-structured with single inheritance. \n",
      "\n",
      "THE TOP LEVEL ALSO CONSTITUTE THE TOP LEVEL ONTOLOGY \n",
      "\n",
      "of tuc's world. \n",
      "\n",
      "IN FACT, A TYPE CHECK OF THE COMPLIANCES OF VERBS, \n",
      "\n",
      "nouns adjectives and prepositions i  not only neces- \n",
      "\n",
      "SARY FOR THE SEMANTIC PROCESSING BUT IS ESSENTIAL FOR \n",
      "\n",
      "the syntax analysis for the disambiguation aswell. \n",
      "\n",
      "IN TUC, THE LEGAL COMBINATIONS ARE CAREFULLY ASSEM- \n",
      "\n",
      "bled in the semantic network, which then serves a \n",
      "\n",
      "DUAL PURPOSE. \n",
      "\n",
      "these semantic definitions are necessary to allow \n",
      "\n",
      "FOR INSTANCE THE FOLLOWING SENTENCES \n",
      "\n",
      "the dog saw a man with a telescope. \n",
      "\n",
      "THE MAN SAW A DOG WITH A TELESCOPE. \n",
      "\n",
      "to be treated differently because with telescope \n",
      "\n",
      "MAY MODIFY THE NOUN MAN BUT NOT THE NOUN DOG, \n",
      "\n",
      "while with telescope modifies the verb see, re- \n",
      "\n",
      "STRICTED TO PERSON. \n",
      "\n",
      "3.4 the query processor \n",
      "\n",
      "EVENT CALCULUS \n",
      "\n",
      "the semantics of the phrases are built up by a kind \n",
      "\n",
      "OF VERB COMPLEMENTS, WHERE THE EVENT PLAY A CENTRAL \n",
      "\n",
      "role. \n",
      "\n",
      "THE TEXT IS TRANSLATED FROM NATURAL ANGUAGE INTO \n",
      "\n",
      "a form called tql (temporal query language/ \n",
      "\n",
      "TUC QUERY LANGUAGE) WHICH IS A FIRST ORDER EVENT \n",
      "\n",
      "calculus expression, a self contained expression con- \n",
      "\n",
      "TAINING THE LITERAL MEANING OF AN UTTERANCE. \n",
      "\n",
      "a formalism tql that was defined, inspired by \n",
      "\n",
      "THE EVENT CALCULUS BY KOWALSKI AND SERGOT (KOWAL- \n",
      "\n",
      "ski and sergot, 1986). \n",
      "\n",
      "THE TQL EXPRESSIONS CONSIST OF PREDICATES, FUNC- \n",
      "\n",
      "tions, constants and variables. the textual words \n",
      "\n",
      "OF NOUNS AND VERBS ARE TRANSLATED TO GENERIC PREDI- \n",
      "\n",
      "cates using the selected interpretation. the follow- \n",
      "\n",
      "ING QUESTION \n",
      "\n",
      "do you know whether the bus goes \n",
      "\n",
      "TO NIDAR ON SATURDAY ?\n",
      "\n",
      "would give the tql expression below. typically, \n",
      "\n",
      "THE NORWEGIAN EQUIVALENT \n",
      "\n",
      "vet du om bussen gaar \n",
      "\n",
      "TIL NIDAR PAA SOENDAG ? \n",
      "\n",
      "5 \n",
      "\n",
      "GIVES EXACTLY THE SAME CODE. \n",
      "\n",
      "test:: % \n",
      "\n",
      "ISA(REAL,PROGRAM,TUC), % \n",
      "\n",
      "isa(real,bus,a), % \n",
      "\n",
      "ISA(REAL,SATURDAY,B), % \n",
      "\n",
      "isa(real,place,nidar), % \n",
      "\n",
      "EVENT(REAL,D), % \n",
      "\n",
      "type of question \n",
      "\n",
      "TUC IS A PROGRAM \n",
      "\n",
      "a is a real bus \n",
      "\n",
      "B ISA SATURDAY \n",
      "\n",
      "nidar is a place \n",
      "\n",
      "D IS AN EVENT \n",
      "\n",
      "know(whether,tuc,c,d), y. c was known at d \n",
      "\n",
      "EVENT (C , E) , Y. E IS AN EVENT IN C \n",
      "\n",
      "action(go,e), y. the action of e is go \n",
      "\n",
      "ACTOR(A,E), Y. THE ACTOR OF E IS A \n",
      "\n",
      "srel(to,place,nidar,e),y. e is to nidar \n",
      "\n",
      "SREL(ON,TIME,B,E), Y, E IS ON THE SATURDAY B \n",
      "\n",
      "the event parameter plays an important role in \n",
      "\n",
      "THE SEMANTICS. IT IS USED FOR VARIOUS PURPOSES. THE \n",
      "\n",
      "most salient role is to identify a subset of time and \n",
      "\n",
      "SPACE IN WHICH AN ACTION OR EVENT OCCURED. BOTH THE \n",
      "\n",
      "actual time and space coordinates are connected to \n",
      "\n",
      "THE ACTIONS THROUGH THE EVENT PARAMETER. \n",
      "\n",
      "pragmatic reasoning \n",
      "\n",
      "THE TQL IS TRANSLATED TO A ROUTE DATABASE QUERY \n",
      "\n",
      "language (buslog) which is actually a prolog pro- \n",
      "\n",
      "GRAM. THIS IS DONE BY A PRODUCTION SYSTEM CALLED \n",
      "\n",
      "pragma, which acts like an advanced rewriting sys- \n",
      "\n",
      "TEM WITH 580 RULES. \n",
      "\n",
      "in addition, there is another rule base for actually \n",
      "\n",
      "GENERATING THE NATURAL LANGUAGE ANSWERS (120 RULES). \n",
      "\n",
      "4 conc lus ions  \n",
      "\n",
      "THE TUC APPROACH AS AS ITS GOAL TO AUTOMATE THE \n",
      "\n",
      "creation of new natural language interfaces for a well \n",
      "\n",
      "DEFINED SUBSET OF THE LANGUAGE AND WITH A MINIMUM \n",
      "\n",
      "of explicit programming. \n",
      "\n",
      "THE IMPLEMENTED SYSTEM HAS PROVED ITS WORTH, \n",
      "\n",
      "and is interesting if for no other reason. there is \n",
      "\n",
      "ALSO AN INCREASING INTEREST FROM OTHER BUS COMPA- \n",
      "\n",
      "nies and route information companies alike to get a \n",
      "\n",
      "SIMILAR SYSTEM FOR THEIR CUSTOMERS. \n",
      "\n",
      "further work remains to make the parser really \n",
      "\n",
      "EFFICIENT, AND MUCH WORK REMAINS TO MAKE THE LAN- \n",
      "\n",
      "guage coverage complete within reasonable imits. \n",
      "\n",
      "IT IS AN OPEN QUESTION WHETHER THE SYSTEM OF THIS \n",
      "\n",
      "kind will be a preferred way of offering information \n",
      "\n",
      "TO THE PUBLIC. \n",
      "\n",
      "if it is, it is a fair amount of work to make it a \n",
      "\n",
      "PORTABLE SYSTEM THAT CAN BE IMPLEMENTED LSEWHERE, \n",
      "\n",
      "also connecting various travelling agencies. \n",
      "\n",
      "IF NOT, IT WILL REMAIN A CURIOSITY. BUT ANYWAY, A\n",
      "\n",
      "system like this will be a contribution to the devel- \n",
      "\n",
      "OPMENT OF INTELLIGENT SYSTEMS. \n",
      "\n",
      "re ferences  \n",
      "\n",
      "TORE AMBLE, ERIK KNUDSEN, AARNO LEHTOLA, JAN \n",
      "\n",
      "ljungberg, and ole ravnholt. 1990. naturlig \n",
      "\n",
      "SPR~K OCH GRAFIK - NYA VSGAR INN I DATABASER. \n",
      "\n",
      "statskontoret. rapport om hsql, ett kunskaps- \n",
      "\n",
      "BASERET HJ~LPSYSTEM FSR SQL. \n",
      "\n",
      "jon s. bratseth. 1997. bustuc - a natural lan- \n",
      "\n",
      "GUAGE BUS TRAFFIC INFORMATIONS SYSTEM. MASTER'S \n",
      "\n",
      "thesis, the norwegian university of science and \n",
      "\n",
      "TECHNOLOGY. \n",
      "\n",
      "r. kowalski and m. sergot. 1986. a logic based \n",
      "\n",
      "CALCULUS OF EVENTS. NEW GENERATION COMPUTING, \n",
      "\n",
      "8(0):67-95. \n",
      "\n",
      "F.C.N. PEREIRA AND D.H.D. WARREN. 1980. DEFINITE \n",
      "\n",
      "clause grammar for language analysis. artificial \n",
      "\n",
      "INTELLIGENCE, 0(3). \n",
      "\n",
      "j. teigen and v. vetland. 1988. syntax analysis of \n",
      "\n",
      "NORWEGIAN LANGUAGE. TECHNICAL REPORT, THE NOR- \n",
      "\n",
      "wegian institute of technology. \n",
      "\n",
      "J. TEIGEN AND V. VETLAND. 1989. HANDLING REASON- \n",
      "\n",
      "able questions beyond \n",
      "\n",
      "THE LINGUISTIC AND CONCEPTUAL COVERAGE OF \n",
      "\n",
      "natural anguage interfaces. master's thesis, the \n",
      "\n",
      "NORWEGIAN INSTITUTE OF TECHNOLOGY. \n",
      "\n",
      "d.h.d warren and f.c.n. pereira. 1982. an effi- \n",
      "\n",
      "CIENT AND EASILY ADAPTABLE SYSTEM FOR INTERPRETING \n",
      "\n",
      "natural language queries. computational linguis- \n",
      "\n",
      "TICS, 8(3-4). \n",
      "\n",
      "6 \n",
      "\n",
      "MACHINE TRANSLATION OF VERY CLOSE LANGUAGES \n",
      "\n",
      "jan haji(~ \n",
      "\n",
      "COMPUTER SCIENCE DEPT. \n",
      "\n",
      "johns hopkins university \n",
      "\n",
      "3400 N. CHARLES ST., BALTIMORE, \n",
      "\n",
      "md 21218, usa \n",
      "\n",
      "HAJIC@CS.JHU.EDU \n",
      "\n",
      "jan hric \n",
      "\n",
      "KTI MFF UK \n",
      "\n",
      "malostransk6 nfim.25 \n",
      "\n",
      "PRAHA 1, CZECH REPUBLIC, 11800 \n",
      "\n",
      "hric@barbora.m ff.cuni.cz \n",
      "\n",
      "VLADISLAV KUBON \n",
      "\n",
      "ofal mff uk \n",
      "\n",
      "MALOSTRANSK6 MIM.25 \n",
      "\n",
      "praha 1, czech republic, 11800 \n",
      "\n",
      "VK@UFAL.MFF.CUNI.CZ \n",
      "\n",
      "abstract \n",
      "\n",
      "USING EXAMPLES OF THE TRANSFER-BASED MT \n",
      "\n",
      "system between czech and russian \n",
      "\n",
      "RUSLAN AND THE WORD-FOR-WORD MT SYSTEM \n",
      "\n",
      "with morphological disambiguation between \n",
      "\n",
      "CZECH AND SLOVAK (~ESILKO WE ARGUE THAT \n",
      "\n",
      "for really close languages it is possible to \n",
      "\n",
      "OBTAIN BETTER TRANSLATION QUALITY BY MEANS OF \n",
      "\n",
      "simpler methods. the problem of translation \n",
      "\n",
      "TO A GROUP OF TYPOLOGICALLY SIMILAR LANGUAGES \n",
      "\n",
      "using a pivot language is also discussed here. \n",
      "\n",
      "INTRODUCTION \n",
      "\n",
      "although the field of machine translation has a \n",
      "\n",
      "VERY LONG HISTORY, THE NUMBER OF REALLY SUCCESSFUL \n",
      "\n",
      "systems is not very impressive. most of the funds \n",
      "\n",
      "INVESTED INTO THE DEVELOPMENT OF VARIOUS MT \n",
      "\n",
      "systems have been wasted and have not \n",
      "\n",
      "STIMULATED A DEVELOPMENT OF TECHNIQUES WHICH \n",
      "\n",
      "would allow to translate at least technical texts \n",
      "\n",
      "FROM A CERTAIN LIMITED DOMAIN. THERE WERE, OF \n",
      "\n",
      "course, exceptions, which demonstrated that \n",
      "\n",
      "UNDER CERTAIN CONDITIONS IT IS POSSIBLE TO DEVELOP \n",
      "\n",
      "a system which will save money and efforts \n",
      "\n",
      "INVESTED INTO HUMAN TRANSLATION. THE MAIN REASON \n",
      "\n",
      "why the field of mt has not met the expectations \n",
      "\n",
      "OF SCI-FI LITERATURE, BUT ALSO THE EXPECTATIONS OF \n",
      "\n",
      "scientific community, is the complexity of the \n",
      "\n",
      "TASK ITSELF. A SUCCESSFUL AUTOMATIC TRANSLATION \n",
      "\n",
      "system requires an application of techniques from \n",
      "\n",
      "SEVERAL AREAS OF COMPUTATIONAL INGUISTICS \n",
      "\n",
      "(morphology, syntax, semantics, discourse \n",
      "\n",
      "ANALYSIS ETC.) AS A NECESSARY, BUT NOT A SUFFICIENT \n",
      "\n",
      "condition. the general opinion is that it is easier \n",
      "\n",
      "TO CREATE AN MT SYSTEM FOR A PAIR OF RELATED \n",
      "\n",
      "languages. in our contribution we would like to \n",
      "\n",
      "DEMONSTRATE HAT THIS ASSUMPTION HOLDS ONLY FOR \n",
      "\n",
      "really very closely related languages. \n",
      "\n",
      "1. CZECH-TO-RUSSIAN MT SYSTEM RUSLAN \n",
      "\n",
      "1.1 history \n",
      "\n",
      "THE FIRST ATTEMPT O VERIFY THE HYPOTHESIS THAT \n",
      "\n",
      "related languages are easier to translate started in \n",
      "\n",
      "MID 80S AT CHARLES UNIVERSITY IN PRAGUE. THE \n",
      "\n",
      "project was called ruslan and aimed at the \n",
      "\n",
      "TRANSLATION OF DOCUMENTATION I THE DOMAIN OF \n",
      "\n",
      "operating systems for mainframe computers. it \n",
      "\n",
      "WAS DEVELOPED IN COOPERATION WITH THE RESEARCH \n",
      "\n",
      "institute of mathematical machines in prague. at \n",
      "\n",
      "THAT TIME IN FORMER COMECON COUNTRIES IT WAS \n",
      "\n",
      "obligatory to translate any kind of documentation \n",
      "\n",
      "TO SUCH SYSTEMS INTO RUSSIAN. THE WORK ON THE \n",
      "\n",
      "czech-to-russian mt system ruslan (cf. oliva \n",
      "\n",
      "(1989)) STARTED IN 1985. IT WAS TERMINATED IN 1990 \n",
      "\n",
      "(with comecon gone) for the lack of funding. \n",
      "\n",
      "1.2 SYSTEM DESCRIPTION \n",
      "\n",
      "the system was rule-based, implemented in \n",
      "\n",
      "COLMERAUER'S Q-SYSTEMS. IT CONTAINED A FULL- \n",
      "\n",
      "fledged morphological and syntactic analysis of \n",
      "\n",
      "CZECH, A TRANSFER AND A SYNTACTIC AND \n",
      "\n",
      "morphological generation of russian. there was \n",
      "\n",
      "ALMOST NO TRANSFER AT THE BEGINNING OF THE PROJECT \n",
      "\n",
      "due to the assumption that both languages are \n",
      "\n",
      "SIMILAR TO THE EXTENT THAT DOES NOT REQUIRE ANY \n",
      "\n",
      "transfer phase at all. this assumption turned to be \n",
      "\n",
      "WRONG AND SEVERAL PHENOMENA WERE COVERED BY \n",
      "\n",
      "the transfer in the later stage of the project (for \n",
      "\n",
      "EXAMPLE THE TRANSLATION OF THE CZECH VERB \"B~\" \n",
      "\n",
      "\\[to be\\] into one of the three possible russian \n",
      "\n",
      "EQUIVALENTS: EMPTY FORM, THE FORM \"BYT6\" IN FUTURE \n",
      "\n",
      "7 \n",
      "\n",
      "TENSE AND THE VERB \"JAVLJAT6SJA\"; OR THE TRANSLATION \n",
      "\n",
      "of verbal negation). \n",
      "\n",
      "AT THE TIME WHEN THE WORK WAS TERMINATED IN \n",
      "\n",
      "1990, the system had a main translation \n",
      "\n",
      "DICTIONARY OF ABOUT 8000 WORDS, ACCOMPANIED BY \n",
      "\n",
      "so called transducing dictionary covering another \n",
      "\n",
      "2000 WORDS. THE TRANSDUCING DICTIONARY WAS \n",
      "\n",
      "based on the original idea described in kirschner \n",
      "\n",
      "(1987). IT AIMED AT THE EXPLOITATION OF THE FACT \n",
      "\n",
      "that technical terms are based (in a majority of \n",
      "\n",
      "EUROPEAN LANGUAGES) ON GREEK OR LATIN STEMS, \n",
      "\n",
      "adopted according to the particular derivational \n",
      "\n",
      "RULES OF THE GIVEN LANGUAGES. THIS FACT ALLOWS FOR \n",
      "\n",
      "the \"translation\" of technical terms by means of a \n",
      "\n",
      "DIRECT TRANSCRIPTION OF PRODUCTIVE NDINGS AND A \n",
      "\n",
      "slight (regular) adjustment of the spelling of the \n",
      "\n",
      "STEM. FOR EXAMPLE, THE ENGLISH WORDS \n",
      "\n",
      "localization and discrimination can be \n",
      "\n",
      "TRANSCRIBED INTO CZECH AS \"LOKALIZACE\" AND \n",
      "\n",
      "\"diskriminace\" with a productive nding -ation \n",
      "\n",
      "BEING TRANSCRIBED TO -ACE. IT WAS GENERALLY \n",
      "\n",
      "assumed that for the pair czech/russian the \n",
      "\n",
      "TRANSDUCING DICTIONARY WOULD BE ABLE TO PROFIT \n",
      "\n",
      "from a substantially greater number of productive \n",
      "\n",
      "RULES. THIS HYPOTHESIS PROVED TO BE WRONG, TOO \n",
      "\n",
      "(see b6mov~, kubofi (1990)). the set of \n",
      "\n",
      "PRODUCTIVE NDINGS FOR BOTH PAIRS (ENGLISH/CZECH, \n",
      "\n",
      "as developed for an earlier mt system from \n",
      "\n",
      "ENGLISH TO CZECH, AND CZECH/RUSSIAN) WAS VERY \n",
      "\n",
      "similar. \n",
      "\n",
      "THE EVALUATION OF RESULTS OF RUSLAN SHOWED \n",
      "\n",
      "that roughly 40% of input sentences were \n",
      "\n",
      "TRANSLATED CORRECTLY, ABOUT 40% WITH MINOR ERRORS \n",
      "\n",
      "correctable by a human post-editor and about \n",
      "\n",
      "20% OF THE INPUT REQUIRED SUBSTANTIAL EDITING OR \n",
      "\n",
      "re-translation. there were two main factors that \n",
      "\n",
      "CAUSED A DETERIORATION OF THE TRANSLATION. THE FIRST \n",
      "\n",
      "factor was the incompleteness of the main \n",
      "\n",
      "DICTIONARY OF THE SYSTEM. EVEN THOUGH THE SYSTEM \n",
      "\n",
      "contained a set of so-called fail-soft rules, whose \n",
      "\n",
      "TASK WAS TO HANDLE SUCH SITUATIONS, AN UNKNOWN \n",
      "\n",
      "word typically caused a failure of the module of  \n",
      "\n",
      "SYNTACTIC ANALYSIS, BECAUSE THE DICTIONARY ENTRIES \n",
      "\n",
      "contained - besides the translation equivalents \n",
      "\n",
      "AND MORPHOLOGICAL INFORMATION - VERY IMPORTANT \n",
      "\n",
      "syntactic information. \n",
      "\n",
      "THE SECOND FACTOR WAS THE MODULE OF SYNTACTIC \n",
      "\n",
      "analysis of czech. there were several reasons of \n",
      "\n",
      "PARSING FAILURES. APART FROM THE COMMON INABILITY \n",
      "\n",
      "of most rule-based formal grammars to cover a \n",
      "\n",
      "PARTICULAR NATURAL ANGUAGE TO THE FINEST DETAIL OF \n",
      "\n",
      "its syntax there were other problems. one of  them \n",
      "\n",
      "WAS THE EXISTENCE OF NON-PROJECTIVE CONSTRUCTIONS, \n",
      "\n",
      "which are quite common in czech even in \n",
      "\n",
      "RELATIVELY SHORT SENTENCES. EVEN THOUGH THEY \n",
      "\n",
      "account only for 1.7Ã¢Â°/'o f syntactic dependencies, \n",
      "\n",
      "EVERY THIRD CZECH SENTENCE CONTAINS AT LEAST ONE, \n",
      "\n",
      "and in a news corpus, we discovered as much as \n",
      "\n",
      "15 NON-PROJECTIVE DEPENDENCIES; SEE ALSO HAJI6 ET \n",
      "\n",
      "al. (1998). an example of a non-projective \n",
      "\n",
      "CONSTRUCTION IS \"SOUBOR SE NEPODAFILO OTEV~IT.\" \n",
      "\n",
      "\\[lit.: file refl. was_not._possible to_open. - it was \n",
      "\n",
      "NOT POSSIBLE TO OPEN THE FILE\\]. THE FORMALISM USED \n",
      "\n",
      "for the implementation (q-systems) was not meant \n",
      "\n",
      "TO HANDLE NON-PROJECTIVE CONSTRUCTIONS. ANOTHER \n",
      "\n",
      "source of trouble was the use of so-called \n",
      "\n",
      "SEMANTIC FEATURES. THESE FEATURES WERE BASED ON \n",
      "\n",
      "lexical semantics of individual words. their main \n",
      "\n",
      "TASK WAS TO SUPPORT A SEMANTICALLY PLAUSIBLE \n",
      "\n",
      "analysis and to block the implausible ones. it \n",
      "\n",
      "TURNED OUT THAT THE QUESTION OF IMPLAUSIBLE \n",
      "\n",
      "combinations of  semantic features is also more \n",
      "\n",
      "COMPLEX THAN IT WAS SUPPOSED TO BE. THE PRACTICAL \n",
      "\n",
      "outcome of the use of semantic features was a \n",
      "\n",
      "HIGHER ATIO OF PARSING FAILURES - SEMANTIC FEATURES \n",
      "\n",
      "often blocked a plausible analysis. for example, \n",
      "\n",
      "HUMAN LEXICOGRAPHERS A SIGNED THE VERB 'TO RUN' A \n",
      "\n",
      "semantic feature stating that only a noun with \n",
      "\n",
      "SEMANTIC FEATURES OF A HUMAN OR OTHER LIVING BEING \n",
      "\n",
      "may be assigned the role of subject of this verb. \n",
      "\n",
      "THE INPUT TEXT WAS HOWEVER FULL OF SENTENCES WITH \n",
      "\n",
      "'programs' or 'systems' running etc. it was of \n",
      "\n",
      "COURSE VERY EASY TO CORRECT HE SEMANTIC FEATURE IN \n",
      "\n",
      "the dictionary, but the problem was that there \n",
      "\n",
      "WERE FAR TOO MANY CORRECTIONS REQUIRED. \n",
      "\n",
      "on the other hand, the fact that both languages \n",
      "\n",
      "ALLOW A HIGH DEGREE OF WORD-ORDER FREEDOM \n",
      "\n",
      "accounted for a certain simplification of  the \n",
      "\n",
      "TRANSLATION PROCESS. THE GRAMMAR ELIED ON THE \n",
      "\n",
      "fact that there are only minor word-order \n",
      "\n",
      "DIFFERENCES BETWEEN CZECH AND RUSSIAN. \n",
      "\n",
      "1.3 lessons learned  f rom ruslan \n",
      "\n",
      "WE HAVE LEARNED SEVERAL LESSONS REGARDING THE MT \n",
      "\n",
      "of closely related languages: \n",
      "\n",
      "Ã‚â‚¬Â¢ THE TRANSFER-BASED APPROACH PROVIDES A \n",
      "\n",
      "similar quality of translation both for closely \n",
      "\n",
      "RELATED AND TYPOLOGICALLY DIFFERENT LANGUAGES \n",
      "\n",
      "Ã¢â‚¬Â¢ two main bottlenecks of full-fledged \n",
      "\n",
      "TRANSFER-BASED SYSTEMS ARE: \n",
      "\n",
      "8 \n",
      "\n",
      "- COMPLEXITY OF THE SYNTACTIC DICTIONARY \n",
      "\n",
      "- relative unreliability of the syntactic \n",
      "\n",
      "ANALYSIS OF THE SOURCE LANGUAGE \n",
      "\n",
      "even a relatively simple component \n",
      "\n",
      "(TRANSDUCING DICTIONARY) WAS EQUALLY COMPLEX \n",
      "\n",
      "for english-to-czech and czech-to-russian \n",
      "\n",
      "TRANSLATION \n",
      "\n",
      "limited text domains do not exist in real life, \n",
      "\n",
      "IT IS NECESSARY TO WORK WITH A HIGH COVERAGE \n",
      "\n",
      "dictionary at least for the source language. \n",
      "\n",
      "2. TRANSLATION AND LOCALIZATION \n",
      "\n",
      "2.1 a pivot language \n",
      "\n",
      "LOCALIZATION OF PRODUCTS AND THEIR DOCUMENTATION \n",
      "\n",
      "is a great problem for any company, which wants \n",
      "\n",
      "TO STRENGTHEN ITS POSITION ON FOREIGN LANGUAGE \n",
      "\n",
      "market, especially for companies producing \n",
      "\n",
      "VARIOUS KINDS OF  SOFTWARE. THE AMOUNTS OF TEXTS \n",
      "\n",
      "being localized are huge and the localization \n",
      "\n",
      "COSTS ARE HUGE AS WELL. \n",
      "\n",
      "it is quite clear that the localization from one \n",
      "\n",
      "SOURCE LANGUAGE TO SEVERAL TARGET LANGUAGES, \n",
      "\n",
      "which are typologically similar, but different \n",
      "\n",
      "FROM THE SOURCE LANGUAGE, IS A WASTE OF MONEY \n",
      "\n",
      "and effort. it is of course much easier to translate \n",
      "\n",
      "TEXTS FROM CZECH TO POLISH OR FROM RUSSIAN TO \n",
      "\n",
      "bulgarian than from english or german to any of \n",
      "\n",
      "THESE LANGUAGES. THERE ARE SEVERAL REASONS, WHY \n",
      "\n",
      "localization and translation is not being \n",
      "\n",
      "PERFORMED THROUGH SOME PIVOT LANGUAGE, \n",
      "\n",
      "representing a certain group of closely related \n",
      "\n",
      "LANGUAGES. APART FROM POLITICAL REASONS THE \n",
      "\n",
      "translation through a pivot language has several \n",
      "\n",
      "DRAWBACKS. THE MOST IMPORTANT ONE IS THE \n",
      "\n",
      "problem of the loss of translation quality. each \n",
      "\n",
      "TRANSLATION MAY TO A CERTAIN EXTENT SHIFT THE \n",
      "\n",
      "meaning of the translated text and thus each \n",
      "\n",
      "SUBSEQUENT TRANSLATION PROVIDES RESULTS MORE AND \n",
      "\n",
      "more different from the original. the second \n",
      "\n",
      "MOST IMPORTANT REASON IS THE LACK OF TRANSLATORS \n",
      "\n",
      "from the pivot to the target language, while this is \n",
      "\n",
      "USUALLY NO PROBLEM FOR THE TRANSLATION FROM THE \n",
      "\n",
      "source directly to the target language. \n",
      "\n",
      "2.2 TRANSLATION MEMORY IS THE KEY \n",
      "\n",
      "the main goal of this paper is to suggest how to \n",
      "\n",
      "OVERCOME THESE OBSTACLES BY MEANS OF A \n",
      "\n",
      "combination of an mt system with commercial \n",
      "\n",
      "MAHT (MACHINE-AIDED HUMAN TRANSLATION) \n",
      "\n",
      "systems. we have chosen the trados \n",
      "\n",
      "TRANSLATOR'S WORKBENCH AS A REPRESENTATIVE \n",
      "\n",
      "system of a class of these products, which can be \n",
      "\n",
      "CHARACTERIZED AS AN EXAMPLE-BASED TRANSLATION \n",
      "\n",
      "tools. ibm's translation manager and other \n",
      "\n",
      "PRODUCTS ALSO BELONG TO THIS CLASS. SUCH SYSTEMS \n",
      "\n",
      "uses so-called translation memory, which contains \n",
      "\n",
      "PAIRS OF PREVIOUSLY TRANSLATED SENTENCES FROM A \n",
      "\n",
      "source to a target language. when a human \n",
      "\n",
      "TRANSLATOR STARTS TRANSLATING A NEW SENTENCE, THE \n",
      "\n",
      "system tries to match the source with sentences \n",
      "\n",
      "ALREADY STORED IN THE TRANSLATION MEMORY. IF IT IS \n",
      "\n",
      "successful, it suggests the translation and the \n",
      "\n",
      "HUMAN TRANSLATOR DECIDES WHETHER TO USE IT, TO \n",
      "\n",
      "modify it or to reject it. \n",
      "\n",
      "THE SEGMENTATION F A TRANSLATION MEMORY IS A KEY \n",
      "\n",
      "feature for our system. the translation memory \n",
      "\n",
      "MAY BE EXPORTED INTO A TEXT FILE AND THUS ALLOWS \n",
      "\n",
      "easy manipulation with its content. let us suppose \n",
      "\n",
      "THAT WE HAVE AT OUR DISPOSAL TWO TRANSLATION \n",
      "\n",
      "memories - one human made for the source/pivot \n",
      "\n",
      "LANGUAGE PAIR AND THE OTHER CREATED BY AN MT \n",
      "\n",
      "system for the pivot/target language pair. the \n",
      "\n",
      "SUBSTITUTION OF SEGMENTS OF A PIVOT LANGUAGE BY \n",
      "\n",
      "the segments of a target language is then only a \n",
      "\n",
      "ROUTINE PROCEDURE. THE HUMAN TRANSLATOR \n",
      "\n",
      "translating from the source language to the target \n",
      "\n",
      "LANGUAGE THEN GETS A TRANSLATION MEMORY FOR THE \n",
      "\n",
      "required pair (source/target). the system of \n",
      "\n",
      "PENALTIES APPLIED IN TRADOS TRANSLATOR'S \n",
      "\n",
      "workbench (or a similar system) guarantees that if \n",
      "\n",
      "THERE IS ALREADY A HUMAN-MADE TRANSLATION PRESENT, \n",
      "\n",
      "then it gets higher priority than the translation \n",
      "\n",
      "OBTAINED AS A RESULT OF THE AUTOMATIC MT. THIS \n",
      "\n",
      "system solves both problems mentioned above - \n",
      "\n",
      "THE HUMAN TRANSLATORS FROM THE PIVOT TO THE TARGET \n",
      "\n",
      "language are not needed at all and the machine- \n",
      "\n",
      "MADE TRANSLATION MEMORY SERVES ONLY AS A \n",
      "\n",
      "resource supporting the direct human translation \n",
      "\n",
      "FROM THE SOURCE TO THE TARGET LANGUAGE. \n",
      "\n",
      "3. mach ine  t rans lat ion of  (very) closely \n",
      "\n",
      "RELATED SLAVIC LANGUAGES \n",
      "\n",
      "in the group of slavic languages, there are more \n",
      "\n",
      "CLOSELY RELATED LANGUAGES THAN CZECH AND RUSSIAN. \n",
      "\n",
      "apart from the pair of serbian and croatian \n",
      "\n",
      "LANGUAGES, WHICH ARE ALMOST IDENTICAL AND WERE \n",
      "\n",
      "9 \n",
      "\n",
      "CONSIDERED ONE LANGUAGE JUST A FEW YEARS AGO, THE \n",
      "\n",
      "most closely related languages in this group are \n",
      "\n",
      "CZECH AND SLOVAK. \n",
      "\n",
      "this fact has led us to an experiment with \n",
      "\n",
      "AUTOMATIC TRANSLATION BETWEEN CZECH AND SLOVAK. \n",
      "\n",
      "it was clear that application of a similar method \n",
      "\n",
      "TO THAT ONE USED IN THE SYSTEM RUSLAN WOULD \n",
      "\n",
      "lead to similar results. due to the closeness of \n",
      "\n",
      "BOTH LANGUAGES WE HAVE DECIDED TO APPLY A \n",
      "\n",
      "simpler method. our new system, (~esilko, \n",
      "\n",
      "AIMS AT A MAXIMAL EXPLOITATION OF THE SIMILARITY \n",
      "\n",
      "of both languages. the system uses the method of \n",
      "\n",
      "DIRECT WORD-FOR-WORD TRANSLATION, JUSTIFIED BY THE \n",
      "\n",
      "similarity of syntactic constructions of both \n",
      "\n",
      "LANGUAGES. \n",
      "\n",
      "although the system is currently being tested on \n",
      "\n",
      "TEXTS FROM THE DOMAIN OF DOCUMENTATION TO \n",
      "\n",
      "corporate information systems, it is not limited to \n",
      "\n",
      "ANY SPECIFIC DOMAIN. ITS PRIMARY TASK IS, HOWEVER, \n",
      "\n",
      "to provide support for translation and localization \n",
      "\n",
      "OF VARIOUS TECHNICAL TEXTS. \n",
      "\n",
      "3.1 system (~esilko \n",
      "\n",
      "THE GREATEST PROBLEM OF THE WORD-FOR-WORD \n",
      "\n",
      "translation approach (for languages with very \n",
      "\n",
      "SIMILAR SYNTAX AND WORD ORDER, BUT DIFFERENT \n",
      "\n",
      "morphological system) is the problem of \n",
      "\n",
      "MORPHOLOGICAL AMBIGUITY OF INDIVIDUAL WORD \n",
      "\n",
      "forms. the type of ambiguity is slightly different \n",
      "\n",
      "IN LANGUAGES WITH A RICH INFLECTION (MAJORITY OF \n",
      "\n",
      "slavic languages) and in languages which do not \n",
      "\n",
      "HAVE SUCH A WIDE VARIETY OF FORMS DERIVED FROM A \n",
      "\n",
      "single lemma. for example, in czech there are \n",
      "\n",
      "ONLY RARE CASES OF PART-OF-SPEECH AMBIGUITIES ( T~T \n",
      "\n",
      "\\[to stay/the state\\], zena \\[woman/chasing\\] or tri \n",
      "\n",
      "\\[THREE/RUB(IMPERATIVE)\\]), MUCH MORE FREQUENT IS \n",
      "\n",
      "the ambiguity of gender, number and case (for \n",
      "\n",
      "EXAMPLE, THE FORM OF THE ADJECTIVE JAM\\[ \\[SPRING\\] \n",
      "\n",
      "is 27-times ambiguous). the main problem is that \n",
      "\n",
      "EVEN THOUGH SEVERAL SLAVIC LANGUAGES HAVE THE \n",
      "\n",
      "same property as czech, the ambiguity is not \n",
      "\n",
      "PRESERVED. IT IS DISTRIBUTED IN A DIFFERENT MANNER \n",
      "\n",
      "and the \"form-for-form\" translation is not \n",
      "\n",
      "APPLICABLE. \n",
      "\n",
      "without he analysis of at least nominal groups it \n",
      "\n",
      "IS OFTEN VERY DIFFICULT TO SOLVE THIS PROBLEM, \n",
      "\n",
      "because for example the actual morphemic \n",
      "\n",
      "CATEGORIES OF ADJECTIVES ARE IN CZECH \n",
      "\n",
      "distinguishable only on the basis of gender, \n",
      "\n",
      "NUMBER AND CASE AGREEMENT BETWEEN AN ADJECTIVE \n",
      "\n",
      "and its governing noun. an alternative way to the \n",
      "\n",
      "SOLUTION OF THIS PROBLEM WAS THE APPLICATION OF A \n",
      "\n",
      "stochastically based morphological disambiguator \n",
      "\n",
      "(MORPHOLOGICAL TAGGER) FOR CZECH WHOSE SUCCESS \n",
      "\n",
      "rate is close to 92Ã¢Â°/'0. our system therefore consists \n",
      "\n",
      "OF THE FOLLOWING MODULES: \n",
      "\n",
      "1. import of the input from so-called 'empty' \n",
      "\n",
      "TRANSLATION MEMORY \n",
      "\n",
      "2. morphological analysis of czech \n",
      "\n",
      "3. MORPHOLOGICAL DISAMBIGUATION \n",
      "\n",
      "4. domain-related bilingual glossaries (incl. \n",
      "\n",
      "SINGLE- AND MULTIWORD TERMINOLOGY) \n",
      "\n",
      "5. general bilingual dictionary \n",
      "\n",
      "6. MORPHOLOGICAL SYNTHESIS OF SLOVAK \n",
      "\n",
      "7. export of the output o the original translation \n",
      "\n",
      "MEMORY \n",
      "\n",
      "letus now look in a more detail at the individual \n",
      "\n",
      "MODULES OF THE SYSTEM: \n",
      "\n",
      "ad 1. the input text is extracted out of a \n",
      "\n",
      "TRANSLATION MEMORY PREVIOUSLY EXPORTED INTO AN \n",
      "\n",
      "ascii file. the exported translation memory (of \n",
      "\n",
      "TRADOS) HAS A SGML-IIKE NOTATION WITH A \n",
      "\n",
      "relatively simple structure (cf. the following \n",
      "\n",
      "EXAMPLE): \n",
      "\n",
      "example 1. - a sample of the exported translation \n",
      "\n",
      "MEMORY \n",
      "\n",
      "<rtf preamble>...</rtf preamble> \n",
      "\n",
      "<TRU> \n",
      "\n",
      "<crd>23051999 \n",
      "\n",
      "<CRU>VK \n",
      "\n",
      "<seg l=cs_01>pomoci v~kazu ad-hoc m65ete \n",
      "\n",
      "RYCHLE A JEDNODUGE VYTV~I~ET REGERGE. \n",
      "\n",
      "<seg l=sk_01 >n/a \n",
      "\n",
      "</TRU> \n",
      "\n",
      "our system uses only the segments marked by \n",
      "\n",
      "<SEG L=CS_01>, WHICH CONTAIN ONE SOURCE \n",
      "\n",
      "language sentence ach, and <seg l=sk_01>, \n",
      "\n",
      "WHICH IS EMPTY AND WHICH WILL LATER CONTAIN THE \n",
      "\n",
      "same sentence translated into the target language \n",
      "\n",
      "BY CESILKO. \n",
      "\n",
      "ad 2. the morphological analysis of czech is \n",
      "\n",
      "BASED ON THE MORPHOLOGICAL DICTIONARY DEVELOPED \n",
      "\n",
      "by jan haji6 and hana skoumalov~i in 1988-99 \n",
      "\n",
      "(FOR LATEST DESCRIPTION, SEE HAJI~ (1998)). THE \n",
      "\n",
      "dictionary contains over 700 000 dictionary \n",
      "\n",
      "ENTRIES AND ITS TYPICAL COVERAGE VARIES BETWEEN \n",
      "\n",
      "10 \n",
      "\n",
      "99% (NOVELS) TO 95% (TECHNICAL TEXTS). THE \n",
      "\n",
      "morphological analysis uses the system of \n",
      "\n",
      "POSITIONAL TAGS WITH 15 POSITIONS (EACH \n",
      "\n",
      "morphological .category, such as part-of-speech, \n",
      "\n",
      "NUMBER, GENDER, CASE, ETC. HAS A FIXED, SINGLE- \n",
      "\n",
      "symbol place in the tag). \n",
      "\n",
      "EXAMPLE 2 - TAGS ASSIGNED TO THE WORD-FORM \n",
      "\n",
      "\"pomoci\" (help/by means of) \n",
      "\n",
      "POMOCI: \n",
      "\n",
      "nfp2 .... . .  a .... \\]nfs7 ...... a .... i r--2 . . . . . . . . . . .  \n",
      "\n",
      "WHERE : \n",
      "\n",
      "n - noun; r - preposition \n",
      "\n",
      "F - FEMININE GENDER \n",
      "\n",
      "s - singular, p - plural \n",
      "\n",
      "7, 2 - CASE (7 - INSTRUMENTAL, 2 - GENITIVE) \n",
      "\n",
      "a - affirmative (non negative) \n",
      "\n",
      "AD 3. THE MODULE OF MORPHOLOGICAL \n",
      "\n",
      "disambiguation is a key to the success of  the \n",
      "\n",
      "TRANSLATION. IT GETS AN AVERAGE NUMBER OF 3.58 \n",
      "\n",
      "tags per token (word form in text) as an input. \n",
      "\n",
      "THE TAGGING SYSTEM IS PURELY STATISTICAL, AND IT \n",
      "\n",
      "uses a log-linear model of probability distribution \n",
      "\n",
      "- SEE HAJI~, HLADKFI (1998). THE LEARNING IS BASED \n",
      "\n",
      "on a manually tagged corpus of czech texts \n",
      "\n",
      "(MOSTLY FROM THE GENERAL NEWSPAPER DOMAIN). \n",
      "\n",
      "the system learns contextual rules (features) \n",
      "\n",
      "AUTOMATICALLY AND ALSO AUTOMATICALLY DETERMINES \n",
      "\n",
      "feature weights. the average accuracy of tagging \n",
      "\n",
      "IS BETWEEN 91 AND 93% AND REMAINS THE SAME \n",
      "\n",
      "even for technical texts (if we disregard the \n",
      "\n",
      "UNKNOWN NAMES AND FOREIGN-LANGUAGE T RMS THAT \n",
      "\n",
      "are not ambiguous anyway). \n",
      "\n",
      "THE LEMMATIZATION IMMEDIATELY FOLLOWS TAGGING; \n",
      "\n",
      "it chooses the first lemma with a possible tag \n",
      "\n",
      "CORRESPONDING TO THE TAG SELECTED. DESPITE THIS \n",
      "\n",
      "simple lemmatization method, and also thanks to \n",
      "\n",
      "THE FACT THAT CZECH WORDS ARE RARELY AMBIGUOUS IN \n",
      "\n",
      "their part-of-speech, it works with an accuracy \n",
      "\n",
      "EXCEEDING 98%. \n",
      "\n",
      "ad 4. the domain-related bilingual glossaries \n",
      "\n",
      "CONTAIN PAIRS OF INDIVIDUAL WORDS AND PAIRS OF \n",
      "\n",
      "multiple-word terms. the glossaries are \n",
      "\n",
      "ORGANIZED INTO A HIERARCHY SPECIFIED BY THE USER; \n",
      "\n",
      "typically, the glossaries for the most specific \n",
      "\n",
      "DOMAIN ARE APPLIED FIRST. THERE IS ONE GENERAL \n",
      "\n",
      "matching rule for all levels of glossaries - the \n",
      "\n",
      "LONGEST MATCH WINS. \n",
      "\n",
      "the multiple-word terms are sequences of lemmas \n",
      "\n",
      "(NOT WORD FORMS). THIS STRUCTURE HAS SEVERAL \n",
      "\n",
      "advantages, among others it allows to minimize \n",
      "\n",
      "THE SIZE OF THE DICTIONARY AND ALSO, DUE TO THE \n",
      "\n",
      "simplicity of the structure, it allows modifications \n",
      "\n",
      "OF THE GLOSSARIES BY THE LINGUISTICALLY NAIVE USER. \n",
      "\n",
      "the necessary morphological information is \n",
      "\n",
      "INTRODUCED INTO THE DOMAIN-RELATED GLOSSARY IN AN \n",
      "\n",
      "off-line preprocessing stage, which does not \n",
      "\n",
      "REQUIRE USER INTERVENTION. THIS MAKES A BIG \n",
      "\n",
      "difference when compared to the ruslan \n",
      "\n",
      "CZECH-TO-RUSSIAN MT SYSTEM, WHEN EACH \n",
      "\n",
      "multiword dictionary entry cost about 30 minutes \n",
      "\n",
      "OF LINGUISTIC EXPERT'S TIME ON AVERAGE. \n",
      "\n",
      "ad 5. the main bilingual dictionary contains data \n",
      "\n",
      "NECESSARY FOR THE TRANSLATION OF  BOTH LEMMAS AND \n",
      "\n",
      "tags. the translation of tags (from the czech into \n",
      "\n",
      "THE SLOVAK MORPHOLOGICAL SYSTEM) IS NECESSARY, \n",
      "\n",
      "because due to the morphological differences both \n",
      "\n",
      "SYSTEMS USE CLOSE, BUT SLIGHTLY DIFFERENT TAGSETS. \n",
      "\n",
      "currently the system handles the 1:1 translation of \n",
      "\n",
      "TAGS (AND 2:2, 3:3, ETC.). DIFFERENT RATIO OF \n",
      "\n",
      "translation is very rare between czech and siovak, \n",
      "\n",
      "BUT NEVERTHELESS AN ADVANCED SYSTEM OF DICTIONARY \n",
      "\n",
      "items is under construction (for the translation 1:2, \n",
      "\n",
      "2:1 ETC.). IT IS QUITE INTERESTING THAT THE LEXICALLY \n",
      "\n",
      "homonymous words often preserve their \n",
      "\n",
      "HOMONYMY EVEN AFTER THE TRANSLATION, SO NO \n",
      "\n",
      "special treatment of homonyms is deemed \n",
      "\n",
      "NECESSARY. \n",
      "\n",
      "ad 6. the morphological synthesis of slovak is \n",
      "\n",
      "BASED ON A MONOLINGUAL DICTIONARY OF SIOVAK, \n",
      "\n",
      "developed by j.hric (1991-99), covering more \n",
      "\n",
      "THAN \\]00,000 DICTIONARY ENTRIES. THE COVERAGE OF \n",
      "\n",
      "the dictionary is not as high as of  the czech one, \n",
      "\n",
      "BUT IT IS STILL GROWING. IT AIMS AT A SIMILAR COVERAGE \n",
      "\n",
      "of slovak as we enjoy for czech. \n",
      "\n",
      "AD 7. THE EXPORT OF  THE OUTPUT OF THE SYSTEM \n",
      "\n",
      "(~esilko into the translation memory (of \n",
      "\n",
      "TRADOS TRANSLATOR'S WORKBENCH) AMOUNTS \n",
      "\n",
      "mainly to cleaning of all irrelevant sgml \n",
      "\n",
      "MARKERS. THE WHOLE RESULTING SLOVAK SENTENCE IS \n",
      "\n",
      "inserted into the appropriate location in the \n",
      "\n",
      "ORIGINAL TRANSLATION MEMORY FILE. THE FOLLOWING \n",
      "\n",
      "example also shows that the marker <cru> \n",
      "\n",
      "CONTAINS AN INFORMATION THAT THE TARGET LANGUAGE \n",
      "\n",
      "sentence was created by an mt system. \n",
      "\n",
      "11 \n",
      "\n",
      "example 3. -a  sample of the translation memory \n",
      "\n",
      "CONTAINING THE RESULTS OF MT \n",
      "\n",
      "<rtf preamble>...</rtf preamble> \n",
      "\n",
      "<TRU> \n",
      "\n",
      "<crd>23051999 \n",
      "\n",
      "<CRU>MT! \n",
      "\n",
      "<seg l=cs_01>pomoci v~kazu ad-hoc mfi~ete \n",
      "\n",
      "RYCHLE A JEDNODU~E VYTV~I~ET RE,ERIE. \n",
      "\n",
      "<seg l=sk_01>pomoci v~kazov ad-hoc m6~ete \n",
      "\n",
      "R~CHIO A JEDNODUCHO VYTVHRAT' RE,ERIE. \n",
      "\n",
      "</tru> \n",
      "\n",
      "3.2 EVALUATION OF RESULTS \n",
      "\n",
      "the problem how to evaluate results of automatic \n",
      "\n",
      "TRANSLATION IS VERY DIFFICULT. FOR THE EVALUATION OF \n",
      "\n",
      "our system we have exploited the close \n",
      "\n",
      "CONNECTION BETWEEN OUR SYSTEM AND THE \n",
      "\n",
      "trados translator's workbench. the method \n",
      "\n",
      "IS SIMPLE - THE HUMAN TRANSLATOR ECEIVES THE \n",
      "\n",
      "translation memory created by our system and \n",
      "\n",
      "TRANSLATES THE TEXT USING THIS MEMORY. THE \n",
      "\n",
      "translator is free to make any changes to the text \n",
      "\n",
      "PROPOSED BY THE TRANSLATION MEMORY. THE TARGET \n",
      "\n",
      "text created by a human translator is then \n",
      "\n",
      "COMPARED WITH THE TEXT CREATED BY THE MECHANICAL \n",
      "\n",
      "application of translation memory to the source \n",
      "\n",
      "TEXT. TRADOS THEN EVALUATES THE PERCENTAGE OF \n",
      "\n",
      "matching in the same manner as it normally \n",
      "\n",
      "EVALUATES THE PERCENTAGE OF MATCHING OF SOURCE \n",
      "\n",
      "text with sentences in translation memory. our \n",
      "\n",
      "SYSTEM ACHIEVED ABOUT 90% MATCH (AS DEFINED BY \n",
      "\n",
      "the trados match module) with the results of \n",
      "\n",
      "HUMAN TRANSLATION, BASED ON A RELATIVELY LARGE \n",
      "\n",
      "(more than 10,000 words) test sample. \n",
      "\n",
      "4. CONCLUSIONS \n",
      "\n",
      "the accuracy of the translation achieved by our \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SYSTEM JUSTIFIES THE HYPOTHESIS THAT WORD-FOR- \n",
      "\n",
      "word translation might be a solution for mt of \n",
      "\n",
      "REALLY CLOSELY RELATED LANGUAGES. THE REMAINING \n",
      "\n",
      "problems to be solved are problems with the one- \n",
      "\n",
      "TO MANY OR MANY-TO-MANY TRANSLATION, WHERE THE \n",
      "\n",
      "lack of information in glossaries and dictionaries \n",
      "\n",
      "SOMETIMES CAUSES AN UNNECESSARY TRANSLATION \n",
      "\n",
      "error. \n",
      "\n",
      "THE SUCCESS OF THE SYSTEM CESILKO HAS \n",
      "\n",
      "encouraged the investigation of the possibility to \n",
      "\n",
      "USE THE SAME METHOD FOR OTHER PAIRS OF SLAVIC \n",
      "\n",
      "languages, namely for czech-to-polish translation. \n",
      "\n",
      "ALTHOUGH THESE LANGUAGES ARE NOT SO SIMILAR AS \n",
      "\n",
      "czech and slovak, we hope that an addition of a \n",
      "\n",
      "SIMPLE PARTIAL NOUN PHRASE PARSING MIGHT PROVIDE \n",
      "\n",
      "results with the quality comparable to the full- \n",
      "\n",
      "FLEDGED SYNTACTIC ANALYSIS BASED SYSTEM RUSLAN \n",
      "\n",
      "(this is of course true also for the czechoto-slovak \n",
      "\n",
      "TRANSLATION). THE FIRST RESULTS OF CZECH-TO POLISH \n",
      "\n",
      "translation are quite encouraging in this respect, \n",
      "\n",
      "EVEN THOUGH WE COULD NOT PERFORM AS RIGOROUS \n",
      "\n",
      "testing as we did for slovak. \n",
      "\n",
      "ACKNOWLEDGEMENTS \n",
      "\n",
      "this project was supported by the grant gat~r \n",
      "\n",
      "405/96/K214 AND PARTIALLY BY THE GRANT GA(~R \n",
      "\n",
      "201/99/0236 and project of the ministry of \n",
      "\n",
      "EDUCATION NO. VS96151. \n",
      "\n",
      "references \n",
      "\n",
      "B6MOVFI, ALEVTINA AND KUBOFI, VLADISLAV (1990). CZECH- \n",
      "\n",
      "to-russian transducing dictionary; in: proceedings \n",
      "\n",
      "OF THE XLLLTH COLING CONFERENCE, HELSINKI 1990 \n",
      "\n",
      "haji~, jan (1998). building and using a syntactially \n",
      "\n",
      "ANNOTATED COPRUS: THE PRAGUE DEPENDENCY \n",
      "\n",
      "treebank. in: festschrifi for jarmila panevov~i, \n",
      "\n",
      "KAROLINUM PRESS, CHARLES UNIVERSITZ, PRAGUE. PP. \n",
      "\n",
      "106---132. \n",
      "\n",
      "HAJI~, JAN AND BARBORA HLADK~T (1998). TAGGING \n",
      "\n",
      "inflective languages. prediction of morphological \n",
      "\n",
      "CATEGORIES FOR A RICH, STRUCTURED TAGSET. ACL- \n",
      "\n",
      "coling'98, montreal, canada, august 1998, pp. 483- \n",
      "\n",
      "490. \n",
      "\n",
      "haji~, jan; brill, eric; collins, michael; hladk~t \n",
      "\n",
      "BARBORA; JONES, DOUGLAS; KUO, CYNTHIA; RAMSHAW, \n",
      "\n",
      "lance; schwartz, oren; tillman, christoph; and \n",
      "\n",
      "ZEMAN, DANIEL: CORE NATURAL LANGUAGE PROCESSING \n",
      "\n",
      "technology applicable to multiple languages. the \n",
      "\n",
      "WORKSHOP'98 FINAL REPORT. CLSP JHU. ALSO AT: \n",
      "\n",
      "http:llwww.clsp.jhu.edulws981projectslnlplreport. \n",
      "\n",
      "KIRSCHNER, ZDEN~K (1987). APAC3-2: AN ENGLISH-TO- \n",
      "\n",
      "czech machine translation system; explizite \n",
      "\n",
      "BESCHREIBUNG DER SPRACHE UND AUTOMATISCHE \n",
      "\n",
      "textbearbeitung xii1, mff uk prague \n",
      "\n",
      "OLIVA, KAREL (1989). A PARSER FOR CZECH IMPLEMENTED \n",
      "\n",
      "in systems q; explizite beschreibung der sprache \n",
      "\n",
      "UND AUTOMATISCHE TEXTBEARBEITUNG XVI, MFF UK \n",
      "\n",
      "prague \n",
      "\n",
      "12 \n",
      "\n",
      "abstract \n",
      "\n",
      "CROSS-LANGUAGE MULTIMEDIA INFORMATION RETRIEVAL \n",
      "\n",
      "sharon flank \n",
      "\n",
      "EMOTION, INC. \n",
      "\n",
      "2600 park tower dr., vienna, va 22180 usa \n",
      "\n",
      "SHARON.FLANK@EMOTION.COM \n",
      "\n",
      "simple measures can achieve high-accuracy \n",
      "\n",
      "CROSS-LANGUAGE R TRIEVAL IN CAREFULLY CHOSEN \n",
      "\n",
      "applications. image retrieval is one of those \n",
      "\n",
      "APPLICATIONS, WITH RESULTS RANGING FROM 68% \n",
      "\n",
      "of human translator performance for \n",
      "\n",
      "GERMAN, TO 100% FOR FRENCH. \n",
      "\n",
      "1 introduction \n",
      "\n",
      "CONTAIN STRINGS OF KEYWORDS. TYPICAL QUERIES \n",
      "\n",
      "are, as in most web search applications, two \n",
      "\n",
      "TO THREE WORDS IN LENGTH. AT THIS POINT, ALL OF \n",
      "\n",
      "the captions are in english. emotion hosts a \n",
      "\n",
      "LARGE DATABASE OF IMAGES FOR SALE AND FOR \n",
      "\n",
      "licensing, picturequest. at least 10% of \n",
      "\n",
      "PICTUREQUEST'S USER BASE IS OUTSIDE THE \n",
      "\n",
      "united states. the tests were performed on \n",
      "\n",
      "THE PICTUREQUEST DATABASE OF APPROXIMATELY \n",
      "\n",
      "400,000 images. \n",
      "\n",
      "INFORMATION IS INCREASINGLY GLOBAL, AND THE \n",
      "\n",
      "need to access it crosses language barriers. \n",
      "\n",
      "THE TOPIC OF THIS PAPER, CROSS-LANGUAGE \n",
      "\n",
      "information retrieval, concerns the automatic \n",
      "\n",
      "RETRIEVAL OF TEXT IN ONE LANGUAGE VIA A QUERY \n",
      "\n",
      "in a different language. a considerable \n",
      "\n",
      "BODY OF LITERATURE HAS GROWN UP AROUND \n",
      "\n",
      "cross-language information retrieval (e.g. \n",
      "\n",
      "GREFENSTETTE 1998, TREC-7 1999). THERE \n",
      "\n",
      "are two basic approaches. either the query \n",
      "\n",
      "CAN BE TRANSLATED, OR EACH ENTIRE DOCUMENT \n",
      "\n",
      "can be translated into the same language as \n",
      "\n",
      "THE QUERY. THE ACCURACY OF RETRIEVAL ACROSS \n",
      "\n",
      "languages, however, is generally not good. \n",
      "\n",
      "ONE OF THE WEAKNESSES THAT PLAGUES CROSS- \n",
      "\n",
      "language retrieval is that we do not have a \n",
      "\n",
      "GOOD SENSE OF WHO THE USERS ARE, OR HOW BEST \n",
      "\n",
      "to interact with them. \n",
      "\n",
      "IN THIS PAPER WE DESCRIBE A MULTIMEDIA \n",
      "\n",
      "application for which cross-language \n",
      "\n",
      "INFORMATION RETRIEVAL WORKS PARTICULARLY \n",
      "\n",
      "well. emotion, inc. has developed a natural \n",
      "\n",
      "LANGUAGE INFORMATION RETRIEVAL APPLICATION \n",
      "\n",
      "that retrieves images, such as photographs, \n",
      "\n",
      "BASED ON SHORT TEXTUAL DESCRIPTIONS OR \n",
      "\n",
      "captions. the captions are typically one to \n",
      "\n",
      "THREE SENTENCES, ALTHOUGH THEY MAY ALSO \n",
      "\n",
      "recent web utilization data for picturequest \n",
      "\n",
      "INDICATE THAT OF THE 10% OF USERS FROM \n",
      "\n",
      "outside the united states, a significant \n",
      "\n",
      "PORTION COME FROM SPANISH-SPEAKING, \n",
      "\n",
      "french-speaking, and german-speaking \n",
      "\n",
      "COUNTRIES. IT IS EXPECTED THAT ADDING \n",
      "\n",
      "appropriate language interfaces and listing \n",
      "\n",
      "PICTUREQUEST IN FOREIGN-LANGUAGE SEARCH \n",
      "\n",
      "engines will dramatically increase non- \n",
      "\n",
      "ENGLISH USAGE. \n",
      "\n",
      "the cross-language multimedia \n",
      "\n",
      "RETRIEVAL APPLICATION \n",
      "\n",
      "this paper offers several original \n",
      "\n",
      "CONTRIBUTIONS TO THE LITERATURE ON CROSS- \n",
      "\n",
      "language information retrieval. first, the \n",
      "\n",
      "CHOICE OF APPLICATION IS NOVEL, AND \n",
      "\n",
      "significant because it simplifies the language \n",
      "\n",
      "PROBLEM ENOUGH TO MAKE IT TRACTABLE. \n",
      "\n",
      "because the objects retrieved are images and \n",
      "\n",
      "NOT TEXT, THEY ARE INSTANTLY COMPREHENSIBLE \n",
      "\n",
      "to the user regardless of language issues. \n",
      "\n",
      "THIS FACT MAKES IT POSSIBLE FOR USERS TO \n",
      "\n",
      "perform a relevance assessment without he \n",
      "\n",
      "NEED FOR ANY KIND OF TRANSLATION. MORE \n",
      "\n",
      "important, users themselves can select \n",
      "\n",
      "OBJECTS OF INTEREST, WITHOUT RECOURSE TO \n",
      "\n",
      "translation. the images are, in fact, \n",
      "\n",
      "13 \n",
      "\n",
      "associated with caption information, but, \n",
      "\n",
      "EVEN IN THE MONOLINGUAL SYSTEM, FEW USERS \n",
      "\n",
      "ever even view the captions. it should be \n",
      "\n",
      "NOTED THAT MOST OF THE IMAGES IN \n",
      "\n",
      "picturequest are utilized for advertising and \n",
      "\n",
      "PUBLISHING, RATHER THAN FOR NEWS \n",
      "\n",
      "applications. users of history and news \n",
      "\n",
      "PHOTOS DO TEND TO CHECK THE CAPTIONS, AND \n",
      "\n",
      "often users in publishing will view the \n",
      "\n",
      "CAPTIONS. FOR ADVERTISING, HOWEVER, WHAT THE \n",
      "\n",
      "image itself conveys is far more important \n",
      "\n",
      "THAN THE CIRCUMSTANCES UNDER WHICH IT WAS \n",
      "\n",
      "created. \n",
      "\n",
      "ANOTHER SIGNIFICANT CONTRIBUTION OF THIS \n",
      "\n",
      "paper is the inclusion of a variety of \n",
      "\n",
      "MACHINE TRANSLATION SYSTEMS. NONE OF THE \n",
      "\n",
      "systems tested is a high-end machine \n",
      "\n",
      "TRANSLATION SYSTEM: ALL ARE FREELY AVAILABLE ON \n",
      "\n",
      "the web. \n",
      "\n",
      "ANOTHER KEY FEATURE OF THIS PAPER IS THE \n",
      "\n",
      "careful selection of an accuracy measure \n",
      "\n",
      "APPROPRIATE TO THE CIRCUMSTANCES OF THE \n",
      "\n",
      "application. the standard measure, percent \n",
      "\n",
      "OF MONOLINGUAL PERFORMANCE ACHIEVED, IS \n",
      "\n",
      "used, with a firm focus on precision. in this \n",
      "\n",
      "APPLICATION, USERS ARE ABLE TO EVALUATE ONLY \n",
      "\n",
      "what they see, and generally have no idea \n",
      "\n",
      "WHAT ELSE IS PRESENT IN THE COLLECTION. AS A \n",
      "\n",
      "result, precision is of far more interest o \n",
      "\n",
      "CUSTOMERS THAN RECALL. RECALL IS, HOWEVER, OF \n",
      "\n",
      "interest to image suppliers, and in any case it \n",
      "\n",
      "WOULD NOT BE PRUDENT TO OPTIMIZE FOR \n",
      "\n",
      "precision without taking into account the \n",
      "\n",
      "RECALL TRADEOFF. \n",
      "\n",
      "the picturequest application avoids several \n",
      "\n",
      "OF THE MAJOR STUMBLING BLOCKS THAT STAND IN \n",
      "\n",
      "the way of high-accuracy cross-language \n",
      "\n",
      "RETRIEVAL. BALLESTEROS AND CROFT (1997) NOTE \n",
      "\n",
      "several pitfalls common to cross-language \n",
      "\n",
      "INFORMATION RETRIEVAL: \n",
      "\n",
      "(1) the dictionary may not contain \n",
      "\n",
      "SPECIALIZED VOCABULARY (PARTICULARLY \n",
      "\n",
      "bilingual dictionaries). \n",
      "\n",
      "(2) DICTIONARY TRANSLATIONS ARE INHERENTLY \n",
      "\n",
      "ambiguous and add extraneous terms \n",
      "\n",
      "TO THE QUERY. \n",
      "\n",
      "(3) failure to translate multi-term \n",
      "\n",
      "CONCEPTS AS PHRASES REDUCES \n",
      "\n",
      "effectiveness. \n",
      "\n",
      "IN THE PICTUREQUEST APPLICATION, THESE PITFALLS \n",
      "\n",
      "are minimized because the queries are short, \n",
      "\n",
      "NOT PARAGRAPH-LONG DESCRIPTIONS AS IN TREC \n",
      "\n",
      "(see, e.g., voorhees and harman 1999). \n",
      "\n",
      "THIS WOULD BE A PROBLEM FOR A STATISTICAL \n",
      "\n",
      "approach, since the queries present little \n",
      "\n",
      "CONTEXT, BUT, SINCE WE ARE NOT RELYING ON \n",
      "\n",
      "context (because reducing ambiguity is not \n",
      "\n",
      "OUR TOP PRIORITY) IT MAKES OUR TASK SIMPLER. \n",
      "\n",
      "assuming that the translation program keeps \n",
      "\n",
      "MULTI-TERM CONCEPTS INTACT, OR AT LEAST THAT IT \n",
      "\n",
      "preserves the modifier-head structure, we \n",
      "\n",
      "CAN SUCCESSFULLY MATCH PHRASES. THE \n",
      "\n",
      "captions (i.e. the documents o be retrieved) \n",
      "\n",
      "ARE MOSTLY IN SENTENCES, AND THEIR PHRASES \n",
      "\n",
      "are intact. the phrase recognizer identifies \n",
      "\n",
      "MEANINGFUL PHRASES (E.G. FIRE ENGINE) AND \n",
      "\n",
      "handles them as a unit. the pattern matcher \n",
      "\n",
      "RECOGNIZES CORE NOUN PHRASES AND MAKES IT \n",
      "\n",
      "more likely that hey will match correctly. \n",
      "\n",
      "WORD CHOICE CAN BE A MAJOR ISSUE AS WELL FOR \n",
      "\n",
      "cross-language retrieval systems. some \n",
      "\n",
      "AMBIGUITY PROBLEMS CAN BE RESOLVED THROUGH \n",
      "\n",
      "the use of a part-of-speech tagger on the \n",
      "\n",
      "CAPTIONS. AS RESNIK AND YAROWSKY (IN \n",
      "\n",
      "press) observe, part-of-speech tagging \n",
      "\n",
      "CONSIDERABLY REDUCES THE WORD SENSE \n",
      "\n",
      "disambiguation problem. however, some \n",
      "\n",
      "AMBIGUITY REMAINS. FOR EXAMPLE, THE \n",
      "\n",
      "decision to translate a word as car, \n",
      "\n",
      "AUTOMOBILE, OR VEHICLE, MAY DRAMATICALLY \n",
      "\n",
      "affect retrieval accuracy. the picturequest \n",
      "\n",
      "14 \n",
      "\n",
      "system uses a semantic net based on \n",
      "\n",
      "WORDNET (FELLBAUM 1998) TO EXPAND TERMS. \n",
      "\n",
      "thus a query for car or automobile will \n",
      "\n",
      "RETRIEVE SSENTIALLY IDENTICAL RESULTS; VEHICLE \n",
      "\n",
      "will be less accurate but will still retrieve \n",
      "\n",
      "MANY OF THE SAME IMAGES. SO WHILE WORD \n",
      "\n",
      "choice may be a significant consideration for \n",
      "\n",
      "A SYSTEM LIKE THAT OF JANG ET AL., 1999, ITS \n",
      "\n",
      "impact on picturequest is minimal. \n",
      "\n",
      "THE USE OF WORDNET AS AN AID TO INFORMATION \n",
      "\n",
      "retrieval is controversial, and some studies \n",
      "\n",
      "INDICATE IT IS MORE HINDRANCE THAN HELP (E.G. \n",
      "\n",
      "voorhees 1993, 1994, smeaton, kelledy and \n",
      "\n",
      "O'DONNELL 1995). WORDNET USES EXTREMELY \n",
      "\n",
      "fine-grained distinctions, which can interfere \n",
      "\n",
      "WITH PRECISION EVEN IN MONOLINGUAL \n",
      "\n",
      "information retrieval. in a cross-language \n",
      "\n",
      "APPLICATION, THE ADDITIONAL SENSES CAN ADD \n",
      "\n",
      "confounding mistranslations. if, on the \n",
      "\n",
      "OTHER HAND, WORDNET EXPANSION IS \n",
      "\n",
      "constrained, the correct ranslation may be \n",
      "\n",
      "MISSED, LOWERING RECALL. IN THE PICTUREQUEST \n",
      "\n",
      "application, we have tuned wordnet \n",
      "\n",
      "EXPANSION LEVELS AND THE CORRESPONDING \n",
      "\n",
      "weights attached to them so that wordnet \n",
      "\n",
      "SERVES TO INCREASE RECALL WITH MINIMAL \n",
      "\n",
      "impact on precision (flank 2000). this \n",
      "\n",
      "TUNED EXPANSION APPEARS TO BE BENEFICIAL IN \n",
      "\n",
      "the cross-language application as well. \n",
      "\n",
      "GILARRANZ, GONZALO AND VERDEJO (1997) \n",
      "\n",
      "point out that, for cross-language \n",
      "\n",
      "INFORMATION RETRIEVAL, SOME PRECISION IS LOST \n",
      "\n",
      "in any case, and wordnet is more likely to \n",
      "\n",
      "ENHANCE CROSS-LINGUISTIC THAN MONOLINGUAL \n",
      "\n",
      "applications. \n",
      "\n",
      "IN FACT, SMEATON AND QUIGLEY (1996) \n",
      "\n",
      "conclude that wordnet is indeed helpful in \n",
      "\n",
      "IMAGE RETRIEVAL, IN PARTICULAR BECAUSE IMAGE \n",
      "\n",
      "captions are too short for statistical analysis \n",
      "\n",
      "TO BE USEFUL. THIS INSIGHT IS WHAT LED US TO \n",
      "\n",
      "develop a proprietary image retrieval engine \n",
      "\n",
      "IN THE FIRST PLACE: FINE-GRAINED LINGUISTIC \n",
      "\n",
      "analysis is more useful that a statistical \n",
      "\n",
      "APPROACH IN A CAPTION AVERAGING SOME THIRTY \n",
      "\n",
      "words. (our typical captions are longer than \n",
      "\n",
      "THOSE REPORTED IN SMEATON AND QUIGLEY \n",
      "\n",
      "1996). \n",
      "\n",
      "3 TRANSLATION METHODOLOGY \n",
      "\n",
      "we performed preliminary testing using two \n",
      "\n",
      "TRANSLATION METHODOLOGIES. FOR THE INITIAL \n",
      "\n",
      "tests, we chose european languages: french, \n",
      "\n",
      "SPANISH, AND GERMAN. CERTAINLY THIS CHOICE \n",
      "\n",
      "simplifies the translation problem, but in our \n",
      "\n",
      "CASE IT ALSO REFLECTS THE MOST PRESSING \n",
      "\n",
      "business need for translation. for the \n",
      "\n",
      "FRENCH, SPANISH, AND GERMAN TESTS, WE USED \n",
      "\n",
      "systran as provided by altavista \n",
      "\n",
      "(BABELFISH); WE ALSO TESTED SEVERAL OTHER \n",
      "\n",
      "web translation programs. we used native \n",
      "\n",
      "SPEAKERS TO CRAFT QUERIES AND THEN TRANSLATED \n",
      "\n",
      "those queries either manually or \n",
      "\n",
      "AUTOMATICALLY AND SUBMITTED THEM TO \n",
      "\n",
      "picturequest. the resulting image set was \n",
      "\n",
      "EVALUATED FOR PRECISION AND, IN A LIMITED \n",
      "\n",
      "fashion, for recall. \n",
      "\n",
      "THE SECOND TRANSLATION METHODOLOGY \n",
      "\n",
      "employed was direct dictionary translation, \n",
      "\n",
      "TESTED ONLY FOR SPANISH. WE USED THE SAME \n",
      "\n",
      "queries for this test. using an on-line \n",
      "\n",
      "SPANISH-ENGLISH DICTIONARY, WE SELECTED, FOR \n",
      "\n",
      "each word, the top (top-frequency) \n",
      "\n",
      "TRANSLATION. WE THEN SUBMITTED THIS WORD- \n",
      "\n",
      "by-word translation to picturequest. \n",
      "\n",
      "(UNLIKE ALTAVISTA, THIS METHOD SPELL- \n",
      "\n",
      "corrected letters entered without the \n",
      "\n",
      "NECESSARY DIACRITICS.) EVALUATION PROCEEDED \n",
      "\n",
      "in the same manner. the word-by-word \n",
      "\n",
      "METHOD INTRODUCES A WEAKNESS IN PHRASE \n",
      "\n",
      "recognition: any phrase recognition \n",
      "\n",
      "CAPABILITIES IN THE RETRIEVAL SYSTEM ARE \n",
      "\n",
      "defeated if phrases are not retained in the \n",
      "\n",
      "INPUT. WE CAN ASSUME THAT THE NON-ENGLISH- \n",
      "\n",
      "speaking user will, however, recognize \n",
      "\n",
      "PHRASES IN HER OR HIS OWN LANGUAGE, AND LOOK \n",
      "\n",
      "15 \n",
      "\n",
      "THEM UP AS PHRASES WHERE POSSIBLE. THUS WE \n",
      "\n",
      "can expect at least those multiword phrases \n",
      "\n",
      "THAT HAVE A DICTIONARY ENTRY TO BE CORRECTLY \n",
      "\n",
      "understood. we still do lose the noun \n",
      "\n",
      "PHRASE RECOGNITION CAPABILITIES IN THE \n",
      "\n",
      "retrieval system, further confounded by the \n",
      "\n",
      "FACT THAT IN SPANISH ADJECTIVES FOLLOW THE \n",
      "\n",
      "nouns they modify. in the hombre de \n",
      "\n",
      "NEGOCIOS EXAMPLE IN THE DATA BELOW, BOTH \n",
      "\n",
      "altavista and langenscheidt correctly \n",
      "\n",
      "IDENTIFY THE PHRASE AS MULTIWORD, AND \n",
      "\n",
      "translate it as businessman rather than man \n",
      "\n",
      "OF BUSINESSES. \n",
      "\n",
      "the use of phrase recognition has been \n",
      "\n",
      "SHOWN TO BE HELPFUL, AND, OPTIMALLY, WE \n",
      "\n",
      "would like to include it. hull and \n",
      "\n",
      "GREFENSTETTE 1996 SHOWED THE UPPER BOUND \n",
      "\n",
      "of the improvements possible by using \n",
      "\n",
      "LEXICALIZED PHRASES. EVERY PHRASE THAT \n",
      "\n",
      "appeared was added to the dictionary, and \n",
      "\n",
      "THAT TACTIC DID AID RETRIEVAL. BOTH STATISTICAL \n",
      "\n",
      "co-occurrence and syntactic phrases are also \n",
      "\n",
      "POSSIBLE APPROACHES. UNFORTUNATELY, THE \n",
      "\n",
      "extra-system approach we take here relies \n",
      "\n",
      "HEAVILY ON THE EXTERNAL MACHINE TRANSLATION \n",
      "\n",
      "to preserve phrases intact. if altavista (or, \n",
      "\n",
      "IN THE CASE OF LANGENSCHEIDT, HE USER) \n",
      "\n",
      "recognizes a phrase and translates it as a \n",
      "\n",
      "UNIT, THE TRANSLATION IS BETTER AND RETRIEVAL IS \n",
      "\n",
      "likely to be better. if, however, the \n",
      "\n",
      "TRANSLATION MISTAKENLY MISSES A PHRASE, \n",
      "\n",
      "retrieval quality is likely to be worse. as for \n",
      "\n",
      "COMPOSITIONAL NOUN PHRASES, IF THE \n",
      "\n",
      "translation preserves normal word order, \n",
      "\n",
      "THEN THE PICMREQUEST-INTERNAL OUN PHRASE \n",
      "\n",
      "recognition will take effect. that is, ifjeune \n",
      "\n",
      "FILLE TRANSLATES AS YOUNG GIRL, THEN \n",
      "\n",
      "picturequest will understand that young is \n",
      "\n",
      "AN ADJECTIVE MODIFYING GIRL. IN THE MORE \n",
      "\n",
      "difficult case, if the translation preserves the \n",
      "\n",
      "CORRECT ORDER IN TRANSLATING LA SELVA AFRICANA, \n",
      "\n",
      "i.e. the african jungle, then noun phrase \n",
      "\n",
      "RECOGNITION WILL WORK. IF, HOWEVER, IT COMES \n",
      "\n",
      "out as the jungle african, then retrieval will \n",
      "\n",
      "BE WORSE. IN THE ARCHITECTURE D SCRIBED HERE, \n",
      "\n",
      "fixing this problem requires access to the \n",
      "\n",
      "INTERNALS OF THE MACHINE TRANSLATION PROGRAM. \n",
      "\n",
      "4 evaluation \n",
      "\n",
      "EVALUATING PRECISION AND RECALL ON A LARGE \n",
      "\n",
      "corpus is a difficult task. we used the \n",
      "\n",
      "EVALUATION METHODS DETAILED IN FLANK 1998. \n",
      "\n",
      "precision was evaluated using a crossing \n",
      "\n",
      "MEASURE, WHEREBY ANY IMAGE RANKED HIGHER \n",
      "\n",
      "than a better match was penalized. recall \n",
      "\n",
      "PER SE WAS MEASURED ONLY WITH RESPECT O A \n",
      "\n",
      "defined subset of the images. ranking \n",
      "\n",
      "INCORPORATES SOME RECALL MEASURES INTO THE \n",
      "\n",
      "precision score, since images ranked too low \n",
      "\n",
      "ARE A RECALL PROBLEM, AND IMAGES MARKED TOO \n",
      "\n",
      "high are a precision problem. if there are \n",
      "\n",
      "THREE GOOD MATCHES, AND THE THIRD SHOWS UP \n",
      "\n",
      "as #4, the bogus #3 is a precision problem, \n",
      "\n",
      "AND THE TOO-LOW #4 IS A RECALL PROBLEM. \n",
      "\n",
      "for evaluation of the overall cross-language \n",
      "\n",
      "RETRIEVAL PERFORMANCE, WE SIMPLY MEASURED \n",
      "\n",
      "the ratio between the cross-language and \n",
      "\n",
      "MONOLINGUAL RETRIEVAL ACCURACY (C/M%). \n",
      "\n",
      "this is standard; see, for example, jang et al. \n",
      "\n",
      "1999. \n",
      "\n",
      "table 1 illustrates the percentage of \n",
      "\n",
      "MONOLINGUAL RETRIEVAL PERFORMANCE WE \n",
      "\n",
      "achieved for the translation tests performed. \n",
      "\n",
      "IN THIS INSTANCE, WE TAKE THE PRECISION \n",
      "\n",
      "performance of the human-translated queries \n",
      "\n",
      "AND NORMALIZE IT TO 100%, AND ADJUST THE \n",
      "\n",
      "other translation modalities relative to the \n",
      "\n",
      "HUMAN BASELINE. \n",
      "\n",
      "language raw \n",
      "\n",
      "PRECISION (%) \n",
      "\n",
      "french (human) 80 \n",
      "\n",
      "FRENCH 86 \n",
      "\n",
      "(altavista) \n",
      "\n",
      "FRENCH 66 \n",
      "\n",
      "(transparent \n",
      "\n",
      "LANGUAGE) \n",
      "\n",
      "c/m \n",
      "\n",
      "(%) \n",
      "\n",
      "100 \n",
      "\n",
      "100 \n",
      "\n",
      "83 \n",
      "\n",
      "16 \n",
      "\n",
      "language raw \n",
      "\n",
      "PRECISION (%) \n",
      "\n",
      "french (intertran) 44 \n",
      "\n",
      "SPANISH (HUMAN) 90 \n",
      "\n",
      "spanish 53 \n",
      "\n",
      "(ALTAVISTA) \n",
      "\n",
      "63 spanish \n",
      "\n",
      "(LANGENSCHEIDT \n",
      "\n",
      "bilingual \n",
      "\n",
      "DICTIONARY) \n",
      "\n",
      "german (human) 80 \n",
      "\n",
      "GERMAN 54 \n",
      "\n",
      "(altavista) \n",
      "\n",
      "C/M \n",
      "\n",
      "(%) \n",
      "\n",
      "55 \n",
      "\n",
      "100 \n",
      "\n",
      "59 \n",
      "\n",
      "70 \n",
      "\n",
      "100 \n",
      "\n",
      "68 \n",
      "\n",
      "SEVERAL OTHER FACTORS MAKE THE PICTUREQUEST \n",
      "\n",
      "application a particularly good application \n",
      "\n",
      "FOR MACHINE TRANSLATION TECHNOLOGY. UNLIKE \n",
      "\n",
      "document ranslation, there is no need to \n",
      "\n",
      "MATCH EVERY WORD IN THE DESCRIPTION; USEFUL \n",
      "\n",
      "images may be retrieved even if a word or \n",
      "\n",
      "TWO IS LOST. THERE ARE NO DISCOURSE ISSUES AT \n",
      "\n",
      "all: searches never use anaphora, and no one \n",
      "\n",
      "CARES IF THE TRANSLATED QUERY SOUNDS GOOD OR \n",
      "\n",
      "not. \n",
      "\n",
      "IN ADDITION, THE FACT THAT THE OBJECTS BEING \n",
      "\n",
      "retrieved were images greatly simplified the \n",
      "\n",
      "ENDEAVOR. UNDER NORMAL CIRCUMSTANCES, \n",
      "\n",
      "developing a user-friendly interface is a \n",
      "\n",
      "MAJOR CHALLENGE. USERS WITH ONLY LIMITED (OR \n",
      "\n",
      "nonexistent) reading knowledge of the \n",
      "\n",
      "LANGUAGE OF THE DOCUMENTS NEED A WAY TO \n",
      "\n",
      "determine, first, which ones are useful, and \n",
      "\n",
      "SECOND, WHAT THEY SAY. IN THE PICTUREQUEST \n",
      "\n",
      "application, however, the retrieved assets are \n",
      "\n",
      "IMAGES. USERS CAN INSTANTLY ASSESS WHICH \n",
      "\n",
      "images meet heir needs. \n",
      "\n",
      "IN CONCLUSION, IT APPEARS THAT SIMPLE ON-LINE \n",
      "\n",
      "translation of queries can support effective \n",
      "\n",
      "CROSS-LANGUAGE INFORMATION RETRIEVAL, FOR \n",
      "\n",
      "certain applications. we showed how an \n",
      "\n",
      "IMAGE RETRIEVAL APPLICATION ELIMINATES OME \n",
      "\n",
      "of the problems of cross-language r trieval, \n",
      "\n",
      "AND HOW CAREFULLY TUNED WORDNET EXPANSION \n",
      "\n",
      "simplifies word choice issues. we used a \n",
      "\n",
      "VARIETY OF MACHINE TRANSLATION SYSTEMS, NONE \n",
      "\n",
      "of them high-end and all of them free, and \n",
      "\n",
      "NONETHELESS ACHIEVED COMMERCIALLY VIABLE \n",
      "\n",
      "results. \n",
      "\n",
      "5 APPENDIX: DATA \n",
      "\n",
      "source example score \n",
      "\n",
      "HUMAN MEN REPAIRING ROAD 100 \n",
      "\n",
      "av men repairing wagon 0 \n",
      "\n",
      "LANG. MAN REPAIR OAD 100 \n",
      "\n",
      "human woman wearing red 100 \n",
      "\n",
      "SHOPPING IN STORE \n",
      "\n",
      "av woman dressed red buying 90 (2 of \n",
      "\n",
      "IN ONE TENDS 20 BAD) \n",
      "\n",
      "lang. woman clothe red buy in wearing \n",
      "\n",
      "SHOP RED IS LOST \n",
      "\n",
      "75 (5 of \n",
      "\n",
      "20 BAD) \n",
      "\n",
      "human cars driving on the 100 \n",
      "\n",
      "HIGHWAY \n",
      "\n",
      "av cars handling by the 80' (4 of \n",
      "\n",
      "FREEWAY 20 BAD) \n",
      "\n",
      "lang. cart handle for the 0 \n",
      "\n",
      "EXPRESSWAY \n",
      "\n",
      "human lions hunting in the 80 (1 of 5 \n",
      "\n",
      "AFRICAN FOREST BAD) \n",
      "\n",
      "av lions hunting in the 80 (1 of 5 \n",
      "\n",
      "AFRICAN FOREST BAD) \n",
      "\n",
      "lang. lion hunt in thejungle 45 (11 of \n",
      "\n",
      "GST \\] I 20 BAD) \n",
      "\n",
      "~'~ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  i~:~ i ~ \n",
      "\n",
      "HUMAN JUGGLER USING COLORFUL BALLS 67 (1 OF 3 \n",
      "\n",
      "bad) \n",
      "\n",
      "AV JUGGLER WITH USING BALLS OF 50 (4 OF 8 \n",
      "\n",
      "colors bad) \n",
      "\n",
      "LANG. JUGGLER BY MEANS OF USE (0; 1 \n",
      "\n",
      "ball colour should be \n",
      "\n",
      "THERE) \n",
      "\n",
      "17 \n",
      "\n",
      "SOURCE EXAMPLE SCORE \n",
      "\n",
      "human blonde children playing 90(#3 \n",
      "\n",
      "WITH MARBLES SHOULD BE \n",
      "\n",
      "#1; \n",
      "\n",
      "REMAINDER \n",
      "\n",
      "of top 20 \n",
      "\n",
      "OK) \n",
      "\n",
      "av blond children playing 90 (2 of \n",
      "\n",
      "WITH MARBLES 20 BAD) \n",
      "\n",
      "lang. young fair play by means 50 (1 of 2 \n",
      "\n",
      "OF MARBLE BAD) \n",
      "\n",
      "human buying power \n",
      "\n",
      "AV SPENDING POWER 45 (11 OF \n",
      "\n",
      "20 bad) \n",
      "\n",
      "LANG. \n",
      "\n",
      "av \n",
      "\n",
      "PURCHASING POWER 100 \n",
      "\n",
      "successful businessman i 60 (8 of \n",
      "\n",
      "OFFICE 20 BAD) \n",
      "\n",
      "lang. successful businessman i 6 (8 of 20 \n",
      "\n",
      "OFFICE BAD) \n",
      "\n",
      "human mother and daughter 100 (but \n",
      "\n",
      "BAKING BREAD IN THE KITCHEN NO FULL \n",
      "\n",
      "matches) \n",
      "\n",
      "AV MOTHER AND DAUGHTER 30 (14 OF \n",
      "\n",
      "\\[horneando-removed\\] 20 bad) \n",
      "\n",
      "BREAD IN THE KITCHEN \n",
      "\n",
      "lang. mother and child bake 100 (but \n",
      "\n",
      "BREAD IN THE KITCHEN NO FULL \n",
      "\n",
      "matches) \n",
      "\n",
      "HUMAN OLD AGE AND LONELINESS 100 \n",
      "\n",
      "av oldness and solitude 0 \n",
      "\n",
      "LANG. OLD AGE AND LONELINESS 100 \n",
      "\n",
      "5.1 spanish \n",
      "\n",
      "HUMAN TRANSLATIONS, TESTED ON PICTUREQUEST: \n",
      "\n",
      "90% (normalize to 100%) \n",
      "\n",
      "ALTAVISTA: 53% (59% NORMALIZED) \n",
      "\n",
      "langenscheidt, word-by-word: 63% (70% \n",
      "\n",
      "NORMALIZED) \n",
      "\n",
      "5.1.1 altavista \n",
      "\n",
      "FOR ALTAVISTA, WE LEFT OUT THE WORDS THAT \n",
      "\n",
      "altavista didn't translate. \n",
      "\n",
      "5.1.2 LANGENSCHEIDT \n",
      "\n",
      "langenscheidt, word-by-word: 63% (70% \n",
      "\n",
      "NORMALIZED) \n",
      "\n",
      "for the langenscheidt word-by-word, we \n",
      "\n",
      "USED THE BILINGUAL DICTIONARY TO TRANSLATE \n",
      "\n",
      "each word separately as if we knew no \n",
      "\n",
      "ENGLISH AT ALL, AND ALWAYS TOOK THE FIRST \n",
      "\n",
      "translation. we made the following \n",
      "\n",
      "ADJUSTMENTS: \n",
      "\n",
      "1. left out \"una,\" since langenscheidt \n",
      "\n",
      "MAPPED IT TO \"UNIR\" RATHER THAN TO EITHER A OR \n",
      "\n",
      "one \n",
      "\n",
      "2. TRANSLATED \"E\" AS AND INSTEAD OF  E \n",
      "\n",
      "5.2 french \n",
      "\n",
      "HUMAN TRANSLATIONS, TESTED ON PICTUREQUEST: \n",
      "\n",
      "80% \n",
      "\n",
      "ALTAVISTA: 86% (100% NORMALIZED) \n",
      "\n",
      "transparent language (freetranslation.com): \n",
      "\n",
      "66% (83% NORMALIZED) \n",
      "\n",
      "intertran (www.intertran.net:2000): 44% \n",
      "\n",
      "(55% NORMALIZED) \n",
      "\n",
      "\\[french examples originally drawn from \n",
      "\n",
      "HTTP ://HUMANITIES.UCHICAGO.EDU/ARTFL/PROJ \n",
      "\n",
      "ects/academie/1835.searchform.html: \n",
      "\n",
      "FRENCH-FRENCH\\] \n",
      "\n",
      "source : example score \n",
      "\n",
      "~,, ~ I!, ~II~L! \"  ~:S~:: ~ ~'~  ~ \n",
      "\n",
      "human signs of the zodiac 100 \n",
      "\n",
      "AV SIGNS OF THE ZODIAC 100 \n",
      "\n",
      "trlang sign zodiaque 0 \n",
      "\n",
      "INTRTRAN \n",
      "\n",
      "human \n",
      "\n",
      "\\[SIGNES\\] ANY ZODIAC \n",
      "\n",
      "fish in water \n",
      "\n",
      "100 \n",
      "\n",
      "30 (14 of 20 \n",
      "\n",
      "BAD) \n",
      "\n",
      "av fish in water 30 (14 of 20 \n",
      "\n",
      "BAD) \n",
      "\n",
      "trlang fish in water 30 (14 of 20 \n",
      "\n",
      "BAD) \n",
      "\n",
      "fish at water intrtran 30 (14 of 20 \n",
      "\n",
      "BAD) \n",
      "\n",
      "18 \n",
      "\n",
      "SOURCE EXAMPLE SCORE \n",
      "\n",
      "i \n",
      "\n",
      "HUMAN PAINFUL EARACHES LO0 \n",
      "\n",
      "av painful earaches 100 \n",
      "\n",
      "TRLANG THE PAINFUL EAR EVIL 0 \n",
      "\n",
      "the \\[manx\\] \\[doreille\\]' 0 \n",
      "\n",
      "DISTRESSING \n",
      "\n",
      "to take a rabbit by the \n",
      "\n",
      "EARS \n",
      "\n",
      "to take a rabbit by the \n",
      "\n",
      "INTRTRAN \n",
      "\n",
      ",~ ~ ~ii ~ \n",
      "\n",
      "HUMAN \n",
      "\n",
      "av \n",
      "\n",
      "65 (7 OF 20 \n",
      "\n",
      "bad) \n",
      "\n",
      "65 (7 OF 20 \n",
      "\n",
      "bad) ears \n",
      "\n",
      "TRLANG TAKE A RABBIT BY THE EARS 65 (7 OF 20 \n",
      "\n",
      "bad) \n",
      "\n",
      "INTRTRAN \n",
      "\n",
      "human \n",
      "\n",
      "CAPTURE A BUNNY BY THE \n",
      "\n",
      "ears \n",
      "\n",
      "CAT WHICH LIVES IN WOOD \n",
      "\n",
      "80 (1 of 5 \n",
      "\n",
      "BAD) \n",
      "\n",
      "%~!,~:,.' i~: ~'\" \n",
      "\n",
      "45 (11 OF 20 \n",
      "\n",
      "bad) \n",
      "\n",
      "AV CAT WHICH LIVES IN WOOD 45 (11 OF 20 \n",
      "\n",
      "bad) \n",
      "\n",
      "TRLANG CAT THAT LIVES IN WOOD 65 (7 OF 20 \n",
      "\n",
      "bad) \n",
      "\n",
      "CAT THANKSGIVING LIVES AT \n",
      "\n",
      "the forest \n",
      "\n",
      "TO LEAVE A HOUSE \n",
      "\n",
      "intrtran \n",
      "\n",
      "HUMAN \n",
      "\n",
      "70 (6 of 20 \n",
      "\n",
      "BAD) \n",
      "\n",
      "60 (8 of 20 \n",
      "\n",
      "BAD) \n",
      "\n",
      "av to leave a house 60 (8 of 20 \n",
      "\n",
      "BAD) \n",
      "\n",
      "trlang to go out of a house 95 (1 of 20 \n",
      "\n",
      "BAD) \n",
      "\n",
      "intrtran come out dune' dwelling 90 (18 of 20 \n",
      "\n",
      "HOUSE BAD) \n",
      "\n",
      "human carpenter's tool 95 (1 of 20 \n",
      "\n",
      "BAD) \n",
      "\n",
      "av instrument of carpenter 100 \n",
      "\n",
      "TRLANG INSTRUMENT OF CARPENTER 100 \n",
      "\n",
      "i intrtran implement any carpenter 35 (13 of 20 \n",
      "\n",
      "BAD) \n",
      "\n",
      "human to play the violin 100 \n",
      "\n",
      "AV TO PLAY OF THE VIOLIN 100 \n",
      "\n",
      "trlang to play the violin 100 \n",
      "\n",
      "INTRTRAN GAMBLE ANY VIOLIN 0 \n",
      "\n",
      "human pleasures of the body 100 \n",
      "\n",
      "SOURCE EXAMPLE SCORE \n",
      "\n",
      "av pleasures of the body 100 \n",
      "\n",
      "100 TRLANG \n",
      "\n",
      "intrtran \n",
      "\n",
      "THE PLEASURES OF THE BODY \n",
      "\n",
      "the delight any body \n",
      "\n",
      "HUMAN A GIRL EATS FRUIT \n",
      "\n",
      "av a girl eats fruit 100 \n",
      "\n",
      "TRLANG A GIRL EATS FRUIT 100 \n",
      "\n",
      "intrtran a girl am eating any fruit 65 (7 of 20 \n",
      "\n",
      "BAD) \n",
      "\n",
      "0 \n",
      "\n",
      "100 \n",
      "\n",
      "5.3 german \n",
      "\n",
      "HUMAN TRANSLATIONS, TESTED ON PICTUREQUEST:  \n",
      "\n",
      "80% (100% normal ized)  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ALTAVISTA 54% (68% NORMAL IZED)  \n",
      "\n",
      "source example score \n",
      "\n",
      "HUMAN BOYS GOLF COURSE 95 \n",
      "\n",
      "av golf course 95 \n",
      "\n",
      "HUMAN ARTIFICIAL PARADISE 100 \n",
      "\n",
      "av artificial paradiese 0 \n",
      "\n",
      "HUMAN SOLAR ENERGY FOR AUTOMOBILES 95 \n",
      "\n",
      "av solar energy for auto 95 ........................ ~, , ,~ :~,,~ . ~.~ ~ ~ ~; : .  , .  ~<.~ \n",
      "\n",
      "HUMAN HIKING THROUGH THE FOREST 90 \n",
      "\n",
      "av migrations by the forest 0 \n",
      "\n",
      "HUMAN AN ELEPHANT IN A ZOO 25 \n",
      "\n",
      "(#17 \n",
      "\n",
      "SHOULD \n",
      "\n",
      "be #2) \n",
      "\n",
      "AV ELEPHANT IN THE ZOO 100 \n",
      "\n",
      "............... i!~ n = ~!~ ~ ~ \n",
      "\n",
      "HUMAN THE SYNTHESIS OF I00 \n",
      "\n",
      "desoxyribonucleic acid \n",
      "\n",
      "AV THE SYNTHESIS OF THE 0 \n",
      "\n",
      "desoxynribonukleinsaeure \n",
      "\n",
      "HUMAN BLACK CARS 100 \n",
      "\n",
      "av black auto 100 \n",
      "\n",
      "HUMAN PLAYING TOGETHER 60 \n",
      "\n",
      "young together play \n",
      "\n",
      "19 \n",
      "\n",
      "source example score \n",
      "\n",
      "HUMAN WOMEN IN BLUE 65 \n",
      "\n",
      "av ladies in blue 75 \n",
      "\n",
      "HUMAN WOMAN AT WORK 65 \n",
      "\n",
      "av ladies on work 40 \n",
      "\n",
      "6 ACKNOWLEDGEMENTS \n",
      "\n",
      "i am grateful to doug oard for comments on \n",
      "\n",
      "AN EARLIER VERSION OF  THIS PAPER. \n",
      "\n",
      "7 references \n",
      "\n",
      "BALLESTEROS, LISA, AND W. BRUCE CROFT, 1997. \"PHRASAL \n",
      "\n",
      "translation and query expansion techniques for \n",
      "\n",
      "CROSS-LANGUAGE INFORMATION RETRIEVAL,\" IN AAAI \n",
      "\n",
      "spring symposium on cross-language text and \n",
      "\n",
      "SPEECH RETRIEVAL, STANFORD UNIVERSITY, PALO ALTO, \n",
      "\n",
      "california, march 24-26, 1997. \n",
      "\n",
      "FELLBAUM, CHRISTIANE, ED., 1998. WORDNET: AN \n",
      "\n",
      "electronic lexical database. cambridge, ma: mit \n",
      "\n",
      "PRESS. \n",
      "\n",
      "flank, sharon. 2000. \"does wordnet improve \n",
      "\n",
      "MULTIMEDIA INFORMATION RETRIEVAL?\" WORKING PAPERÃ‚â‚¬Â¢ \n",
      "\n",
      "flank, sharon. 1998Ã¢â‚¬Â¢ \"a layered approach to nlp- \n",
      "\n",
      "BASED INFORMATION RETRIEVAL,\" IN PROCEEDINGS OF \n",
      "\n",
      "coling-acl, 36th annual meeting of the \n",
      "\n",
      "ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, MONTREAL, \n",
      "\n",
      "canada, 10-14 august 1998. \n",
      "\n",
      "GILARRANZ, JULIO, JULIO GONZALO AND FELISA VERDEJO. \n",
      "\n",
      "1997. \"an approach to conceptual text retrieval \n",
      "\n",
      "USING THE EUROWORDNET MULTILINGUAL SEMANTIC \n",
      "\n",
      "database,\" in aaai spring symposium on cross- \n",
      "\n",
      "LANGUAGE TEXT AND SPEECH RETRIEVAL, STANFORD \n",
      "\n",
      "university, palo alto, california, march 24-26, \n",
      "\n",
      "1997. (HTTP://WWW.CLIS.UMD.EDU/DLRG/FILTER/SSS/PAPERS) \n",
      "\n",
      "grefenstette, gregory, ed., 1998. cross-language \n",
      "\n",
      "INFORMATION RETRIEVAL. NORWELL, MA: KLUWER. \n",
      "\n",
      "hull, david a. and gregory grefenstette, 1996. \n",
      "\n",
      "\"EXPERIMENTS IN MULTILINGUAL INFORMATION RETRIEVAL,\" \n",
      "\n",
      "m proceedin s o the 19 th l Ã¢â‚¬Â¢ \" g f nternational conference \n",
      "\n",
      "ON RESEARCH AND DEVELOPMENT IN INFORMATION \n",
      "\n",
      "retrieval (sigir96) zurich, switzerland. \n",
      "\n",
      "JANG, MYUNG-GIL, SUNG HYON MYAENG, AND SE \n",
      "\n",
      "young park, 1999. \"using mutual information to \n",
      "\n",
      "RESOLVE QUERY TRANSLATION AMBIGUITIES AND QUERY \n",
      "\n",
      "term weighting,\" in proceedings of 37 th annual \n",
      "\n",
      "MEETING OF THE ASSOCIATION FOR COMPUTATIONAL \n",
      "\n",
      "linguistics, college park, maryland. \n",
      "\n",
      "MCCARLEY, J. SCOTT, 1999. \"SHOULD WE TRANSLATE THE \n",
      "\n",
      "documents or the queries in cross-language \n",
      "\n",
      "INFORMATION RETRIEVAL?\" \n",
      "\n",
      "resnik, philip and yarowsky, david, in press. \n",
      "\n",
      "\"DISTINGUISHING SYSTEMS AND DISTINGUISHING SENSE: \n",
      "\n",
      "new evaluation methods for word sense \n",
      "\n",
      "DISAMBIGUATION,\" NATURAL LANGUAGE ENGINEERING. \n",
      "\n",
      "smeaton, alan f., f. kelledy and r. o'donnell, \n",
      "\n",
      "1995. \"TREC-4 EXPERIMENTS AT DUBLIN CITY \n",
      "\n",
      "university: thresholding posting lists, query \n",
      "\n",
      "EXPANSION WITH WORDNET AND POS TAGGING OF \n",
      "\n",
      "spanish,\" in donna k. harman (ed.) nist special \n",
      "\n",
      "PUBLICATION 500-236: THE FOURTH TEXT RETRIEVAL \n",
      "\n",
      "conference (trec-4), gaithersburg, md, usa: \n",
      "\n",
      "DEPARTMENT OF COMMERCE, NATIONAL INSTITUTE OF \n",
      "\n",
      "standards and technology. \n",
      "\n",
      "(HTTP://TREC.NIST.GOV/PUBS/TREC4/T4_PROCEEDINGS.HTML) \n",
      "\n",
      "smeaton, alan f. and i. quigley, 1996. \"experiments \n",
      "\n",
      "ON USING SEMANTIC DISTANCES BETWEEN WORDS IN \n",
      "\n",
      "image caption retrieval,\" in proceedings of the 19 th \n",
      "\n",
      "INTERNATIONAL CONFERENCE ON RESEARCH AND \n",
      "\n",
      "development in information retrieval (sigir96) \n",
      "\n",
      "ZURICH, SWITZERLAND. \n",
      "\n",
      "voorhees, ellen m. 1994. \"query expansion using \n",
      "\n",
      "LEXICAL-SEMANTIC RELATIONS,\" IN PROCEEDINGS OF THE \n",
      "\n",
      "17 th international acm sigir conference on \n",
      "\n",
      "RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, \n",
      "\n",
      "pp. 61-70. \n",
      "\n",
      "VOORHEES, ELLEN M. 1993. \"USING WORDNET TO \n",
      "\n",
      "disambiguate word senses for text retrieval,\" in \n",
      "\n",
      "PROCEEDINGS OF THE 16 TH INTERNATIONAL ACM SIGIR \n",
      "\n",
      "conference on research and development in \n",
      "\n",
      "INFORMATION RETRIEVAL, PP. 171-180. \n",
      "\n",
      "voorhees, ellen m. and donna k. harman, editors, \n",
      "\n",
      "1999Ã‚â‚¬Â¢ THE 7 TH TEXT RETRIEVAL CONFERENCE (TREC- 7). \n",
      "\n",
      "20 \n",
      "\n",
      "AUTOMATIC CONSTRUCTION OF PARALLEL ENGLISH-CHINESE CORPUS FOR \n",
      "\n",
      "cross-language information retrieval \n",
      "\n",
      "J I ANG  CHEN AND  J IAN -YUN  N IE  \n",
      "\n",
      "d~partement d ' in format ique et recherche op~rationnel le \n",
      "\n",
      "UNIVERSIT~ DE MONTREAL  \n",
      "\n",
      "c.p. 6128, succursale centre-v ille  \n",
      "\n",
      "MONTREAL  (QUEBEC), CANADA  H3C 3J7 \n",
      "\n",
      "{chen, nie} @iro. umontreal, ca \n",
      "\n",
      "ABST RAC T  \n",
      "\n",
      "a major obstacle to the construction ofa probabilis- \n",
      "\n",
      "TIC TRANSLATION MODEL IS THE LACK OF LARGE PARALLEL COR- \n",
      "\n",
      "pora. in this paper we first describe a parallel text \n",
      "\n",
      "MINING SYSTEM THAT FINDS PARALLEL TEXTS AUTOMATICALLY \n",
      "\n",
      "on the web. the generated chinese-english paral- \n",
      "\n",
      "LEL CORPUS IS USED TO TRAIN A PROBABILISTIC TRANSLATION \n",
      "\n",
      "model which translates queries for chinese-english \n",
      "\n",
      "CROSS-LANGUAGE INFORMATION RETRIEVAL (CLIR). WE WILL \n",
      "\n",
      "discuss ome problems in translation model training \n",
      "\n",
      "AND SHOW THE PRELIMINARY CUR RESULTS. \n",
      "\n",
      "1 in t roduct ion  \n",
      "\n",
      "PARALLEL TEXTS HAVE BEEN USED IN A NUMBER OF STUDIES \n",
      "\n",
      "in computational linguistics. brown et al. (1993) \n",
      "\n",
      "DEFINED A SERIES OF PROBABILISTIC TRANSLATION MODELS \n",
      "\n",
      "for mt purposes. while people may question the \n",
      "\n",
      "EFFECTIVENESS OF USING THESE MODELS FOR A FULL-BLOWN \n",
      "\n",
      "mt system, the models are certainly valuable for de- \n",
      "\n",
      "VELOPING TRANSLATION ASSISTANCE TOOLS. FOR EXAMPLE, \n",
      "\n",
      "we can use such a translation model to help com- \n",
      "\n",
      "PLETE TARGET EXT BEING DRAFTED BY A HUMAN TRANSLA- \n",
      "\n",
      "tor (langlais et al., 2000). \n",
      "\n",
      "ANOTHER UTILIZATION IS IN CROSS-LANGUAGE INFORMA- \n",
      "\n",
      "tion retrieval (clir) where queries have to be trans- \n",
      "\n",
      "LATED FROM ONE LANGUAGE TO ANOTHER LANGUAGE IN \n",
      "\n",
      "which the documents are written. in clir, the qual- \n",
      "\n",
      "ITY REQUIREMENT FOR TRANSLATION IS RELATIVELY LOW. FOR \n",
      "\n",
      "example, the syntactic aspect is irrelevant. even if \n",
      "\n",
      "THE TRANSLATED WORD IS NOT A TRUE TRANSLATION BUT IS \n",
      "\n",
      "strongly related to the original query, it is still help- \n",
      "\n",
      "FUL. THEREFORE, CLIR IS A SUITABLE APPLICATION FOR \n",
      "\n",
      "such a translation model. \n",
      "\n",
      "HOWEVER, A MAJOR OBSTACLE TO THIS APPROACH IS THE \n",
      "\n",
      "lack of parallel corpora for model training. only \n",
      "\n",
      "A FEW SUCH CORPORA EXIST, INCLUDING THE HANSARD \n",
      "\n",
      "english-french corpus and the hkust english- \n",
      "\n",
      "CHINESE CORPUS (WU, 1994). IN THIS PAPER, WE WILL \n",
      "\n",
      "describe a method which automatically searches for \n",
      "\n",
      "PARALLEL TEXTS ON THE WEB. WE WILL DISCUSS THE TEXT \n",
      "\n",
      "mining algorithm we adopted, some issues in trans- \n",
      "\n",
      "LATION MODEL TRAINING USING THE GENERATED PARALLEL \n",
      "\n",
      "corpus, and finally the translation model's perfor- \n",
      "\n",
      "MANCE IN CLIR. \n",
      "\n",
      "2 para l le l  text  m in ing  a lgor i thm \n",
      "\n",
      "THE PTMINER SYSTEM IS AN INTELLIGENT WEB AGENT \n",
      "\n",
      "that is designed to search for large amounts of paral- \n",
      "\n",
      "LEL TEXT ON THE WEB. THE MINING ALGORITHM IS LARGELY \n",
      "\n",
      "language independent. it can thus be adapted to \n",
      "\n",
      "OTHER LANGUAGE PAIRS WITH ONLY MINOR MODIFICATIONS. \n",
      "\n",
      "taking advantage ofweb search engines as much \n",
      "\n",
      "AS POSSIBLE, PTMINER IMPLEMENTS HE FOLLOWING STEPS \n",
      "\n",
      "(illustrated in fig. 1): \n",
      "\n",
      "1 SEARCH FOR CANDIDATE SITES - USING EXISTING WEB \n",
      "\n",
      "search engines, search for the candidate sites \n",
      "\n",
      "THAT MAY CONTAIN PARALLEL PAGES; \n",
      "\n",
      "2 file name fetching - for each candidate site, \n",
      "\n",
      "FETCH THE URLS OF WEB PAGES THAT ARE INDEXED \n",
      "\n",
      "by the search engines; \n",
      "\n",
      "3 HOST CRAWLING - STARTING FROM THE URLS COL- \n",
      "\n",
      "lected in the previous tep, search through each \n",
      "\n",
      "CANDIDATE SITE SEPARATELY FOR MORE URLS; \n",
      "\n",
      "4 pair scan - from the obtained urls of each \n",
      "\n",
      "SITE, SCAN FOR POSSIBLE PARALLEL PAIRS; \n",
      "\n",
      "5 download and verifying - download the parallel \n",
      "\n",
      "PAGES, DETERMINE FILE SIZE, LANGUAGE, AND CHARAC- \n",
      "\n",
      "ter set of each page, and filter out non-parallel \n",
      "\n",
      "PAIRS. \n",
      "\n",
      "2.1 search for candidate sites \n",
      "\n",
      "WE TAKE ADVANTAGE OF THE HUGE NUMBER OF WEB SITES \n",
      "\n",
      "indexed by existing search engines in determining \n",
      "\n",
      "CANDIDATE SITES. THIS IS DONE BY SUBMITTING SOME \n",
      "\n",
      "particular equests to the search engines. the re- \n",
      "\n",
      "QUESTS ARE DETERMINED ACCORDING TO THE FOLLOWING OB- \n",
      "\n",
      "servations. in the sites where parallel text exists, \n",
      "\n",
      "THERE ARE NORMALLY SOME PAGES IN ONE LANGUAGE CON- \n",
      "\n",
      "taining links to the parallel version in the other lan- \n",
      "\n",
      "GUAGE. THESE ARE USUALLY INDICATED BY THOSE LINKS' \n",
      "\n",
      "anchor texts 1. for example, on some english page \n",
      "\n",
      "THERE MAY BE A LINK TO ITS CHINESE VERSION WITH \n",
      "\n",
      "the anchor text \"chinese version\" or \"in chinese\". \n",
      "\n",
      "1AN ANCHOR TEXT  IS A PIECE OF TEXT ON A WEB PAGE WHICH, \n",
      "\n",
      "when clicked on, will take you to another linked page. to \n",
      "\n",
      "BE HELPFUL, IT USUAL LY  CONTAINS THE KEY INFORMATION ABOUT THE \n",
      "\n",
      "l inked page. \n",
      "\n",
      "21 \n",
      "\n",
      "figure 1: the workflow of the mining process. \n",
      "\n",
      "THE SAME PHENOMENON CAN BE OBSERVED ON CHINESE \n",
      "\n",
      "pages. chances are that a site with parallel texts \n",
      "\n",
      "WILL CONTAIN SUCH LINKS IN SOME OF ITS DOCUMENTS. \n",
      "\n",
      "this fact is used as the criterion in searching for \n",
      "\n",
      "CANDIDATE SITES. \n",
      "\n",
      "therefore, to determine possible sites for english- \n",
      "\n",
      "CHINESE PARALLEL TEXTS, WE CAN REQUEST AN ENGLISH \n",
      "\n",
      "document containing the following anchor: \n",
      "\n",
      "ANCHOR : \"ENGL ISH VERSION H \\[\"IN ENGLISH\", ...\\]. \n",
      "\n",
      "similar requests are sent for chinese documents. \n",
      "\n",
      "FROM THE TWO SETS OF PAGES OBTAINED BY THE ABOVE \n",
      "\n",
      "queries we extract wo sets of web sites. the union \n",
      "\n",
      "OF THESE TWO SETS CONSTITUTES THEN THE CANDIDATE SITES. \n",
      "\n",
      "that  is to say, a site is a candidate site when it \n",
      "\n",
      "IS FOUND TO HAVE EITHER AN ENGLISH PAGE LINKING TO \n",
      "\n",
      "its chinese version or a chinese page linking to its \n",
      "\n",
      "ENGLISH VERSION. \n",
      "\n",
      "2.2 file name fetching \n",
      "\n",
      "WE NOW ASSUME THAT A PAIR OF PARALLEL TEXTS EXISTS ON \n",
      "\n",
      "the same site. to search for parallel pairs on a site, \n",
      "\n",
      "PTMINER FIRST HAS TO OBTAIN ALL (OR AT LEAST PART OF) \n",
      "\n",
      "the html file names on the site. from these names \n",
      "\n",
      "PAIRS ARE SCANNED. IT IS POSSIBLE TO USE A WEB CRAWLER \n",
      "\n",
      "to explore the candidate sites completely. however, \n",
      "\n",
      "WE CAN TAKE ADVANTAGE OF THE SEARCH ENGINES AGAIN TO \n",
      "\n",
      "accelerate the process. as the first step, we submit \n",
      "\n",
      "THE FOLLOWING QUERY TO THE SEARCH ENGINES: \n",
      "\n",
      "host : hostname \n",
      "\n",
      "TO FETCH THE WEB PAGES THAT THEY INDEXED FROM THIS \n",
      "\n",
      "site. if we only require a small amount of parallel \n",
      "\n",
      "TEXTS, THIS RESULT MAY BE SUFFICIENT. FOR OUR PURPOSE, \n",
      "\n",
      "however, we need to explore the sites more thor- \n",
      "\n",
      "OUGHLY USING A HOST CRAWLER. THEREFORE, WE CONTINUE \n",
      "\n",
      "our search for files with a host crawler which uses \n",
      "\n",
      "THE DOCUMENTS FOUND BY THE SEARCH ENGINES AS THE \n",
      "\n",
      "starting point. \n",
      "\n",
      "2.3 HOST CRAWLING \n",
      "\n",
      "a host crawler is slightly different from a web \n",
      "\n",
      "CRAWLER. WEB CRAWLERS GO THROUGH INNUMERABLE \n",
      "\n",
      "pages and hosts on the web. a host crawler is a \n",
      "\n",
      "WEB CRAWLER THAT CRAWLS THROUGH DOCUMENTS ON A \n",
      "\n",
      "given host only. a breadth-first crawling algorithm \n",
      "\n",
      "IS APPLIED IN PTMINER AS HOST CRAWLER. THE PRINCIPLE \n",
      "\n",
      "is that when a link to an unexplored ocument on \n",
      "\n",
      "THE SAME SITE IS FOUND IN A DOCUMENT, IT IS ADDED TO \n",
      "\n",
      "a list that will be explored later. in this way, most \n",
      "\n",
      "FILE NAMES FROM THE CANDIDATE SITES ARE OBTAINED. \n",
      "\n",
      "2.4 pair scan \n",
      "\n",
      "AFTER COLLECTING FILE NAMES FOR EACH CANDIDATE SITE, \n",
      "\n",
      "the next task is to determine the parallel pairs. \n",
      "\n",
      "AGAIN, WE TRY TO USE SOME HEURISTIC RULES TO GUESS \n",
      "\n",
      "which files may be parallel texts before downloading \n",
      "\n",
      "THEM. THE RULES ARE BASED ON EXTERNAL FEATURES OF \n",
      "\n",
      "the documents. by external feature, we mean those \n",
      "\n",
      "FEATURES WHICH MAY BE KNOWN WITHOUT ANALYZING THE \n",
      "\n",
      "contents of the file, such as its url, size, and date. \n",
      "\n",
      "THIS IS IN CONTRAST WITH THE INTERNAL FEATURES, SUCH AS \n",
      "\n",
      "language, character set, and html structure, which \n",
      "\n",
      "CANNOT BE KNOWN UNTIL WE HAVE DOWNLOADED THE PAGE \n",
      "\n",
      "and analyzed its contents. \n",
      "\n",
      "THE HEURISTIC CRITERION COMES FROM THE FOLLOWING \n",
      "\n",
      "observation: we observe that parallel text pairs usu- \n",
      "\n",
      "ALLY HAVE SIMILAR NAME PATTERNS. THE DIFFERENCE BE- \n",
      "\n",
      "tween the names of two parailel pages usually lies \n",
      "\n",
      "IN A SEGMENT WHICH INDICATES THE LANGUAGE. FOR EX- \n",
      "\n",
      "ample, \"file-ch.html\" (in chinese) vs. \"file-en.html\" \n",
      "\n",
      "(IN ENGLISH). THE DIFFERENCE MAY ALSO APPEAR IN THE \n",
      "\n",
      "path, such as \".../chinese/.../fi le.html\" vs. \".../en- \n",
      "\n",
      "GLISH/.../F I LE.HTML'. THE NAME PATTERNS DESCRIBED \n",
      "\n",
      "above are commonly used by webmasters to help or- \n",
      "\n",
      "GANIZE THEIR SITES. HENCE, WE CAN SUPPOSE THAT A \n",
      "\n",
      "pair of pages with this kind of pattern are probably \n",
      "\n",
      "PARALLEL TEXTS. \n",
      "\n",
      "22\n",
      "\n",
      "FIRST, WE ESTABLISH FOUR LISTS FOR ENGLISH PRE- \n",
      "\n",
      "fixes, english suffixes, chinese prefixes and chi- \n",
      "\n",
      "NESE SUFFIXES. FOR EXAMPLE: ENGL ISH P RE F IX  = \n",
      "\n",
      "{e, en, e_, en_, e - ,  en - ,  ...}. for each file in one lan- \n",
      "\n",
      "GUAGE, IF A SEGMENT IN ITS NAME CORRESPONDS TO ONE \n",
      "\n",
      "of the language affixes, several new names are gener- \n",
      "\n",
      "ATED BY CHANGING THE SEGMENT TO THE POSSIBLE CORRE- \n",
      "\n",
      "sponding affixes of the other language. if a generated \n",
      "\n",
      "NAME CORRESPONDS TO AN EXISTING FILE, THEN THE FILE IS \n",
      "\n",
      "considered as a candidate parallel document of the \n",
      "\n",
      "ORIGINAL FILE. \n",
      "\n",
      "2.5 filtering \n",
      "\n",
      "NEXT, WE FURTHER EXAMINE THE CONTENTS OF THE PAIRED \n",
      "\n",
      "files to determine if they are really parallel according \n",
      "\n",
      "TO VARIOUS EXTERNAL AND INTERNAL FEATURES. THIS MAY \n",
      "\n",
      "further improve the pairing precision. the following \n",
      "\n",
      "METHODS HAVE BEEN IMPLEMENTED IN OUR SYSTEM. \n",
      "\n",
      "2.5.1 text length \n",
      "\n",
      "PARALLEL FILES OFTEN HAVE SIMILAR FILE LENGTHS. ONE SIM- \n",
      "\n",
      "ple way to filter out incorrect pairs is to compare \n",
      "\n",
      "THE LENGTHS OF THE TWO FILES. THE ONLY PROBLEM IS TO \n",
      "\n",
      "set a reasonable threshold that will not discard too \n",
      "\n",
      "MANY GOOD PAIRS, I.E. BALANCE RECALL AND PRECISION. \n",
      "\n",
      "the usual difference ratio depends on the language \n",
      "\n",
      "PAIRS WE ARE DEALING WITH. FOR EXAMPLE, CHINESE- \n",
      "\n",
      "english parallel texts usually have a larger differ- \n",
      "\n",
      "ENCE RATIO THAN ENGLISH-FRENCH PARALLEL TEXTS. THE \n",
      "\n",
      "filtering threshold had to be determined empirically, \n",
      "\n",
      "FROM THE ACTUAL OBSERVATIONS. FOR CHINESE-ENGLISH, \n",
      "\n",
      "a difference up to 50% is tolerated. \n",
      "\n",
      "2.5.2 LANGUAGE AND  CHARACTER SET \n",
      "\n",
      "it is also obvious that the two files of a pair have \n",
      "\n",
      "TO BE IN THE TWO LANGUAGES OF INTEREST. BY AUTO- \n",
      "\n",
      "matically identifying language and character set, we \n",
      "\n",
      "CAN FILTER OUT THE PAIRS THAT DO NOT SATISFY THIS BASIC \n",
      "\n",
      "criterion. some web pages explicitly indicate the \n",
      "\n",
      "LANGUAGE AND THE CHARACTER SET. MORE OFTEN SUCH \n",
      "\n",
      "information is omitted by authors. we need some \n",
      "\n",
      "LANGUAGE IDENTIFICATION TOOL FOR THIS TASK. \n",
      "\n",
      "silc is a language and encoding identification \n",
      "\n",
      "SYSTEM DEVELOPED BY THE RALI LABORATORY AT THE \n",
      "\n",
      "university of montreal. it employs a probabilistic \n",
      "\n",
      "MODEL ESTIMATED ON TRI-GRAMS. USING THESE MOD- \n",
      "\n",
      "els, the system is able to determine the most proba- \n",
      "\n",
      "BLE LANGUAGE AND ENCODING OF A TEXT (ISABELLE ET AL., \n",
      "\n",
      "1997). \n",
      "\n",
      "2.5.3 HTML STRUCTURE AND ALIGNMENT \n",
      "\n",
      "in the strand system (resnik, 1998), the candi- \n",
      "\n",
      "DATE PAIRS ARE EVALUATED BY ALIGNING THEM ACCORDING \n",
      "\n",
      "to their html structures and computing confidence \n",
      "\n",
      "VALUES. PAIRS ARE ASSUMED TO BE WRONG IF THEY HAVE \n",
      "\n",
      "too many mismatching markups or low confidence \n",
      "\n",
      "VALUES. \n",
      "\n",
      "comparing html structures seems to be a sound \n",
      "\n",
      "WAY TO EVALUATE CANDIDATE PAIRS SINCE PARALLEL PAIRS \n",
      "\n",
      "usually have similar html structures. however, we \n",
      "\n",
      "ALSO NOTICED THAT PARALLEL TEXTS MAY HAVE QUITE DIF- \n",
      "\n",
      "ferent html structures. one of the reasons is that \n",
      "\n",
      "THE TWO FILES MAY BE CREATED USING TWO HTML ED- \n",
      "\n",
      "itors. for example, one may be used for english \n",
      "\n",
      "AND ANOTHER FOR CHINESE, DEPENDING ON THE LANGUAGE \n",
      "\n",
      "handling capability of the editors. therefore, cau- \n",
      "\n",
      "TION IS REQUIRED WHEN MEASURING STRUCTURE DIFFERENCE \n",
      "\n",
      "numerically. \n",
      "\n",
      "PARALLEL TEXT ALIGNMENT IS STILL AN EXPERIMENTAL \n",
      "\n",
      "area. measuring the confidence values of an align- \n",
      "\n",
      "MENT IS EVEN MORE COMPLICATED. FOR EXAMPLE, THE \n",
      "\n",
      "alignment algorithm we used in the training of the \n",
      "\n",
      "STATISTICAL TRANSLATION MODEL PRODUCES ACCEPTABLE \n",
      "\n",
      "alignment results but it does not provide a confi- \n",
      "\n",
      "DENCE VALUE THAT WE CAN \"CONFIDENTLY\" USE AS AN EVAL- \n",
      "\n",
      "uation criterion. so, for the moment his criterion is \n",
      "\n",
      "NOT USED IN CANDIDATE PAIR EVALUATION. \n",
      "\n",
      "3 generated  corpus  and trans la t ion  \n",
      "\n",
      "MODE L  TRA IN ING  \n",
      "\n",
      "in this section, we describe the results of our parallel \n",
      "\n",
      "TEXT MINING AND TRANSLATION MODEL TRAINING. \n",
      "\n",
      "3.1 the corpus \n",
      "\n",
      "USING THE ABOVE APPROACH FOR CHINESE-ENGLISH, 185 \n",
      "\n",
      "candidate sites were searched from the domain hk. \n",
      "\n",
      "WE LIMITED THE MINING DOMAIN TO HK BECAUSE HONG \n",
      "\n",
      "kong is a bilingual english-chinese city where high \n",
      "\n",
      "QUALITY PARALLEL WEB SITES EXIST. BECAUSE OF THE SMALL \n",
      "\n",
      "number of candidate sites, the host crawler was used \n",
      "\n",
      "TO THOROUGHLY EXPLORE EACH SITE. THE RESULTING COR- \n",
      "\n",
      "pus contains 14820 pairs of texts including 117.2mb \n",
      "\n",
      "CHINESE TEXTS AND 136.5MB ENGLISH TEXTS. THE ENTIRE \n",
      "\n",
      "mining process lasted about a week. using length \n",
      "\n",
      "COMPARISON AND LANGUAGE IDENTIFICATION, WE REFINED \n",
      "\n",
      "the precision of the corpus to about 90%. the preci- \n",
      "\n",
      "SION IS ESTIMATED BY EXAMINING 367 RANDOMLY PICKED \n",
      "\n",
      "pairs. \n",
      "\n",
      "3.2 STATISTICAL TRANSLATION MODEL \n",
      "\n",
      "many approaches in computational linguistics try to \n",
      "\n",
      "EXTRACT RANSLATION KNOWLEDGE FROM PREVIOUS TRANS- \n",
      "\n",
      "lation examples. most work of this kind establishes \n",
      "\n",
      "PROBABILISTIC MODELS FROM PARALLEL CORPORA. BASED \n",
      "\n",
      "on one of the statistical models proposed by brown \n",
      "\n",
      "ET AL. (1993), THE BASIC PRINCIPLE OF OUR TRANSLATION \n",
      "\n",
      "model is the following: given a corpus of aligned sen- \n",
      "\n",
      "TENCES, IF TWO WORDS OFTEN CO-OCCUR IN THE SOURCE AND \n",
      "\n",
      "target sentences, there is a good likelihood that they \n",
      "\n",
      "ARE TRANSLATIONS OF EACH OTHER. IN THE SIMPLEST CASE \n",
      "\n",
      "(model 1), the model earns the probability, p(tls), of \n",
      "\n",
      "HAVING A WORD T IN THE TRANSLATION OF A SENTENCE CON- \n",
      "\n",
      "taining a word s. for an input sentence, the model \n",
      "\n",
      "THEN CALCULATES A SEQUENCE OF WORDS THAT ARE MOST \n",
      "\n",
      "probable to appear in its translation. using a sim- \n",
      "\n",
      "ILAR STATISTICAL MODEL, WU (1995) EXTRACTED A LARGE- \n",
      "\n",
      "scale english-chinese l xicon from the hkust cor- \n",
      "\n",
      "23  \n",
      "\n",
      "<s id=\"00~\"> \n",
      "\n",
      "<HTML> <HEAD> \n",
      "\n",
      "<meta htrp-equiv=\"content-type\" \n",
      "\n",
      "CONTENT=\"TEXT/HTML; CHARSET--ISO-8859-1\"> \n",
      "\n",
      "<meta hti'p-equiv=\"content-language\" \n",
      "\n",
      "CONTENT=\"WESTERN\"> \n",
      "\n",
      "</s> \n",
      "\n",
      "<S ID=\"0001\"> \n",
      "\n",
      "<title>journal of primary education 1996, \n",
      "\n",
      "VOI., NO. L&2, PP. 19-27 </TITLE> \n",
      "\n",
      "</head> \n",
      "\n",
      "</S> \n",
      "\n",
      "<s id=\"0002\"> \n",
      "\n",
      "<BODY BACKGROUND=\".JGIF/PEJBG.JPG\" \n",
      "\n",
      "text=\"#000(3(o\" bgcolor=\"#ffffff\"> \n",
      "\n",
      "<CENTER> \n",
      "\n",
      "</s> \n",
      "\n",
      "<S ID=\"0003\"> \n",
      "\n",
      "<hi>journal of primary education </hi> \n",
      "\n",
      "</S> \n",
      "\n",
      "<s id=\"0004\"> \n",
      "\n",
      "<HR> <B>VOLUME 6, NO L&2, PP. 19-27 (MAY, \n",
      "\n",
      "1996) </b> <hr> \n",
      "\n",
      "</S> \n",
      "\n",
      "<s id=\"0005\"> \n",
      "\n",
      "<H3>PRINCIPLES FOR REDESIGNING TEACHER \n",
      "\n",
      "education </h3> alan tom </center> \n",
      "\n",
      "</S> \n",
      "\n",
      "<s id=\"0006\"> \n",
      "\n",
      "<P> <B> <I> ABSTRACT </I> </B> \n",
      "\n",
      "</s> \n",
      "\n",
      "<S ID=\"0000\"> \n",
      "\n",
      "<html> <head> \n",
      "\n",
      "<META H'ITP-EQUW=\"CONTENT-TYPE\" \n",
      "\n",
      "content=\"text/html; charset=bigs\"> \n",
      "\n",
      "<META HTTP-EQUIV=\"CONTENT-LANGUAGE\" \n",
      "\n",
      "content=\"zh\"> \n",
      "\n",
      "<IS> \n",
      "\n",
      "<s id=\"0001\"> \n",
      "\n",
      "<TITLE> JOURNAL OF PRIMARY EDUCATION 1996, \n",
      "\n",
      "vol., no. l&2, page 19-27 </title> \n",
      "\n",
      "</HEAD> \n",
      "\n",
      "</s> \n",
      "\n",
      "<S ID=\"0002\"> \n",
      "\n",
      "<body background=\".jgif/pejbg.jpg\" \n",
      "\n",
      "TEXT=\"#000000\" BGCOLOR=\"#FFFFFF\"> <A \n",
      "\n",
      "href=\"/erdpej/b2g__pej.phtml?url=%2fen%2fp \n",
      "\n",
      "EJ%2F0601%2F0601019C.HTM\"> \n",
      "\n",
      "<img src=\"/en/gif/kan.gif\" alt=\"~\"  \n",
      "\n",
      "BORDER=0 ALIGN=R IGHT> </A> <CENTER> \n",
      "\n",
      "</s> \n",
      "\n",
      "<S ID=\"0003\"> \n",
      "\n",
      "<h2>~ ~ 11i ~ o.</h2> \n",
      "\n",
      "</S> \n",
      "\n",
      "<s id=\"0004\"> \n",
      "\n",
      "<HR> (~:~H-FV-C?.JLJL) ~,-\\]'Ã‚Â¢~.. \n",
      "\n",
      "</s> \n",
      "\n",
      "<S ID=\"0005\"> \n",
      "\n",
      "~ 19-27\\]~ <i-1r> \n",
      "\n",
      "</S> \n",
      "\n",
      "figure 2: an alignment example using pure length-based method. \n",
      "\n",
      "PUS WHICH IS BUILT MANUALLY. IN OUR CASE, THE PROB- \n",
      "\n",
      "abilistic translation model will be used for clir. \n",
      "\n",
      "THE REQUIREMENT ON OUR TRANSLATION MODEL MAY BE \n",
      "\n",
      "less demanding: it is not absolutely necessary that \n",
      "\n",
      "A WORD T WITH HIGH P(TLS ) ALWAYS BE A TRUE TRANS- \n",
      "\n",
      "lation of s. it is still useful if t is strongly related \n",
      "\n",
      "TO S. FOR EXAMPLE, ALTHOUGH \"RAILWAY\" IS NOT A TRUE \n",
      "\n",
      "translation of \"train\" (in french), it is highly useful \n",
      "\n",
      "TO INCLUDE \"RAILWAY\" IN THE TRANSLATION OF A QUERY ON \n",
      "\n",
      "\"train\". this is one of the reasons why we think a \n",
      "\n",
      "LESS CONTROLLED PARALLEL CORPUS CAN BE USED TO TRAIN A \n",
      "\n",
      "translation model for clir. \n",
      "\n",
      "3.3 PARALLEL TEXT AL IGNMENT \n",
      "\n",
      "before the mined documents can be aligned into par- \n",
      "\n",
      "ALLEL SENTENCES, THE RAW TEXTS HAVE TO UNDERGO A SE- \n",
      "\n",
      "ries of some preprocessing, which, to some extent, is \n",
      "\n",
      "LANGUAGE DEPENDENT. FOR EXAMPLE, THE MAJOR OPERA- \n",
      "\n",
      "tions on the chinese-english corpus include encod- \n",
      "\n",
      "ING SCHEME TRANSFORMATION (FOR CHINESE), SENTENCE \n",
      "\n",
      "level segmentation, parallel text alignment, chinese \n",
      "\n",
      "WORD SEGMENTATION (NIE ET AL., 1999) AND ENGLISH \n",
      "\n",
      "expression extraction. \n",
      "\n",
      "THE PARALLEL WEB PAGES WE COLLECTED FROM VARI- \n",
      "\n",
      "ous sites are not all of the same quality. some are \n",
      "\n",
      "HIGHLY PARALLEL AND EASY TO ALIGN WHILE OTHERS CAN BE \n",
      "\n",
      "very noisy. aligning english-chinese parallel texts \n",
      "\n",
      "IS ALREADY VERY DIFFICULT BECAUSE OF THE GREAT DIFFER- \n",
      "\n",
      "ences in the syntactic structures and writing sys- \n",
      "\n",
      "TEMS OF THE TWO LANGUAGES. A NUMBER OF ALIGNMENT \n",
      "\n",
      "techniques have been proposed, varying from statis- \n",
      "\n",
      "TICAL METHODS (BROWN ET AL., 1991; GALE AND CHURCH, \n",
      "\n",
      "1991) to lexical methods (kay and rsscheisen, 1993; \n",
      "\n",
      "CHEN, 1993). THE METHOD WE ADOPTED IS THAT OF \n",
      "\n",
      "simard et al. (1992). because it considers both \n",
      "\n",
      "LENGTH SIMILARITY AND COGNATENESS AS ALIGNMENT CRI- \n",
      "\n",
      "teria, the method is more robust and better able \n",
      "\n",
      "TO DEAL WITH NOISE THAN PURE LENGTH-BASED METHODS. \n",
      "\n",
      "cognates are identical sequences of characters in cor- \n",
      "\n",
      "RESPONDING WORDS IN TWO LANGUAGES. THEY ARE COM- \n",
      "\n",
      "monly found in english and french. in the case of \n",
      "\n",
      "ENGLISH-CHINESE ALIGNMENT, WHERE THERE ARE NO COG- \n",
      "\n",
      "nates shared by the two languages, only the html \n",
      "\n",
      "MARKUP IN BOTH TEXTS ARE TAKEN AS COGNATES. BE- \n",
      "\n",
      "cause the html structures of parallel pages are nor- \n",
      "\n",
      "MALLY SIMILAR, THE MARKUP WAS FOUND TO BE HELPFUL \n",
      "\n",
      "for alignment. \n",
      "\n",
      "TO ILLUSTRATE HOW MARKUP CAN HELP WITH THE ALIGN- \n",
      "\n",
      "ment, we align the same pair with both the pure \n",
      "\n",
      "LENGTH-BASED METHOD OF GALE & CHURCH (FIG. 2), \n",
      "\n",
      "and the method of simard et al. (fig. 3). first of \n",
      "\n",
      "ALL, WE OBSERVE FROM THE FIGURES THAT THE TWO TEXTS ARE \n",
      "\n",
      "24\n",
      "\n",
      "<S ID=\"0000\"> \n",
      "\n",
      "<html> <head> \n",
      "\n",
      "<META HTTP-EQUIV=\"CONTENT-TYPE\" \n",
      "\n",
      "content=\"text/html; charset=iso-8859-1 \"> \n",
      "\n",
      "<META HTTP-EQUIV=\"CONTENT-LANGUAGE\" \n",
      "\n",
      "content=\"westem\"> \n",
      "\n",
      "</S> \n",
      "\n",
      "<s id=\"0001\"> \n",
      "\n",
      "<TITLE>JOURNAL OF PRIMARY EDUCATION 1996, \n",
      "\n",
      "vol., no. l&2, pp. 19-27 </title> \n",
      "\n",
      "</HEAD> \n",
      "\n",
      "</s> \n",
      "\n",
      "<S ID=\"0002\"> \n",
      "\n",
      "<body background=-\". jgif/pejbg.jpg\" \n",
      "\n",
      "TEXT=\"#000000\" BGCOLOR=\"#FFFFFF\"> \n",
      "\n",
      "<center> \n",
      "\n",
      "</S> \n",
      "\n",
      "<s id=\"0003\"> \n",
      "\n",
      "<H 1 >JOURNAL OF PRIMARY EDUCATION </H 1 > \n",
      "\n",
      "<is> \n",
      "\n",
      "<S ID=\"0004\"> \n",
      "\n",
      "<hr> <b>volume 6,no l&2, pp. 19-27 (may, \n",
      "\n",
      "1996) </B> <HR> \n",
      "\n",
      "</$> \n",
      "\n",
      "<S ID=\"0000\"> \n",
      "\n",
      "<html> <head> \n",
      "\n",
      "<META HTRP-EQUIV=\"CONTENT-TYPE\" \n",
      "\n",
      "content=\"text/html; charset=big5\"> \n",
      "\n",
      "<META H'LTP-EQUIV=\"CONTENT-LANGUAGE\" \n",
      "\n",
      "content=\"zh\"> \n",
      "\n",
      "<IS> \n",
      "\n",
      "<s id=\"0001\"> \n",
      "\n",
      ":<TITLE> JOURNAL OF PRIMARY EDUCATION 1996, \n",
      "\n",
      "vol., no. l&2, page 19-27 </title> \n",
      "\n",
      "</HEAD> \n",
      "\n",
      "</s> \n",
      "\n",
      "<S ID=\"0002\"> \n",
      "\n",
      "<body background=-\". jgiffpejbg.jpg\" \n",
      "\n",
      "TEXT=\"#O00000\" BGCOLOR=\"#FFFFFFF> <A \n",
      "\n",
      "href=\"/ergpej/b2g_pej.phtml?url=%2fen%2fp \n",
      "\n",
      "EJ %2F0601%2 F0601019C.HTM\"> \n",
      "\n",
      "<img src=\"/erdgif/kan.gif\" alt=\"~k\" \n",
      "\n",
      "BORDER={) ALIGN=R IGHT> </A> <CEHTEIL~ \n",
      "\n",
      "</s> \n",
      "\n",
      "<S ID=\"0003\"> \n",
      "\n",
      "<h2>~k ~ ~ ~\\[1.</h2> \n",
      "\n",
      "</S> \n",
      "\n",
      "<s id=\"0004\"> \n",
      "\n",
      "<HR> (~T~-~Ã‚Â¢-#CJL.~) ,-~Ã‚Â¢~. \n",
      "\n",
      "</s> \n",
      "\n",
      "<S ID=\"0005\"> \n",
      "\n",
      "~ $ ~  19-27 \\]~ <hr> \n",
      "\n",
      "<\\]S> \n",
      "\n",
      "<s id=\"0005\"> <s id=\"0006\"> \n",
      "\n",
      "<H3>PRINCIPLES FOR REDESIGNING TEACHER <H3>.~ K~4VT ~'~ ~ ~J </H3> ALAN TOM \n",
      "\n",
      "education </h3> alan tom </center> </center> \n",
      "\n",
      "<IS> <IS> \n",
      "\n",
      "<s id=\"0006\"> <s id=\"0007\"> \n",
      "\n",
      "<P> <B> <I> ABSTRACT </I> </B> <P> <I> <B> ~4\\[- </B> </I> <P> \n",
      "\n",
      "</s> </s> \n",
      "\n",
      "FIGURE 3: AN ALIGNMENT EXAMPLE CONSIDERING COGNATES. \n",
      "\n",
      "divided into sentences. the sentences are marked by \n",
      "\n",
      "<S ID=\"XXXX\"> AND </S>.  NOTE THAT WE DETERMINE \n",
      "\n",
      "sentences not only by periods, but also by means of \n",
      "\n",
      "HTML MARKUP. \n",
      "\n",
      "we further notice that it is difficult to align sen- \n",
      "\n",
      "TENCES 0002. THE SENTENCE IN THE CHINESE PAGE IS \n",
      "\n",
      "much longer than its counterpart in the english page \n",
      "\n",
      "BECAUSE SOME ADDITIONAL INFORMATION (FONT) IS ADDED. \n",
      "\n",
      "the length-based method thus tends to take sen- \n",
      "\n",
      "TENCE 0002, 0003, AND 0004 IN THE ENGLISH PAGE AS \n",
      "\n",
      "the translation of sentence 0002 in the chinese page \n",
      "\n",
      "(FIG. 2), WHICH IS WRONG. THIS IN TURN PROVOCATED \n",
      "\n",
      "the three following incorrect alignments. as we can \n",
      "\n",
      "SEE IN FIG. 3, THE COGNATE METHOD DID NOT MAKE THE \n",
      "\n",
      "same mistake because of the noise in sentence 0002. \n",
      "\n",
      "DESPITE THEIR LARGE LENGTH DIFFERENCE, THE TWO 0002 \n",
      "\n",
      "sentences are still aligned as a 1-1 pair, because the \n",
      "\n",
      "SENTENCES IN THE FOLLOWING 4 ALIGNMENTS (0003 - 0003; \n",
      "\n",
      "0004 - 0004, 0005; 0005 - 0006; 0006 - 0007) have \n",
      "\n",
      "RATHER SIMILAR HTML MARKUPS AND ARE TAKEN BY THE \n",
      "\n",
      "program to be the most likely alignments. \n",
      "\n",
      "BESIDE HTML MARKUPS, OTHER CRITERIA MAY ALSO \n",
      "\n",
      "be incorporated. for example, it would be helpful \n",
      "\n",
      "TO CONSIDER STRONG CORRESPONDENCE B TWEEN CERTAIN \n",
      "\n",
      "english and chinese words, as in (wu, 1994). we \n",
      "\n",
      "HOPE TO IMPLEMENT SUCH CORRESPONDENCES IN OUR FU- \n",
      "\n",
      "ture research. \n",
      "\n",
      "3.4 LEX ICON  EVA LUAT ION  \n",
      "\n",
      "to evaluate the precision of the english-chinese \n",
      "\n",
      "TRANSLATION MODEL TRAINED ON THE WEB CORPUS, WE \n",
      "\n",
      "examined two sample lexicons of 200 words, one in \n",
      "\n",
      "EACH DIRECTION. THE 200 WORDS FOR EACH LEXICON WERE \n",
      "\n",
      "randomly selected from the training source. we ex- \n",
      "\n",
      "AMINED THE MOST PROBABLE TRANSLATION FOR EACH WORD. \n",
      "\n",
      "the chinese-english lexicon was found to have a \n",
      "\n",
      "PRECISION OF 77%. THE ENGLISH-CHINESE L XICON HAS \n",
      "\n",
      "a higher precision of 81.5%. part of the lexicons \n",
      "\n",
      "ARE SHOWN IN FIG. 4, WHERE T / F  INDICATES WHETHER A \n",
      "\n",
      "translation is true or false. \n",
      "\n",
      "THESE PRECISIONS SEEM TO BE REASONABLY HIGH. \n",
      "\n",
      "they are quite comparable to that obtained by wu \n",
      "\n",
      "(1994) USING A MANUAL CHINESE-ENGLISH PARALLEL COR- \n",
      "\n",
      "pus. \n",
      "\n",
      "3.5 EFFECT  O F  S TOPWORDS  \n",
      "\n",
      "we also found that stop-lists have significant effect \n",
      "\n",
      "ON THE TRANSLATION MODEL. STOP-LIST IS A SET OF THE \n",
      "\n",
      "most frequent words that we remove from the train- \n",
      "\n",
      "2FI \n",
      "\n",
      "english word \n",
      "\n",
      "A .N L .  \n",
      "\n",
      "access \n",
      "\n",
      "ADAPTATION \n",
      "\n",
      "add \n",
      "\n",
      "ADOPT \n",
      "\n",
      "agent \n",
      "\n",
      "AGREE \n",
      "\n",
      "airline \n",
      "\n",
      "AMENDMENT \n",
      "\n",
      ", appliance \n",
      "\n",
      "APPLY \n",
      "\n",
      "attendance \n",
      "\n",
      "AUDITOR \n",
      "\n",
      "- ,average \n",
      "\n",
      "BASE_ON \n",
      "\n",
      "t/f \n",
      "\n",
      "T \n",
      "\n",
      "f \n",
      "\n",
      "T \n",
      "\n",
      "t \n",
      "\n",
      "T \n",
      "\n",
      "t \n",
      "\n",
      "T \n",
      "\n",
      "t \n",
      "\n",
      "T \n",
      "\n",
      "t \n",
      "\n",
      "T \n",
      "\n",
      "t \n",
      "\n",
      "F \n",
      "\n",
      "t \n",
      "\n",
      "F \n",
      "\n",
      "translmion probability chinese word \n",
      "\n",
      "~'~- 0.201472 ~T L :  \n",
      "\n",
      "~\"  0.071705 \"~\"  \n",
      "\n",
      "~F~.,~ 0.179633 JLLL~ \n",
      "\n",
      "0.317435 \n",
      "\n",
      "~ 0.231637 ~.~ \n",
      "\n",
      "1~ta~ 0.224902 4j~'~ \n",
      "\n",
      "0.36569 \n",
      "\n",
      "0.344001 \n",
      "\n",
      "0.367518 \n",
      "\n",
      "j~ 4~ 0.136319 \n",
      "\n",
      "I~.~I 0.19448 J~  \n",
      "\n",
      "~',1~ 0.171769 ,~- jj~ \n",
      "\n",
      "*~ 0.15011 -~-~ \n",
      "\n",
      "~- ~ 0.467646 * *~ \n",
      "\n",
      "0.107304 \n",
      "\n",
      "figure 4: part of the evaluation lexicons. \n",
      "\n",
      "T/F \n",
      "\n",
      "t \n",
      "\n",
      "T \n",
      "\n",
      "t \n",
      "\n",
      "T \n",
      "\n",
      "t \n",
      "\n",
      "F \n",
      "\n",
      "t \n",
      "\n",
      "F \n",
      "\n",
      "t \n",
      "\n",
      "T \n",
      "\n",
      "t \n",
      "\n",
      "T \n",
      "\n",
      "t \n",
      "\n",
      "T \n",
      "\n",
      "t \n",
      "\n",
      "TRANSLATION PROBABILITY \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "office 0.375868 \n",
      "\n",
      "PROTECTION 0.343071 \n",
      "\n",
      "report 0.358592 \n",
      "\n",
      "PREPARE 0.189513 \n",
      "\n",
      "loca l  0.421837 \n",
      "\n",
      "FOLLOW 0.023685 \n",
      "\n",
      "standard 0.445453 \n",
      "\n",
      "ADU L T  0.044959 \n",
      "\n",
      "inadequate 0.093012 \n",
      "\n",
      "PART 0.313676 \n",
      "\n",
      "financial 0.16608 \n",
      "\n",
      "VISIT 0.309642 \n",
      "\n",
      "bill 0.401997 \n",
      "\n",
      "VEHICLE 0.467034 \n",
      "\n",
      "saving 0.176695 \n",
      "\n",
      "FIGURE 5: EFFECT OF STOP LISTS IN C-E TRANSLATION. \n",
      "\n",
      "ing source. because these words exist in most align- \n",
      "\n",
      "MENTS, THE STATISTICAL MODEL CANNOT DERIVE CORRECT \n",
      "\n",
      "translations for them. more importantly, their ex- \n",
      "\n",
      "ISTENCE GREATLY AFFECTS THE ACCURACY OF OTHER TRANSLA- \n",
      "\n",
      "tions. they can be taken as translations for many \n",
      "\n",
      "WORDS. \n",
      "\n",
      "a priori, it would seem that both the english and \n",
      "\n",
      "CHINESE STOP-LISTS HOULD BE APPLIED TO ELIMINATE THE \n",
      "\n",
      "noise caused by them. interestingly, from our ob- \n",
      "\n",
      "SERVATION AND ANALYSIS WE CONCLUDED THAT FOR BETTER \n",
      "\n",
      "precision, only the stop-list of the target language \n",
      "\n",
      "SHOULD BE APPLIED IN THE MODEL TRAINING. \n",
      "\n",
      "we first explain why the stop-list of the target lan- \n",
      "\n",
      "GUAGE HAS TO BE APPLIED. ON THE LEFT SIDE OF FIG. 5, \n",
      "\n",
      "if the chinese word c exists in the same alignments \n",
      "\n",
      "WITH THE ENGLISH WORD E MORE THAN ANY OTHER CHI- \n",
      "\n",
      "nese words, c will be the most probable translation \n",
      "\n",
      "FOR E. BECAUSE OF THEIR FREQUENT APPEARANCE, SOME \n",
      "\n",
      "chinese stopwords may have more chances to be in \n",
      "\n",
      "THE SAME ALIGNMENTS WITH E. THE PROBABILITY OF THE \n",
      "\n",
      "translation e --+ c is then reduced (maybe ven less \n",
      "\n",
      "THAN THOSE OF THE INCORRECT ONES). THIS IS THE REASON \n",
      "\n",
      "why many english words are translated to \"~ '  (of) \n",
      "\n",
      "BY THE TRANSLATION MODEL TRAINED WITHOUT USING THE \n",
      "\n",
      "chinese stop-list. \n",
      "\n",
      "WE ALSO FOUND THAT IT IS NOT NECESSARY TO REMOVE \n",
      "\n",
      "the stopwords of the source language. in fact, as il- \n",
      "\n",
      "LUSTRATED ON THE RIGHT SIDE OF FIG. 5, THE EXISTENCE OF \n",
      "\n",
      "the english stopwords has two effects on the proba- \n",
      "\n",
      "BILITY OF THE TRANSLATION E -~ C: \n",
      "\n",
      "1 they may often be found together with the chi- \n",
      "\n",
      "NESE WORD C. OWING TO THE EXPECTATION MAXI- \n",
      "\n",
      "mization algorithm, the probability of e -~ c \n",
      "\n",
      "MAY THEREFORE BE REDUCED. \n",
      "\n",
      "2 on the other hand, there is a greater likelihood \n",
      "\n",
      "THAT ENGLISH STOPWORDS WILL BE FOUND TOGETHER \n",
      "\n",
      "with the most frequent chinese words. here, \n",
      "\n",
      "WE USE THE TERM \"CHINESE FREQUENT WORDS\" IN- \n",
      "\n",
      "stead of \"chinese stopwords\" because ven if a \n",
      "\n",
      "STOP-LIST IS APPLIED, THERE MAY STILL REMAIN SOME \n",
      "\n",
      "common words that have the same effect as the \n",
      "\n",
      "STOPWORDS. THE COEXISTENCE OFENGLISH AND CHI- \n",
      "\n",
      "nese frequent words reduces the probability that \n",
      "\n",
      "THE CHINESE FREQUENT WORDS ARE THE TRANSLATIONS \n",
      "\n",
      "of e, and thus raise the probability of e -+ c. \n",
      "\n",
      "THE SECOND EFFECT WAS FOUND TO BE MORE SIGNIFI- \n",
      "\n",
      "cant than the first, since the model trained without \n",
      "\n",
      "THE ENGLISH STOPWORDS HAS BETTER PRECISION THAN THE \n",
      "\n",
      "model trained with the english stopwords. for the \n",
      "\n",
      "CORRECT RANSLATIONS GIVEN BY BOTH MODELS, THE MODEL \n",
      "\n",
      "26\n",
      "\n",
      "MONO-LINGUAL IR \n",
      "\n",
      "translation model \n",
      "\n",
      "DICTIONARY \n",
      "\n",
      "c-e clir \n",
      "\n",
      "0.3861 \n",
      "\n",
      "0.1504 (39.0%mono) \n",
      "\n",
      "0.1530 (39.6%MONO) \n",
      "\n",
      "0.2583 (66.9%mono) \n",
      "\n",
      "E-C CLIR \n",
      "\n",
      "0.3976 \n",
      "\n",
      "0.1841 (46.3%MONO) \n",
      "\n",
      "0.1427 (35.9%mono) \n",
      "\n",
      "0.2232 (56.1%MONO) \n",
      "\n",
      "table 1: clir results. \n",
      "\n",
      "TRAINED WITHOUT CONSIDERING THE ENGLISH STOPWORDS \n",
      "\n",
      "gives higher probabilities. \n",
      "\n",
      "4 ENG L I SH -CH INESE  CL IR  RESU L TS  \n",
      "\n",
      "our final goal was to test the performance of the \n",
      "\n",
      "TRANSLATION MODELS TRAINED ON THE WEB PARALLEL COR- \n",
      "\n",
      "pora in clir. we conducted clir experiments u - \n",
      "\n",
      "ING THE SMART IR SYSTEM. \n",
      "\n",
      "4.1 results  \n",
      "\n",
      "THE ENGLISH TEST CORPUS (FOR C-E CLIR) WAS THE \n",
      "\n",
      "ap corpus used in trec6 and trec7. the short \n",
      "\n",
      "ENGLISH QUERIES WERE TRANSLATED MANUALLY INTO CHI- \n",
      "\n",
      "nese and then translated back to english by the \n",
      "\n",
      "TRANSLATION MODEL. THE CHINESE TEST CORPUS WAS THE \n",
      "\n",
      "one used in the trec5 and trec6 chinese track. \n",
      "\n",
      "IT CONTAINS BOTH CHINESE QUERIES AND THEIR ENGLISH \n",
      "\n",
      "translations. \n",
      "\n",
      "OUR EXPERIMENTS ON THESE TWO CORPORA PRODUCED \n",
      "\n",
      "the results hown in tab. 1. the precision of mono- \n",
      "\n",
      "LINGUAL IR IS GIVEN AS BENCHMARK. IN BOTH E-C AND \n",
      "\n",
      "c-e clir, the translation model achieved around \n",
      "\n",
      "40% OF MONOLINGUAL PRECISION. TO COMPARE WITH THE \n",
      "\n",
      "dictionary-based approach, we employed a chinese- \n",
      "\n",
      "ENGLISH DICTIONARY, CEDICT (DENISOWSKI, 1999), \n",
      "\n",
      "and an english-chinese online dictionary (anony- \n",
      "\n",
      "MOUS, 1999A) TO TRANSLATE QUERIES. FOR EACH WORD \n",
      "\n",
      "of the source query, all the possible translations \n",
      "\n",
      "GIVEN BY THE DICTIONARY ARE INCLUDED IN THE TRANSLATED \n",
      "\n",
      "query. the chinese-english dictionary has about \n",
      "\n",
      "THE SAME PERFORMACE AS THE TRANSLATION MODEL, WHILE \n",
      "\n",
      "the english-chinese dictionary has lower precision \n",
      "\n",
      "THAN THAT OF THE TRANSLATION MODEL. \n",
      "\n",
      "we also tried to combine the translations given by \n",
      "\n",
      "THE TRANSLATION MODEL AND THE DICTIONARY. IN BOTH \n",
      "\n",
      "c-e and e-c clir, significant improvements were \n",
      "\n",
      "ACHIEVED (AS SHOWN IN TAB. 1). THE IMPROVEMENTS \n",
      "\n",
      "show that the translations given by the translation \n",
      "\n",
      "MODEL AND THE DICTIONARY COMPLEMENT EACH OTHER \n",
      "\n",
      "well for ir purposes. the translation model may \n",
      "\n",
      "GIVE EITHER EXACT RANSLATIONS ORINCORRECT BUT RELATED \n",
      "\n",
      "words. even though these words are not correct in \n",
      "\n",
      "THE SENSE OF TRANSLATION, THEY ARE VERY POSSIBLY RE- \n",
      "\n",
      "lated to the subject of the query and thus helpful \n",
      "\n",
      "FOR IR PURPOSES. THE DICTIONARY-BASED APPROACH EX- \n",
      "\n",
      "pands a query along another dimension. it gives \n",
      "\n",
      "ALL THE POSSIBLE TRANSLATIONS FOR EACH WORD INCLUDING \n",
      "\n",
      "those that are missed by the translation model. \n",
      "\n",
      "4.2 COMPARISON WI TH  MT SYSTEMS \n",
      "\n",
      "one advantage of a parallel text-based translation \n",
      "\n",
      "MODEL IS THAT IT IS EASIER TO BUILD THAN AN MT SYSTEM. \n",
      "\n",
      "now that we have examined the clir performance \n",
      "\n",
      "OF THE TRANSLATION MODEL, WE WILL COMPARE IT WITH \n",
      "\n",
      "two existing mt systems. both systems were tested \n",
      "\n",
      "IN E-C CLIR. \n",
      "\n",
      "4.2.1 sunshine webtran server \n",
      "\n",
      "USING THE SUNSHINE WEBTRAN SERVER (ANONYMOUS, \n",
      "\n",
      "1999b), an online engiish-chinese mt system, to \n",
      "\n",
      "TRANSLATE THE 54 ENGLISH QUERIES, WE OBTAINED AN \n",
      "\n",
      "average precision of 0.2001, which is 50.3% of the \n",
      "\n",
      "MONO-LINGUAL PRECISION. THE PRECISION IS HIGHER THAN \n",
      "\n",
      "that obtained using the translation model (0.1804) \n",
      "\n",
      "OR THE DICTIONARY (0.1427) ALONE, BUT LOWER THAN THE \n",
      "\n",
      "precison obtained using them together (0.2232). \n",
      "\n",
      "4.2.2 TRANSPERFECT \n",
      "\n",
      "kwok (1999) investigated the clir performance of\n",
      "\n",
      "AN ENGLISH-CHINESE MT SOFTWARE CALLED TRANSPER- \n",
      "\n",
      "fect, using the same trec chinese collection as we \n",
      "\n",
      "USED IN THIS STUDY. USING THE MT SOFTWARE ALONE, \n",
      "\n",
      "kwok achieved 56% of monolingual precision. the \n",
      "\n",
      "PRECISION IS IMPROVED TO 62% BY REFINING THE TRANS- \n",
      "\n",
      "lation with a dictionary. kwok also adopted pre- \n",
      "\n",
      "TRANSLATION QUERY EXPANSION, WHICH FURTHER IMPROVED \n",
      "\n",
      "the precison to 70% of the monolingual results. \n",
      "\n",
      "IN OUR CASE, THE BEST E-C CLIR PRECISON USING THE \n",
      "\n",
      "translation model (and dictionary) is 56.1%. it is \n",
      "\n",
      "LOWER THAN WHAT KWOK ACHIEVED USING TRANSPERFECT, \n",
      "\n",
      "however, the difference is not large. \n",
      "\n",
      "4.3 FURTHER  PROBLEMS \n",
      "\n",
      "the chinese-english translation model has a fax \n",
      "\n",
      "LOWER CLIR PERFORMANCE THAN THAT OF THE ENGLISH- \n",
      "\n",
      "french model established using the same method \n",
      "\n",
      "(NIE ET AL., 1999). THE PRINCIPAL REASON FOR THIS IS THE \n",
      "\n",
      "fact that english and chinese are much more differ- \n",
      "\n",
      "ENT THAN ENGLISH AND FRENCH. THIS PROBLEM SURFACED \n",
      "\n",
      "in many phases of this work, from text alignment to \n",
      "\n",
      "QUERY TRANSLATION. BELOW, WE LIST SOME FURTHER FAC- \n",
      "\n",
      "tors affecting clir precision. \n",
      "\n",
      "Ã‚â‚¬Â¢ THE WEB-COLLECTED CORPUS IS NOISY AND IT IS DIF- \n",
      "\n",
      "ficult to align english-chinese t xts. the align- \n",
      "\n",
      "MENT METHOD WE EMPLOYED HAS PERFORMED MORE \n",
      "\n",
      "poorly than on english-french alignment. this \n",
      "\n",
      "IN TURN LEADS TO POORER PERFORMANCE OF THE TRANS- \n",
      "\n",
      "lation model. in general, we observe a higher \n",
      "\n",
      "27 \n",
      "\n",
      "variability in chinese-english translations than \n",
      "\n",
      "IN ENGLISH-FRENCH TRANSLATIONS. \n",
      "\n",
      "Ã¢â‚¬Â¢ for e-c clir, although queries in both lan- \n",
      "\n",
      "GUAGES WERE PROVIDED, THE ENGLISH QUERIES WERE \n",
      "\n",
      "not strictly translated from the original chi- \n",
      "\n",
      "NESE ONES. FOR EXAMPLE, A JG ,~ (HUMAN RIGHT \n",
      "\n",
      "situation) was translated into human right is- \n",
      "\n",
      "SUE. WE CANNOT EXPECT HE TRANSLATION MODEL \n",
      "\n",
      "to translate issue back to ~ (situation). \n",
      "\n",
      "Ã‚â‚¬Â¢ THE TRAINING SOURCE AND THE CLIR COLLECTIONS \n",
      "\n",
      "were from different domains. the web cor- \n",
      "\n",
      "PUS ARE RETRIEVED FROM THE PARALLEL SITES IN HONG \n",
      "\n",
      "kong while the chinese collection is from peo- \n",
      "\n",
      "PLE'S DAILY AND XINHUA NEWS AGENCY, WHICH ARE \n",
      "\n",
      "published in mainland china. as the result, \n",
      "\n",
      "SOME IMPORTANT ERMS SUCH AS ~$ $ (MOST- \n",
      "\n",
      "favored-nation) and --- i!! ~ ~ (one-nation-two- \n",
      "\n",
      "SYSTEMS) IN THE COLLECTION ARE NOT KNOWN BY THE \n",
      "\n",
      "model. \n",
      "\n",
      "5 SUMMARY  \n",
      "\n",
      "the goal of this work was to investigate he feasibil- \n",
      "\n",
      "ITY OF USING A STATISTICAL TRANSLATION MODEL TRAINED ON \n",
      "\n",
      "a web-collected corpus to do english-chinese clir. \n",
      "\n",
      "IN THIS PAPER, WE HAVE DESCRIBED THE ALGORITHM AND \n",
      "\n",
      "implementation we used for parallel text mining, \n",
      "\n",
      "TRANSLATION MODEL TRAINING, AND SOME RESULTS WE OB- \n",
      "\n",
      "tained in clir experiments. although further work \n",
      "\n",
      "REMAINS TO BE DONE, WE CAN CONCLUDE THAT IT IS POS- \n",
      "\n",
      "sible to automatically construct a chinese-english \n",
      "\n",
      "PARALLEL CORPUS FROM THE WEB. THE CURRENT SYSTEM \n",
      "\n",
      "can be easily adapted to other language pairs. de- \n",
      "\n",
      "SPITE THE NOISY NATURE OF THE CORPUS AND THE GREAT \n",
      "\n",
      "difference in the languages, the evaluation lexicons \n",
      "\n",
      "GENERATED BY THE TRANSLATION MODEL PRODUCED ACCEPT- \n",
      "\n",
      "able precision. while the current clir results are \n",
      "\n",
      "NOT AS ENCOURAGING ASTHOSE OF ENGLISH-FRENCH CLIR, \n",
      "\n",
      "they could be improved in various ways, such as im- \n",
      "\n",
      "PROVING THE ALIGNMENT METHOD BY ADAPTING COGNATE \n",
      "\n",
      "definitions to html markup, incorporating a lexi- \n",
      "\n",
      "CON AND/OR REMOVING SOME COMMON FUNCTION WORDS \n",
      "\n",
      "in translated queries. \n",
      "\n",
      "WE HOPE TO BE ABLE TO DEMONSTRATE IN THE NEAR \n",
      "\n",
      "future that a fine-tuned english-chinese translation \n",
      "\n",
      "MODEL CAN PROVIDE QUERY TRANSLATIONS FOR CLIR WITH \n",
      "\n",
      "the same quality produced by mt systems. \n",
      "\n",
      "RE FERENCES  \n",
      "\n",
      "anonymous. 1999a. sunrain.net - english-chinese \n",
      "\n",
      "DICTIONARY, HTTP://SUNRAIN.NET/R_ECDICT _E.HTM. \n",
      "\n",
      "anonymous. 1999b. sunshine webtran server. \n",
      "\n",
      "HTTP://WWW.READWORLD.COM/TRANSLATE.HTM. \n",
      "\n",
      "p. f. brown, j. c. lai, and r. l. mercer. 1991. \n",
      "\n",
      "ALIGNING SENTENCES IN PARALLEL CORPORA. IN 29TH \n",
      "\n",
      "annual meeting of the association for computa- \n",
      "\n",
      "TIONAL LINGUISTICS, PAGES 89-94, BERKELEY, CALIF. \n",
      "\n",
      "p. f. brown, s. a. della pietra, v. j. della pietra, \n",
      "\n",
      "AND R. L. MERCER. 1993. THE MATHEMATICS OF MA- \n",
      "\n",
      "chine translation: parameter estimation. compu- \n",
      "\n",
      "TATIONAL LINGUISTICS, 19:263-311. \n",
      "\n",
      "s. f. chen. 1993. aligning sentences in bilingual \n",
      "\n",
      "CORPORA USING LEXICAL INFORMATION. IN PROCEEDINGS \n",
      "\n",
      "of the 31th annual meeting of the association for \n",
      "\n",
      "COMPUTATIONAL LINGUISTICS, PAGES 9-16, COLUM- \n",
      "\n",
      "bus, ohio. \n",
      "\n",
      "PAUL DENISOWSKI. 1999. CEDICT (CHINESE-ENGLISH DIC- \n",
      "\n",
      "tionary) project, http://www.mindspring.com/ \n",
      "\n",
      "PAUL_DENISOWSKI/CEDICT.HTML. \n",
      "\n",
      "william a. gale and kenneth w. church. 1991. a \n",
      "\n",
      "PROGRAM FOR ALIGNING SENTENCES IN BILINGUAL COR- \n",
      "\n",
      "pora. in proceedings of the 29th annual meeting \n",
      "\n",
      "OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, \n",
      "\n",
      "pages 177-184, berkeley, calif. \n",
      "\n",
      "P. ISABELLE, G. FOSTER, AND P. PLAMONDON. \n",
      "\n",
      "1997. silc: un syst~me d'identification \n",
      "\n",
      "DE LA LANGUE ET DU CODAGE, HTTP://WWW- \n",
      "\n",
      "rali.iro.umontreal.ca/projetsilc.en.html. \n",
      "\n",
      "M. KAY AND M. RSSCHEISEN. 1993. TEXT-TRANSLATION \n",
      "\n",
      "alignment. computational linguistics, 19:121- \n",
      "\n",
      "142. \n",
      "\n",
      "k. l. kwok. 1999. english-chinese cross-language \n",
      "\n",
      "RETRIEVAL BASED ON A TRANSLATION PACKAGE. IN WORK- \n",
      "\n",
      "shop of machine translation for cross language \n",
      "\n",
      "INFORMATION RETRIEVAL, MACHINE TRANSLATION SUM- \n",
      "\n",
      "mit vii, singapore. \n",
      "\n",
      "P. LANGLAIS, G. FOSTER, AND G. LAPALME. 2000. UNIT \n",
      "\n",
      "completion for a computer-aided translation typ- \n",
      "\n",
      "ING SYSTEM. IN APPLIED NATURAL LANGUAGE PRO- \n",
      "\n",
      "cessing conference (anlp), seattle, washington, \n",
      "\n",
      "MAY. \n",
      "\n",
      "jianyun nie, michel simard, pierre isabelle, and \n",
      "\n",
      "RICHARD DURAND. 1999. CROSS-LANGUAGE INFORMA- \n",
      "\n",
      "tion retrieval based on parallel texts and auto- \n",
      "\n",
      "MATIC MINING PARALLEL TEXTS FROM THE WEB. IN \n",
      "\n",
      "acm sigir '99, pages 74-81, august. \n",
      "\n",
      "PHILIP RESNIK. 1998. PARALLEL STANDS: A PRELIMINARY \n",
      "\n",
      "investigation i to mining the web for bilingual \n",
      "\n",
      "TEXT. IN AMTA '98, OCTOBER. \n",
      "\n",
      "michel simard, george f. foster, and pierre is- \n",
      "\n",
      "ABELLE. 1992. USING COGNATES TO ALIGN SENTENCES \n",
      "\n",
      "in bilingual corpora. in proceedings of tmi-92, \n",
      "\n",
      "MONTREAL, QUEBEC. \n",
      "\n",
      "dekai wu. 1994. aligning a parallel english- \n",
      "\n",
      "CHINESE CORPUS STATISTICALLY WITH LEXICAL CRITERIA. \n",
      "\n",
      "in acl-9$: 32nd annual meeting of the assoc. \n",
      "\n",
      "FOR COMPUTATIONAL LINGUISTICS, PAGES 80-87, LAS \n",
      "\n",
      "cruces, nm, june. \n",
      "\n",
      "DEKAI WU. 1995. LARGE-SCALE AUTOMATIC EXTRACTION \n",
      "\n",
      "of an english-chinese l xicon. machine transla- \n",
      "\n",
      "TION, 9(3-4):285-313. \n",
      "\n",
      "28 \n",
      "\n",
      "PARTSLD: A DIALOGUE-BASED SYSTEM FOR IDENTIFYING PARTS FOR MEDICAL \n",
      "\n",
      "systems \n",
      "\n",
      "AMIT BAGGA, TOMEK STRZALKOWSKI, AND G. BOWDEN WISE \n",
      "\n",
      "information technology laboratory \n",
      "\n",
      "GE CORPORATE RESEARCH AND DEVELOPMENT \n",
      "\n",
      "1 research circle \n",
      "\n",
      "NISKAYUNA, USA, NY 12309 \n",
      "\n",
      "{ bagga, strzalkowski, wisegb } @crd.ge.com \n",
      "\n",
      "ABSTRACT \n",
      "\n",
      "this paper describes a system that \n",
      "\n",
      "PROVIDES CUSTOMER SERVICE BY ALLOWING \n",
      "\n",
      "users to retrieve identification umbers of \n",
      "\n",
      "PARTS FOR MEDICAL SYSTEMS USING SPOKEN \n",
      "\n",
      "natural language dialogue. the paper also \n",
      "\n",
      "PRESENTS AN EVALUATION OF THE SYSTEM \n",
      "\n",
      "which shows that the system successfully \n",
      "\n",
      "RETRIEVES THE IDENTIFICATION NUMBERS OF \n",
      "\n",
      "approximately 80% of the parts. \n",
      "\n",
      "INTRODUCTION \n",
      "\n",
      "currently people deal with customer service \n",
      "\n",
      "CENTERS EITHER OVER THE PHONE OR ON THE WORLD \n",
      "\n",
      "wide web on a regular basis. these service \n",
      "\n",
      "CENTERS UPPORT A WIDE VARIETY OF TASKS INCLUDING \n",
      "\n",
      "checking the balance of a bank or a credit card \n",
      "\n",
      "ACCOUNT, TRANSFERRING MONEY FROM ONE ACCOUNT O \n",
      "\n",
      "another, buying airline tickets, and filing one's \n",
      "\n",
      "INCOME TAX RETURNS. MOST OF THESE CUSTOMER \n",
      "\n",
      "service centers use interactive voice response \n",
      "\n",
      "(IVR) SYSTEMS ON THE FRONT-END FOR DETERMINING \n",
      "\n",
      "the user's need by providing a list of options that \n",
      "\n",
      "THE USER CAN CHOOSE FROM, AND THEN ROUTING THE \n",
      "\n",
      "call appropriately. the ivrs also gather \n",
      "\n",
      "ESSENTIAL INFORMATION LIKE THE USER'S BANK \n",
      "\n",
      "account number, social security number, etc. \n",
      "\n",
      "FOR BACK-END SUPPORT, THE CUSTOMER SERVICE \n",
      "\n",
      "centers use either specialized computer systems \n",
      "\n",
      "(EXAMPLE: A SYSTEM THAT RETRIEVES THE ACCOUNT \n",
      "\n",
      "balance from a database), or, as in most cases, \n",
      "\n",
      "HUMAN OPERATORS. \n",
      "\n",
      "however, the ivr systems are unwieldy \n",
      "\n",
      "TO USE. OFTEN A USER'S NEEDS ARE NOT COVERED BY \n",
      "\n",
      "the options provided by the system forcing the \n",
      "\n",
      "USER TO HIT 0 TO TRANSFER TO A HUMAN OPERATOR. IN \n",
      "\n",
      "addition, frequent users often memorize the \n",
      "\n",
      "SEQUENCE OF OPTIONS THAT WILL GET THEM THE \n",
      "\n",
      "desired information. therefore, any change in \n",
      "\n",
      "THE OPTIONS GREATLY INCONVENIENCES THESE USERS. \n",
      "\n",
      "moreover, there are users that always hit 0 to \n",
      "\n",
      "SPEAK TO A LIVE OPERATOR BECAUSE THEY PREFER TO \n",
      "\n",
      "deal with a human instead of a machine. \n",
      "\n",
      "FINALLY, AS CUSTOMER SERVICE PROVIDERS CONTINUE \n",
      "\n",
      "to rapidly add functionality to their ivr \n",
      "\n",
      "SYSTEMS, THE SIZE AND COMPLEXITY OF THESE \n",
      "\n",
      "systems continues to grow proportionally. in \n",
      "\n",
      "SOME POPULAR SYSTEMS LIKE THE IVR SYSTEM THAT \n",
      "\n",
      "provides customer service for the internal \n",
      "\n",
      "REVENUE SERVICE (IRS), THE USER IS INITIALLY \n",
      "\n",
      "bombarded with 10 different options with each \n",
      "\n",
      "OPTION LEADING TO SUB-MENUS OFFERING A FURTHER 3- \n",
      "\n",
      "5 options, and so on. the total number of nodes \n",
      "\n",
      "IN THE TREE CORRESPONDING TO THE IRS' IVR SYSTEM \n",
      "\n",
      "is quite large (approximately 100) making it \n",
      "\n",
      "EXTREMELY COMPLEX TO USE. \n",
      "\n",
      "some customer service providers have \n",
      "\n",
      "STARTED TO TAKE ADVANTAGE OF THE RECENT ADVANCES \n",
      "\n",
      "in speech recognition technology. therefore, \n",
      "\n",
      "SOME OF THE IVR SYSTEMS NOW ALLOW USERS TO SAY \n",
      "\n",
      "the option number (1, 2, 3 . . . . .  etc.) instead of \n",
      "\n",
      "PRESSING THE CORRESPONDING BUTTON. IN ADDITION, \n",
      "\n",
      "some providers have taken this a step further by \n",
      "\n",
      "ALLOWING USERS TO SAY A KEYWORD OR A PHRASE \n",
      "\n",
      "from a list of keywords and/or phrases. for \n",
      "\n",
      "EXAMPLE, AT&T, THE LONG DISTANCE COMPANY, \n",
      "\n",
      "provides their users the following options: \n",
      "\n",
      "\"PLEASE SAY INFORMATION FOR INFORMATION ON \n",
      "\n",
      "placing a call, credit for requesting credit, or \n",
      "\n",
      "OPERATOR TO SPEAK TO AN OPERATOR.\" \n",
      "\n",
      "however, given the improved speech \n",
      "\n",
      "RECOGNITION TECHNOLOGY, AND THE RESEARCH DONE IN \n",
      "\n",
      "natural anguage dialogue over the last decade, \n",
      "\n",
      "THERE EXISTS TREMENDOUS POTENTIAL IN ENHANCING \n",
      "\n",
      "29 \n",
      "\n",
      "THESE CUSTOMER SERVICE CENTERS BY ALLOWING USERS \n",
      "\n",
      "to conduct a more natural human-like dialogue \n",
      "\n",
      "WITH AN AUTOMATED SYSTEM TO PROVIDE A \n",
      "\n",
      "customer-friendly s stem. in this paper we \n",
      "\n",
      "DESCRIBE A SYSTEM THAT USES NATURAL LANGUAGE \n",
      "\n",
      "dialogue to provide customer service for a \n",
      "\n",
      "MEDICAL DOMAIN. THE SYSTEM ALLOWS FIELD \n",
      "\n",
      "engineers to call and obtain identification \n",
      "\n",
      "NUMBERS OF PARTS FOR MEDICAL SYSTEMS USING \n",
      "\n",
      "natural language dialogue. we first describe \n",
      "\n",
      "SOME WORK DONE PREVIOUSLY IN USING NATURAL \n",
      "\n",
      "language dialogue for customer service \n",
      "\n",
      "APPLICATIONS. NEXT, WE PRESENT HE ARCHITECTURE \n",
      "\n",
      "of our system along with a description of each of \n",
      "\n",
      "THE KEY COMPONENTS. FINALLY, WE CONCLUDE BY \n",
      "\n",
      "providing results from an evaluation of the \n",
      "\n",
      "SYSTEM. \n",
      "\n",
      "1. previous work \n",
      "\n",
      "AS MENTIONED EARLIER, SOME CUSTOMER SERVICE \n",
      "\n",
      "centers now allow users to say either the option \n",
      "\n",
      "NUMBER OR A KEYWORD FROM A LIST OF \n",
      "\n",
      "options/descriptions. however, the only known \n",
      "\n",
      "WORK WHICH AUTOMATES PART OF A CUSTOMER SERVICE \n",
      "\n",
      "center using natural language dialogue is the one \n",
      "\n",
      "BY CHU-CARROLL AND CARPENTER (1999). THE \n",
      "\n",
      "system described here is used as the front-end of \n",
      "\n",
      "A BANK'S CUSTOMER SERVICE CENTER. IT ROUTES CALLS \n",
      "\n",
      "by extracting key phrases from a user utterance \n",
      "\n",
      "AND THEN BY STATISTICALLY COMPARING THESE PHRASES \n",
      "\n",
      "to phrases extracted from utterances in a training \n",
      "\n",
      "CORPUS CONSISTING OF PRE-RECORDED CALLS WHERE \n",
      "\n",
      "the routing was done by a human. the call is \n",
      "\n",
      "ROUTED TO THE DESTINATION OF THE UTTERANCE FROM \n",
      "\n",
      "the training corpus that is most \"similar\" to the \n",
      "\n",
      "CURRENT UTTERANCE. ON OCCASION, THE SYSTEM WILL \n",
      "\n",
      "interact with the user to clarify the user's request \n",
      "\n",
      "BY ASKING A QUESTION. FOR EXAMPLE, IF THE USER \n",
      "\n",
      "wishes to reach the loan department, the system \n",
      "\n",
      "WILL ASK IF THE LOAN IS FOR AN AUTOMOBILE, OR A \n",
      "\n",
      "home. other related work is (georgila et al., \n",
      "\n",
      "1998). \n",
      "\n",
      "while we are aware of the work being \n",
      "\n",
      "DONE BY SPEECH RECOGNITION COMPANIES LIKE \n",
      "\n",
      "nuance (www.nuance.com) and speechworks \n",
      "\n",
      "(WWW.SPEECHWORKS.COM) IN THE AREA OF \n",
      "\n",
      "providing more natural anguage dialogue-based \n",
      "\n",
      "CUSTOMER SERVICE, WE ARE NOT AWARE OF ANY \n",
      "\n",
      "conference or journal publications from them. \n",
      "\n",
      "SOME MAGAZINE ARTICLES WHICH MENTION THEIR \n",
      "\n",
      "work are (rosen 1999; rossheim 1999; \n",
      "\n",
      "GREENEMEIER 1999 ; MEISEL 1999). IN ADDITION, \n",
      "\n",
      "when we tried out a demo of nuance's ystems, \n",
      "\n",
      "WE FOUND THAT THEIR SYSTEMS HAD A VERY IVRISH \n",
      "\n",
      "feel to them. for example, if one wanted to \n",
      "\n",
      "TRANSFER $50 FROM ONE ACCOUNT O ANOTHER, THE \n",
      "\n",
      "system would first ask the account that the \n",
      "\n",
      "MONEY WAS COMING FROM, THEN THE ACCOUNT HAT \n",
      "\n",
      "the money was going to, and finally, the amount \n",
      "\n",
      "TO BE TRANSFERRED. THEREFORE, A USER COULD NOT \n",
      "\n",
      "say \"i want to transfer $50 from my savings \n",
      "\n",
      "ACCOUNT O MY CHECKING ACCOUNT\" AND HAVE THE \n",
      "\n",
      "system conduct that transaction. \n",
      "\n",
      "IN ADDITION TO THE WORKS MENTIONED ABOVE, \n",
      "\n",
      "there have been several classic projects in the \n",
      "\n",
      "AREA OF NATURAL LANGUAGE DIALOGUE LIKE \n",
      "\n",
      "trains/trips project at rochester (allen et \n",
      "\n",
      "AL., 1989, 1995, 1996), DUKE'S CIRCUIT-FIXIT- \n",
      "\n",
      "shoppe and pascal tutoring system (biermann \n",
      "\n",
      "ET AL., 1997; 1995), ETC. WHILE THE CIRCUIT-FIXIT- \n",
      "\n",
      "shoppe system helps users fix a circuit through a\n",
      "\n",
      "DIALOGUE WITH THE SYSTEM, THE TRIPS AND THE \n",
      "\n",
      "trains projects allow users to plan their \n",
      "\n",
      "ITINERARIES THROUGH DIALOGUE. DUKE'S PASCAL \n",
      "\n",
      "tutoring system helps students in an introductory \n",
      "\n",
      "PROGRAMMING CLASS DEBUG THEIR PROGRAMS BY \n",
      "\n",
      "allowing them to analyze their syntax errors, get \n",
      "\n",
      "ADDITIONAL INFORMATION ON THE ERROR, AND LEARN THE \n",
      "\n",
      "correct syntax. although these systems have \n",
      "\n",
      "BEEN QUITE SUCCESSFUL, THEY USE DETAILED MODELS \n",
      "\n",
      "of the domain and therefore cannot be used for \n",
      "\n",
      "DIVERSE APPLICATIONS UCH AS THE ONES REQUIRED \n",
      "\n",
      "for customer service centers. other related work \n",
      "\n",
      "ON DIALOGUE INCLUDE (CARBERRY, 1990; GROSZ AND \n",
      "\n",
      "sidner, 1986; reichman, 1981). \n",
      "\n",
      "2. PARTSLD: A SYSTEM FOR IDENTIFICATION \n",
      "\n",
      "of parts for medical systems \n",
      "\n",
      "INITIALLY, WE WERE APPROACHED BY THE MEDICAL \n",
      "\n",
      "systems business of our company for help in \n",
      "\n",
      "REDUCING THE NUMBER OF CALLS HANDLED BY HUMAN \n",
      "\n",
      "operators at their call center. an analysis of the \n",
      "\n",
      "TYPES OF CUSTOMER SERVICE PROVIDED BY THEIR CALL \n",
      "\n",
      "center showed that a large volume of calls \n",
      "\n",
      "HANDLED BY THEIR OPERATORS WERE PLACED BY FIELD \n",
      "\n",
      "engineers requesting identification umbers of \n",
      "\n",
      "PARTS FOR VARIOUS MEDICAL SYSTEMS. THE ID \n",
      "\n",
      "numbers were most often used for ordering the \n",
      "\n",
      "CORRESPONDING PARTS USING AN AUTOMATED IVR \n",
      "\n",
      "system. therefore, the system we have built \n",
      "\n",
      "30 \n",
      "\n",
      "figure 1. partsld system architecture \n",
      "\n",
      "W \n",
      "\n",
      "i parser l \n",
      "\n",
      "~ USER \n",
      "\n",
      "dia logue  manager  \n",
      "\n",
      "F . , .  \n",
      "\n",
      "pros entetion \n",
      "\n",
      "HELPS AUTOMATE SOME PERCENTAGE OF THESE CALLS \n",
      "\n",
      "by allowing the engineer to describe a part using \n",
      "\n",
      "NATURAL LANGUAGE. THE REST OF THIS SECTION \n",
      "\n",
      "describes our system in detail. \n",
      "\n",
      "2.1 DATA \n",
      "\n",
      "the database we used for our system was the \n",
      "\n",
      "SAME AS THE ONE USED BY THE OPERATORS AT THE CALL \n",
      "\n",
      "center. this database consists of the most \n",
      "\n",
      "COMMON PARTS AND WAS BUILT BY THE OPERATORS \n",
      "\n",
      "themselves. however, the data contained in the \n",
      "\n",
      "DATABASE IS NOT CLEAN AND THERE ARE SEVERAL TYPES \n",
      "\n",
      "of errors including mis-spellings, use of non- \n",
      "\n",
      "STANDARD ABBREVIATIONS, USE OF SEVERAL DIFFERENT \n",
      "\n",
      "abbreviations for the same word, etc. \n",
      "\n",
      "THE DATABASE CONSISTS OF APPROXIMATELY \n",
      "\n",
      "7000 different parts. for each part, the database \n",
      "\n",
      "CONTAINS ITS IDENTIFICATION UMBER, A DESCRIPTION, \n",
      "\n",
      "and the product (machine type) that it is used in. \n",
      "\n",
      "THE DESCRIPTIONS CONSIST OF APPROXIMATELY \n",
      "\n",
      "60,000 unique words of which approximately \n",
      "\n",
      "3,000 ARE WORDS WHICH EITHER ARE NON-STANDARD \n",
      "\n",
      "abbreviations or are unique to the medical \n",
      "\n",
      "DOMAIN (EXAMPLE: COLLIMATOR). \n",
      "\n",
      "due to the large size of the database, we \n",
      "\n",
      "DID NOT ATTEMPT TO CLEAN THE DATA. HOWEVER, WE \n",
      "\n",
      "did build several data structures based on the \n",
      "\n",
      "DATABASE WHICH WERE USED BY THE SYSTEM. THE \n",
      "\n",
      "primary data structures built were two inverted \n",
      "\n",
      "HASH TABLES CORRESPONDING TO THE PRODUCT, AND THE \n",
      "\n",
      "part description fields in the database. the \n",
      "\n",
      "INVERTED HASH TABLES WERE BUILT AS FOLLOWS: \n",
      "\n",
      "1) each product and part description field \n",
      "\n",
      "WAS SPLIT INTO WORDS. \n",
      "\n",
      "2) stop-words (words containing no \n",
      "\n",
      "INFORMATION LIKE: A, THE, AN, ETC.) WERE \n",
      "\n",
      "filtered. \n",
      "\n",
      "3) EACH REMAINING WORD WAS INSERTED AS THE \n",
      "\n",
      "index of the appropriate hash table with \n",
      "\n",
      "THE IDENTIFICATION NUMBER OF THE PART \n",
      "\n",
      "being the value corresponding to the \n",
      "\n",
      "INDEX. \n",
      "\n",
      "therefore, for each non-stop-word word used in \n",
      "\n",
      "DESCRIBING A PART, THE HASH TABLE CONTAINS A LIST OF \n",
      "\n",
      "all the parts whose descriptions contained that \n",
      "\n",
      "WORD. SIMILARLY, THE PRODUCTS HASH TABLE \n",
      "\n",
      "contains a list of all parts corresponding to each \n",
      "\n",
      "PRODUCT WORD. \n",
      "\n",
      "2.2 system architecture \n",
      "\n",
      "THE ARCHITECTURE OF THE SYSTEM IS SHOWN IN \n",
      "\n",
      "figure 1. the system was designed in a manner \n",
      "\n",
      "SUCH THAT IT COULD BE EASILY PORTED FROM ONE \n",
      "\n",
      "application to another with minimal effort other \n",
      "\n",
      "THAN PROVIDING THE DOMAIN-SPECIFIC KNOWLEDGE \n",
      "\n",
      "regarding the new application. therefore, we \n",
      "\n",
      "DECIDED TO ABSTRACT AWAY THE DOMAIN-SPECIFIC \n",
      "\n",
      "information into self-contained modules while \n",
      "\n",
      "KEEPING THE OTHER MODULES COMPLETELY \n",
      "\n",
      "independent. the domain-specific modules are \n",
      "\n",
      "SHOWN IN THE DARK SHADED BOXES IN FIGURE I. \n",
      "\n",
      "the remainder of this section discusses each of \n",
      "\n",
      "THE MODULES HOWN IN THE SYSTEM ARCHITECTURE. \n",
      "\n",
      "2.2.1 the speech recognition system (asr) \n",
      "\n",
      "SINCE CUSTOMER SERVICE CENTERS ARE MEANT O BE \n",
      "\n",
      "used by a variety of users, we needed a user- \n",
      "\n",
      "INDEPENDENT SPEECH RECOGNITION SYSTEM. IN \n",
      "\n",
      "31 \n",
      "\n",
      "ADDITION, SINCE THE SYSTEM COULD NOT RESTRICT HE \n",
      "\n",
      "manner in which a user asked for service, the \n",
      "\n",
      "SPEECH RECOGNITION SYSTEM COULD NOT BE \n",
      "\n",
      "grammar-based. therefore, we used a general \n",
      "\n",
      "PURPOSE DICTATION ENGINE FOR THE SYSTEM. THE \n",
      "\n",
      "dictation system used was lernout & hauspie's \n",
      "\n",
      "VOICEXPRESS YSTEM (WWW.LHS.COM). ALTHOUGH \n",
      "\n",
      "the system was general purpose, we did provide \n",
      "\n",
      "TO IT THE SET OF KEYWORDS AND PHRASES THAT ARE \n",
      "\n",
      "commonly used in the domain thereby enabling \n",
      "\n",
      "IT TO BETTER RECOGNIZE THESE DOMAIN-SPECIFIC \n",
      "\n",
      "keywords and phrases. the keywords and \n",
      "\n",
      "PHRASES USED WERE SIMPLY THE LIST OF DESCRIPTIONS \n",
      "\n",
      "and product names corresponding to each part in \n",
      "\n",
      "THE DATABASE. IT SHOULD BE NOTED THAT THE SET OF \n",
      "\n",
      "domain-specific keywords and phrases was \n",
      "\n",
      "PROVIDED TO THE SPEECH RECOGNITION SYSTEM AS A \n",
      "\n",
      "text document. in other words, the training was \n",
      "\n",
      "NOT DONE BY A HUMAN SPEAKING THE KEYWORDS AND \n",
      "\n",
      "phrases into the speech recognition system. in \n",
      "\n",
      "ADDITION, THE SPEECH RECOGNITION SYSTEM IS FAR \n",
      "\n",
      "from perfect. the recognition rates hover \n",
      "\n",
      "AROUND 50%, AND THE SYSTEM HAS ADDITIONAL \n",
      "\n",
      "difficulty in identifying product names which \n",
      "\n",
      "ARE MOST OFTEN WORDS NOT FOUND IN A DICTIONARY \n",
      "\n",
      "(examples: 3mlasercam, 8000bucky, etc.). \n",
      "\n",
      "2.2.2 PARSER AND THE LEXICON \n",
      "\n",
      "the parser is domain-driven i the sense that it \n",
      "\n",
      "USES DOMAIN-DEPENDENT INFORMATION PRODUCED BY \n",
      "\n",
      "the lexicon to look for information, in a user \n",
      "\n",
      "UTTERANCE, THAT IS USEFUL IN THE CURRENT DOMAIN. \n",
      "\n",
      "however, it does not attempt to understand fully \n",
      "\n",
      "EACH USER UTTERANCE. IT IS ROBUST ENOUGH TO \n",
      "\n",
      "handle ungrammatical sentences, hort phrases, \n",
      "\n",
      "AND SENTENCES THAT CONTAIN MIS-RECOGNIZED TEXT. \n",
      "\n",
      "the lexicon, in addition to providing \n",
      "\n",
      "DOMAIN-DEPENDENT KEYWORDS AND PHRASES TO THE \n",
      "\n",
      "parser, also provides the semantic knowledge \n",
      "\n",
      "ASSOCIATED WITH EACH KEYWORD AND PHRASE. \n",
      "\n",
      "therefore, for each content word in the inverted \n",
      "\n",
      "HASH TABLES, THE LEXICON CONTAINS ENTRIES WHICH \n",
      "\n",
      "help the system determine whether the word was \n",
      "\n",
      "USED IN A PART DESCRIPTION, OR A PRODUCT NAME. IN \n",
      "\n",
      "addition, the lexicon also provides the semantic \n",
      "\n",
      "KNOWLEDGE ASSOCIATED WITH THE PRE-SPECIFIED \n",
      "\n",
      "actions which can be taken by the user like \n",
      "\n",
      "\"OPERATOR\" WHICH ALLOWS THE USER TO TRANSFER TO \n",
      "\n",
      "an operator, and \"stop,\" or \"quit\" which allow \n",
      "\n",
      "THE USER TO QUIT THE SYSTEM. SOME SAMPLE NTRIES \n",
      "\n",
      "are: \n",
      "\n",
      "COLLIMATOR => (DESCRIPTION_WORD, COLLIMATOR) \n",
      "\n",
      "camera => (product_word, camera) \n",
      "\n",
      "OPERATOR => (USER ACTION, OPERATOR) \n",
      "\n",
      "etc. \n",
      "\n",
      "THE PARSER SCANS A USER UTTERANCE AND \n",
      "\n",
      "returns, as output, a list of semantic tuples \n",
      "\n",
      "ASSOCIATED WITH EACH KEYWORD/PHRASE CONTAINED \n",
      "\n",
      "in the utterance. it is mainly interested in \"key \n",
      "\n",
      "WORDS\" (WORDS THAT ARE CONTAINED IN PRODUCT AND \n",
      "\n",
      "part descriptions, user action words, etc.) and it \n",
      "\n",
      "IGNORES ALL THE OTHER WORDS IN THE USER UTTERANCE. \n",
      "\n",
      "the parser also returns a special tuple containing \n",
      "\n",
      "THE ENTIRE INPUT STRING WHICH MAY BE USED LATER \n",
      "\n",
      "by the context-based parser for sub-string \n",
      "\n",
      "MATCHING SPECIALLY IN CASES WHEN THE DM HAS \n",
      "\n",
      "asked a specific question to the user and is \n",
      "\n",
      "EXPECTING A PARTICULAR KIND OF RESPONSE. \n",
      "\n",
      "2.2.3 the filler and template modules \n",
      "\n",
      "THE FILLER TAKES AS INPUT THE SET OF TUPLES \n",
      "\n",
      "generated by the parser and attempts to check \n",
      "\n",
      "OFF TEMPLATES CONTAINED IN THE TEMPLATES MODULE \n",
      "\n",
      "using these tuples, the set of templates in the \n",
      "\n",
      "TEMPLATES MODULE CONTAINS MOST OF REMAINING \n",
      "\n",
      "domain-specific knowledge required by the \n",
      "\n",
      "SYSTEM. EACH TEMPLATE IS AN INTERNAL \n",
      "\n",
      "representation of a part in the database. it \n",
      "\n",
      "CONTAINS FOR EACH PART, ITS ID, ITS DESCRIPTION, AND \n",
      "\n",
      "the product which contains it. in addition, there \n",
      "\n",
      "ARE SEVERAL ADDITIONAL TEMPLATES CORRESPONDING TO\n",
      "\n",
      "pre-specified user actions like \"operator,\" and \n",
      "\n",
      "\"QUIT.\" A SAMPLE TEMPLATE FOLLOWS: \n",
      "\n",
      "tl__i = ( \n",
      "\n",
      "'PRODUCT' = > 'SFD', \n",
      "\n",
      "'product__ids' = > 2229005\" \n",
      "\n",
      "'PRODUCT_DESCRIPTIONS' => 'IR RECEIVER PC \n",
      "\n",
      "board ci104 bistable memory') \n",
      "\n",
      "FOR EACH TUPLE INPUT FROM THE PARSER, THE \n",
      "\n",
      "filler checks off the fields which correspond to \n",
      "\n",
      "THE TUPLE. FOR EXAMPLE, IF THE FILLER GETS AS INPUT \n",
      "\n",
      "(description_word, collimator), it checks off the \n",
      "\n",
      "DESCRIPTION FIELDS OF THOSE TEMPLATES CONTAINING \n",
      "\n",
      "collimator as a word in the field. a template is \n",
      "\n",
      "CHECKED OFF IFF ONE OR MORE OF ITS FIELDS IS \n",
      "\n",
      "checked off. in addition, the filler also \n",
      "\n",
      "MAINTAINS A LIST OF ALL DESCRIPTION AND PRODUCT \n",
      "\n",
      "words passed through the tuples (i.e. these words \n",
      "\n",
      "32\n",
      "\n",
      "have been uttered by the user). these two lists \n",
      "\n",
      "ARE SUBSEQUENTLY PASSED TO THE DIALOGUE \n",
      "\n",
      "manager. \n",
      "\n",
      "ALTHOUGH THE FILLER DOES NOT APPEAR TO BE \n",
      "\n",
      "very helpful for the current application domain, \n",
      "\n",
      "IT IS AN IMPORTANT PART OF THE ARCHITECTURE FOR \n",
      "\n",
      "other application domains. for example, the \n",
      "\n",
      "CURRENT PARTSLD SYSTEM IS A DESCENDANT FROM AN \n",
      "\n",
      "earlier system which allowed users to process \n",
      "\n",
      "FINANCIAL TRANSACTIONS WHERE THE FILLER WAS \n",
      "\n",
      "instrumental in helping the dialogue manager \n",
      "\n",
      "DETERMINE THE TYPE OF TRANSACTION BEING CARRIED \n",
      "\n",
      "out by the user (bagga et al., 2000). \n",
      "\n",
      "2.2.4 THE DIALOGUE MANAGER (DM) \n",
      "\n",
      "the dm receives as input from the filler the set \n",
      "\n",
      "OF TEMPLATES WHICH ARE CHECKED OFF. IN ADDITION, \n",
      "\n",
      "it also receives two lists containing the list of \n",
      "\n",
      "DESCRIPTION WORDS, AND PRODUCT WORD UTTERED BY \n",
      "\n",
      "the user. the dm proceeds using the following \n",
      "\n",
      "ALGORITHM: \n",
      "\n",
      "1) it first checks the set of checked off \n",
      "\n",
      "TEMPLATES INPUT FROM THE FILLER. IF THERE IS \n",
      "\n",
      "exactly one template in this set, the dm asks \n",
      "\n",
      "THE USER TO CONFIRM THE PART THAT THE TEMPLATE \n",
      "\n",
      "corresponds to. upon receipt of the \n",
      "\n",
      "CONFIRMATION FROM THE USER, IT RETURNS THE \n",
      "\n",
      "identification number of the part to the user. \n",
      "\n",
      "2) OTHERWISE, FOR EACH DESCRIPTION WORD UTTERED \n",
      "\n",
      "by the user, the dm looks up the set of parts \n",
      "\n",
      "(OR TEMPLATES) CONTAINING THE WORD FROM THE \n",
      "\n",
      "descriptions inverted hash table. it then \n",
      "\n",
      "COMPUTES THE INTERSECTION OF THESE SETS. IF \n",
      "\n",
      "the intersection is empty, the dm computes \n",
      "\n",
      "THE UNION OF THESE SETS AND PROCEEDS TREATING \n",
      "\n",
      "the union as the intersection. \n",
      "\n",
      "3) IF THE INTERSECTION OBTAINED FROM (2) ABOVE \n",
      "\n",
      "contains exactly one template, the dm asks \n",
      "\n",
      "THE USER TO CONFIRM THE PART CORRESPONDING TO\n",
      "\n",
      "the template as in (1) above. \n",
      "\n",
      "4) OTHERWISE, THE DM LOOKS AT THE SET OF \n",
      "\n",
      "product words uttered by the user. if this set \n",
      "\n",
      "IS EMPTY, THE DM QUERIES THE USER FOR THE \n",
      "\n",
      "product name. since the dm is expecting a\n",
      "\n",
      "PRODUCT NAME HERE, THE INPUT PROVIDED BY THE \n",
      "\n",
      "user is handled by the context-based parser. \n",
      "\n",
      "SINCE MOST PRODUCT NAMES CONSIST OF NON- \n",
      "\n",
      "standard words consisting of alpha-numeric \n",
      "\n",
      "CHARACTERS (EXAMPLES: AMX3, \n",
      "\n",
      "8000bucky, etc.), the recognition quality \n",
      "\n",
      "IS QUITE POOR. THEREFORE, THE CONTEXT-BASED \n",
      "\n",
      "parser anks the input received from the user \n",
      "\n",
      "USING A SUB-STRING MATCHING ALGORITHM THAT \n",
      "\n",
      "uses character-based unigram and bigram \n",
      "\n",
      "COUNTS (DETAILS ARE PROVIDED IN THE NEXT \n",
      "\n",
      "section). the sub-string matching algorithm \n",
      "\n",
      "GREATLY ENHANCES THE PERFORMANCE OF THE \n",
      "\n",
      "system (as shown in the sample dialogue \n",
      "\n",
      "BELOW). \n",
      "\n",
      "5) if the set of product words is non-empty, or \n",
      "\n",
      "IF THE DM HAS SUCCESSFULLY QUERIED THE USER \n",
      "\n",
      "for a product name, it extracts the set of \n",
      "\n",
      "PARTS (TEMPLATES) CONTAINING EACH PRODUCT \n",
      "\n",
      "word from the product words inverted hash \n",
      "\n",
      "TABLE. IT THEN COMPUTES AN INTERSECTION OF \n",
      "\n",
      "these sets with the intersection set of \n",
      "\n",
      "DESCRIPTION WORDS OBTAINED FROM (2) ABOVE. \n",
      "\n",
      "the resulting intersection is the joint product \n",
      "\n",
      "AND DESCRIPTION I TERSECTION. \n",
      "\n",
      "6) if the joint intersection has exactly one \n",
      "\n",
      "TEMPLATE, THE DM PROCEEDS AS IN (1) ABOVE. \n",
      "\n",
      "alternatively, if the number of templates in \n",
      "\n",
      "THE JOINT INTERSECTION IS LESS THAN 4, THE DM \n",
      "\n",
      "lists the parts corresponding toeach of these \n",
      "\n",
      "AND ASKS THE USER TO CONFIRM THE CORRECT ONE. \n",
      "\n",
      "7) if there are more than 4 templates in the \n",
      "\n",
      "JOINT INTERSECTION, THE DM RANKS THE \n",
      "\n",
      "templates based upon word overlap with the \n",
      "\n",
      "DESCRIPTION WORDS UTTERED BY THE USER. IF THE \n",
      "\n",
      "number of resulting top-ranked templates i\n",
      "\n",
      "LESS THAN 4, THE DM PROCEEDS AS IN THE \n",
      "\n",
      "second half of (6) above. \n",
      "\n",
      "8) IF THE JOINT INTERSECTION IS EMPTY, OR IN THE \n",
      "\n",
      "highly unlikely case of there being more \n",
      "\n",
      "THAN 4 TOP-RANKED TEMPLATES IN (7), THE DM \n",
      "\n",
      "asks the user to enter additional \n",
      "\n",
      "DISAMBIGUATING INFORMATION. \n",
      "\n",
      "the goal of the dm is to hone in on the part \n",
      "\n",
      "(TEMPLATE) DESIRED BY THE USER, AND IT HAS TO \n",
      "\n",
      "determine this from the set of templates input to \n",
      "\n",
      "IT BY THE FILLER. IT HAS TO BE ROBUST ENOUGH TO DEAL \n",
      "\n",
      "with poor recognition quality, inadequate \n",
      "\n",
      "INFORMATION INPUT BY THE USER, AND AMBIGUOUS \n",
      "\n",
      "data. therefore, the dm is designed to handle \n",
      "\n",
      "THESE ISSUES. FOR EXAMPLE, DESCRIPTION WORDS \n",
      "\n",
      "that are mis-recognized as other description \n",
      "\n",
      "WORDS USUALLY CAUSE THE INTERSECTION OF THE SETS \n",
      "\n",
      "of parts corresponding to these words to be \n",
      "\n",
      "EMPTY. THE DM, IN THIS CASE, TAKES A UNION OF \n",
      "\n",
      "the sets of parts corresponding to the description \n",
      "\n",
      "333333\n",
      "\n",
      "words thereby ensuring that the template \n",
      "\n",
      "CORRESPONDING TOTHE DESIRED PART IS IN THE UNION. \n",
      "\n",
      "the dm navigates the space of possibilities \n",
      "\n",
      "BY FIRST ANALYZING THE INTERSECTION OF THE SETS OF \n",
      "\n",
      "parts corresponding to the description words \n",
      "\n",
      "UTTERED BY THE USER. IF NO UNIQUE PART EMERGES, \n",
      "\n",
      "the dm then checks to see if the user has \n",
      "\n",
      "PROVIDED ANY INFORMATION ABOUT THE PRODUCT HAT \n",
      "\n",
      "the part is going to be used in. if no product was \n",
      "\n",
      "MENTIONED BY THE USER, THE DM QUERIES THE USER \n",
      "\n",
      "for the product name. once this is obtained, the \n",
      "\n",
      "DM THEN CHECKS TO SEE IF A UNIQUE PART \n",
      "\n",
      "corresponds to the product name and the part \n",
      "\n",
      "DESCRIPTION PROVIDED BY THE USER. IF NO UNIQUE \n",
      "\n",
      "part emerges, then the dm backs off and asks \n",
      "\n",
      "THE USER TO RE-ENTER THE PART DESCRIPTION. \n",
      "\n",
      "alternatively, if more than one part corresponds \n",
      "\n",
      "TO THE SPECIFIED PRODUCT AND PART DESCRIPTION, \n",
      "\n",
      "then the dm ranks the parts based upon the \n",
      "\n",
      "NUMBER OF WORDS UTTERED BY THE USER. \n",
      "\n",
      "obviously, since the dm in this case uses a \n",
      "\n",
      "HEURISTIC, IT ASKS THE USER TO CONFIRM THE PART THAT \n",
      "\n",
      "ranks the highest. if more than one (although \n",
      "\n",
      "LESS THAN 4) PARTS HAVE THE SAME RANK, THEN THE \n",
      "\n",
      "dm explicitly lists these parts and asks the user \n",
      "\n",
      "TO SPECIFY THE DESIRED PART. IT SHOULD BE NOTED \n",
      "\n",
      "that the dm has to ensure that the information it\n",
      "\n",
      "RECEIVES IS ACTUALLY WHAT THE USER MEANT. THIS IS \n",
      "\n",
      "especially true when the dm uses heuristics, and \n",
      "\n",
      "SUB-STRING MATCHES (AS IN THE CASE OF PRODUCT \n",
      "\n",
      "names). therefore, the dm occasionally asks \n",
      "\n",
      "THE USER TO CONFIRM INPUT IT HAS RECEIVED. \n",
      "\n",
      "2.2.5 the sub-string matching algorithm \n",
      "\n",
      "WHEN THE DIALOGUE MANAGER IS EXPECTING A \n",
      "\n",
      "certain type of input (examples : product names, \n",
      "\n",
      "YES/NO RESPONSES) FROM THE USER, THE USER \n",
      "\n",
      "response is processed by the context-based \n",
      "\n",
      "PARSER. SINCE THE TYPE OF INPUT IS KNOWN, THE \n",
      "\n",
      "context-based parser uses a sub-string matching \n",
      "\n",
      "ALGORITHM THAT USES CHARACTER-BASED UNIGRAM AND \n",
      "\n",
      "bigram counts to match the user input with the \n",
      "\n",
      "EXPECTATION OF THE DIALOGUE MANAGER. THEREFORE, \n",
      "\n",
      "the sub-string matching module takes as input a \n",
      "\n",
      "USER UTTERANCE STRING ALONG WITH A LIST OF \n",
      "\n",
      "expected responses, and it ranks the list of \n",
      "\n",
      "EXPECTED RESPONSES BASED UPON THE USER \n",
      "\n",
      "response. listed below are the details of the \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALGORITHM : \n",
      "\n",
      "1) the algorithm first concatenates the words \n",
      "\n",
      "OF THE USER UTTERANCE INTO ONE LONG STRING. \n",
      "\n",
      "this is needed because the speech \n",
      "\n",
      "RECOGNITION SYSTEM OFTEN BREAKS UP THE \n",
      "\n",
      "utterance into words even though a single \n",
      "\n",
      "WORD IS BEING SAID. FOR EXAMPLE, THE \n",
      "\n",
      "product name amxl l0  is often broken up \n",
      "\n",
      "INTO THE STRING 'AMEX 110'. \n",
      "\n",
      "2) next, the algorithm goes through the string \n",
      "\n",
      "FORMED IN (1) AND COMPARES THIS CHARACTER BY \n",
      "\n",
      "character with the list of expected responses. \n",
      "\n",
      "IT ASSIGNS ONE POINT FOR EVERY COMMON \n",
      "\n",
      "character. therefore, the expected response \n",
      "\n",
      "'AMX3' GETS THREE POINTS FOR THE UTTERANCE \n",
      "\n",
      "'amex110'. \n",
      "\n",
      "3) THE ALGORITHM THEN COMPARES THE USER \n",
      "\n",
      "utterance with the list of expected responses \n",
      "\n",
      "USING 2 CHARACTERS (BIGRAMS) AT A TIME. IT \n",
      "\n",
      "assigns 2 points for each bigram match. for \n",
      "\n",
      "THE EXAMPLE SHOWN IN (2), THERE ARE TWO \n",
      "\n",
      "bigram matches: the first is that the \n",
      "\n",
      "UTTERANCE STARTS WITH AN 'A' (THE PREVIOUS \n",
      "\n",
      "character is this case is the null character), \n",
      "\n",
      "AND THE SECOND IS THE BIGRAM 'AM'. \n",
      "\n",
      "4) the algorithm now compares the length of \n",
      "\n",
      "THE USER UTTERANCE STRING AND THE EXPECTED \n",
      "\n",
      "response. if the length of the two strings is \n",
      "\n",
      "THE SAME, THEN IT ASSIGNS 2 POINTS TO THE \n",
      "\n",
      "expected response. \n",
      "\n",
      "5) FINALLY, THE ALGORITHM CALCULATES THE NUMBER \n",
      "\n",
      "of unique characters in the expected \n",
      "\n",
      "RESPONSE, AND THE USER UTTERANCE STRING. IF \n",
      "\n",
      "these characters are the same, then it assigns \n",
      "\n",
      "4 POINTS TO THE EXPECTED RESPONSE. \n",
      "\n",
      "the expected response which has the highest \n",
      "\n",
      "NUMBER OF POINTS IS THE MOST LIKELY ONE. IF TWO \n",
      "\n",
      "or more expected responses have the same \n",
      "\n",
      "NUMBER OF POINTS, THEN THE SYSTEM ASKS THE USER \n",
      "\n",
      "to confh'm the correct one. \n",
      "\n",
      "WHILE WE HAVE NOT EVALUATED THIS SUB- \n",
      "\n",
      "string matching algorithm independently, a brief \n",
      "\n",
      "EVALUATION IN THE CONTEXT OF THE SYSTEM RESULTED \n",
      "\n",
      "in about 90% accuracy. \n",
      "\n",
      "2.2.6 THE PRESENTATION MODULE \n",
      "\n",
      "the presentation module works in one of two \n",
      "\n",
      "POSSIBLE MODES: OVER THE PHONE, AND OVER THE \n",
      "\n",
      "web. this module takes as input a string \n",
      "\n",
      "GENERATED BY THE QUESTION-GENERATION MODULE \n",
      "\n",
      "and presents this string to the user in the \n",
      "\n",
      "APPROPRIATE MODE OF COMMUNICATION. IF THE \n",
      "\n",
      "speech option for the system is turned on, the \n",
      "\n",
      "SPEECH-BASED OUTPUT IS GENERATED USING LERNOUT \n",
      "\n",
      "\"~ld. 34\n",
      "\n",
      "AND HAUSPIE'S REALSPEAK TEXT-TO-SPEECH SYSTEM. \n",
      "\n",
      "although the system currently cannot use both \n",
      "\n",
      "MODES OF COMMUNICATION SIMULTANEOUSLY, WE \n",
      "\n",
      "plan to incorporate this feature sometime in the \n",
      "\n",
      "FUTURE. \n",
      "\n",
      "2.2. 7 robustness of  the system \n",
      "\n",
      "AS WITH ANY DIALOGUE SYSTEM, IT IS EXTREMELY \n",
      "\n",
      "important for the system to be robust. our \n",
      "\n",
      "SYSTEM HAS THE FOLLOWING TWO FEATURES WHICH \n",
      "\n",
      "make it extremely robust: \n",
      "\n",
      "1) THE USER CAN, AT ANY GIVEN MOMENT, \n",
      "\n",
      "say operator to transfer to an \n",
      "\n",
      "OPERATOR, QUIT~STOP TO EXIT, AND \n",
      "\n",
      "back~restart to start afresh. \n",
      "\n",
      "2) WHEN EXPECTING A RESPONSE FROM THE \n",
      "\n",
      "user, if the system does not receive an \n",
      "\n",
      "EXPECTED INPUT, IT REPEATS THE QUESTION \n",
      "\n",
      "at most twice before transferring \n",
      "\n",
      "CONTROL TO AN OPERATOR. \n",
      "\n",
      "3. sample dialogues \n",
      "\n",
      "THIS SECTION GIVES EXAMPLES OF TWO SAMPLE \n",
      "\n",
      "dialogues that occur during the testing of the \n",
      "\n",
      "SYSTEM. THE SYSTEM'S RESPONSE IS INDICATED BY \n",
      "\n",
      "\"s>\", the user's response by \"u>\", and the \n",
      "\n",
      "RECOGNITION OF THE USER'S RESPONSE BY \"V>\". \n",
      "\n",
      "s> welcome to the partsld center. please tell \n",
      "\n",
      "ME THE PART THAT YOU WANT THE ID FOR. \n",
      "\n",
      "u> i need the id for  pcb control. \n",
      "\n",
      "V> I NEED THE I THE FOR PCB HOME THROWN. \n",
      "\n",
      "s> what product do you need this for? \n",
      "\n",
      "U> COMPAX 40E \n",
      "\n",
      "v> home fax for a o0 e \n",
      "\n",
      "S> IS COMPAX 40E THE PRODUCT NAME THAT YOU \n",
      "\n",
      "said? \n",
      "\n",
      "U> YES \n",
      "\n",
      "v> gas \n",
      "\n",
      "S> DO YOU WANT THE ID FOR PCB DISPLAY SID OR \n",
      "\n",
      "the pcb control? \n",
      "\n",
      "U> THE SECOND ONE. \n",
      "\n",
      "v> the second home. \n",
      "\n",
      "S> DO YOU NEED THE ID FOR PCB CONTROL USED IN \n",
      "\n",
      "product compax 40e? \n",
      "\n",
      "U> YES \n",
      "\n",
      "v> yes \n",
      "\n",
      "S> THE ID FOR PCB CONTROL USED IN PRODUCT \n",
      "\n",
      "compax 40e is 2168983. do you wan to exit \n",
      "\n",
      "OR F IND THE ID FOR ANOTHER PART ? \n",
      "\n",
      "u> look up another part. \n",
      "\n",
      "S> WELCOME TO THE PARTSLD CENTER. PLEASE TELL \n",
      "\n",
      "me the part that you want the id for. \n",
      "\n",
      "U> I NEED CABLE DATA FOR CRADLE 2M LONG. \n",
      "\n",
      "v> i needed cable date them for cradle to be \n",
      "\n",
      "LOAN. \n",
      "\n",
      "s> do you need this part for a angixm2004, \n",
      "\n",
      "OR A AFM ? \n",
      "\n",
      "u> afm \n",
      "\n",
      "V> A FAN \n",
      "\n",
      "s> is afm the product name that you said? \n",
      "\n",
      "U> YES \n",
      "\n",
      "v> yes \n",
      "\n",
      "S> DO YOU WANT THE ID FOR CABLE DATA FOR \n",
      "\n",
      "cradle 2m long ? \n",
      "\n",
      "U> YES \n",
      "\n",
      "v> yes \n",
      "\n",
      "S> THE ID FOR  CABLE DATA FOR CRADLE 2M LONG \n",
      "\n",
      "used in product afm is 45438628. do you wan \n",
      "\n",
      "TO EXIT OR F IND THE ID FOR ANOTHER PART? \n",
      "\n",
      "u> look up another part. \n",
      "\n",
      "4. EVALUATION AND RESULTS \n",
      "\n",
      "the goal of our evaluation was to ensure that the \n",
      "\n",
      "SYSTEM HELPED A USER SUCCESSFULLY IDENTIFY PARTS \n",
      "\n",
      "irrespective of the performance of the speech \n",
      "\n",
      "RECOGNITION ENGINE FOR THE USER. IN OTHER WORDS, \n",
      "\n",
      "we wanted to see if the system was robust \n",
      "\n",
      "ENOUGH TO CONDUCT TRANSACTIONS WITH A DIVERSE \n",
      "\n",
      "mix of users. we tested the system with 4 \n",
      "\n",
      "DIFFERENT USERS TWO OF WHOM HAD FOREIGN ACCENTS. \n",
      "\n",
      "for each user, we randomly selected 20 parts \n",
      "\n",
      "FROM THE DATABASE. THE RESULTS ARE SUMMARIZED \n",
      "\n",
      "in table 1. \n",
      "\n",
      "THESE RESULTS SHOW THAT THE SYSTEM WAS \n",
      "\n",
      "quite successful in handling requests from users \n",
      "\n",
      "WITH A VARIETY OF ACCENTS ACHIEVING VARYING \n",
      "\n",
      "recognition rates. out of the 80 parts tested, \n",
      "\n",
      "ONLY TWICE DID THE USER FEEL THAT HE/SHE HAD TO \n",
      "\n",
      "transfer to an operator. the system successfully \n",
      "\n",
      "RETRIEVED THE IDENTIFICATION UMBERS OF 79% OF \n",
      "\n",
      "the parts while transferring 19% of the cases to a \n",
      "\n",
      "HUMAN OPERATOR BECAUSE OF EXTREMELY BAD \n",
      "\n",
      ":$5 \n",
      "\n",
      "USER PARTS \n",
      "\n",
      "successfully \n",
      "\n",
      "IDENTIFIED \n",
      "\n",
      "15 \n",
      "\n",
      "CALLS SYSTEM \n",
      "\n",
      "transfers to \n",
      "\n",
      "OPERATOR \n",
      "\n",
      "3 \n",
      "\n",
      "CALLS USER \n",
      "\n",
      "transfers to \n",
      "\n",
      "OPERATOR \n",
      "\n",
      "2 \n",
      "\n",
      "SYSTEM \n",
      "\n",
      "prompts per \n",
      "\n",
      "CALL \n",
      "\n",
      "3.7 \n",
      "\n",
      "RELEVANT WORDS \n",
      "\n",
      "recognized per \n",
      "\n",
      "PART \n",
      "\n",
      "2.5 \n",
      "\n",
      "18 2 0 3 2.35 \n",
      "\n",
      "13 7 0 2.5 1.65 \n",
      "\n",
      "17 3 0 2.9 2.7 \n",
      "\n",
      "table 1: summary of results \n",
      "\n",
      "RECOGNITION. WE ARE PLANNING ON CONDUCTING A\n",
      "\n",
      "more elaborate test which a larger set of users. \n",
      "\n",
      "CONCLUSIONS \n",
      "\n",
      "in this paper we have described a robust system \n",
      "\n",
      "THAT PROVIDES CUSTOMER SERVICE FOR A MEDICAL \n",
      "\n",
      "parts application. the preliminary results are \n",
      "\n",
      "EXTREMELY ENCOURAGING WITH THE SYSTEM BEING \n",
      "\n",
      "able to successfully process approximately 80% \n",
      "\n",
      "OF THE REQUESTS FROM USERS WITH DIVERSE ACCENTS. \n",
      "\n",
      "acknowledgements \n",
      "\n",
      "WE WISH TO THANK THE GE MEDICAL SYSTEMS TEAM \n",
      "\n",
      "of todd reinke, jim tierney, and lisa \n",
      "\n",
      "NAUGHTON FOR PROVIDING SUPPORT AND FUNDING FOR \n",
      "\n",
      "this project. in addition, we also wish to thank \n",
      "\n",
      "DONG HSU OF LERNOUT AND HAUSPIE FOR HIS HELP \n",
      "\n",
      "on the asr and the text-to-speech systems. \n",
      "\n",
      "FINALLY, WE WISH TO THANK THE INFORMATION \n",
      "\n",
      "technology laboratory of ge crd for \n",
      "\n",
      "PROVIDING ADDITIONAL FUNDING FOR THIS PROJECT. \n",
      "\n",
      "references \n",
      "\n",
      "ALLEN, J. F. ET AL. (1995) THE TRAINS PROJECT: A \n",
      "\n",
      "case study in building a conversational p anning \n",
      "\n",
      "AGENT. JOURNAL OF EXPERIMENTAL ND THEORETICAL AI, \n",
      "\n",
      "(7) 7-48. \n",
      "\n",
      "ALLEN, J. F., MILLER, B. W.; RINGER, E. K.; AND \n",
      "\n",
      "sikorski, t. (1996) a robust system for natural \n",
      "\n",
      "SPOKEN DIALOGUE. 34TH ANNUAL MEETING OF THE \n",
      "\n",
      "acl, santa cruz, 62-70. \n",
      "\n",
      "BAGGA, A., STEIN G. C., AND STRZALKOWSKI, T. (2000) \n",
      "\n",
      "fidelityxpress: a multi-modal system for \n",
      "\n",
      "FINANCIAL TRANSACTIONS. PROCEEDINGS OF THE 6 A~ \n",
      "\n",
      "conference on content-based multimedia \n",
      "\n",
      "INFORMATION ACCESS (RIAO'00). \n",
      "\n",
      "biermann, a.w.; rodman, r.; rubin, d.; and \n",
      "\n",
      "HEIDLAGE, J.R. (1985) NATURAL LANGUAGE WITH \n",
      "\n",
      "discrete speech as a mode for human to machine \n",
      "\n",
      "COMMUNICATION. COMMUNICATION OF THE ACM \n",
      "\n",
      "18(6): 628-636. \n",
      "\n",
      "BIERMANN, ALAN W.; GUINN, CURRY I.; FULKERSON, M.: \n",
      "\n",
      "keim, g.a.; liang, z.; melamed, d.m.; and \n",
      "\n",
      "RAJAGOPALAN, K. (1997) GOAL-ORIENTEDMULTIMEDIA \n",
      "\n",
      "dialogue with variable initiative. lecture notes in \n",
      "\n",
      "ARTIFICIAL INTELLIGENCE 1325; SPRINGER-VERLAG, NEW \n",
      "\n",
      "york; pp. 1-16. \n",
      "\n",
      "CARBERRY, S. (1990) PLAN RECOGNITION IN NATURAL \n",
      "\n",
      "language dialogue. cambridge, mass.: the mit \n",
      "\n",
      "PRESS. \n",
      "\n",
      "chu-carroll, j, and r. carpenter. (1999) vector- \n",
      "\n",
      "BASED NATURAL LANGUAGE CALL ROUTING. JOURNAL OF \n",
      "\n",
      "computational linguistics, 25(30), pp. 361-388. \n",
      "\n",
      "GEORGILA, K., A.TSOPANOGLOU, N.FAKOTAKIS AND \n",
      "\n",
      "g.kokkinakis. (1998) an integrated dialogue \n",
      "\n",
      "SYSTEM FOR THE AUTOMATION OF CALL CENTRE SERVICES. \n",
      "\n",
      "iclsp'98, 5th international conference on spoken \n",
      "\n",
      "LANGUAGE PROCESSING, SYDNEY, AUSTRALIA. \n",
      "\n",
      "grosz, b.j. and sidner, c.l. (1986) attentions, \n",
      "\n",
      "INTENTIONS, AND THE STRUCTURE OF DISCOURSE. \n",
      "\n",
      "computational linguistics 12(3): 175-204. \n",
      "\n",
      "GREENEMEIER, L. (1999) VOICE-RECOGNITION \n",
      "\n",
      "technology builds a following. information \n",
      "\n",
      "WEEK, DECEMBER 13. \n",
      "\n",
      "meisel, w. (1999) can speech recognition give \n",
      "\n",
      "TELEPHONES A NEW FACE? BUSINESS \n",
      "\n",
      "communications review, november 1. \n",
      "\n",
      "REICHMAN, R.. (1981) PLAIN-SPEAKING: A THEORY AND \n",
      "\n",
      "grammar of spontaneous discourse. phd thesis, \n",
      "\n",
      "DEPARTMENT OF COMPUTER SCIENCE, HARVARD \n",
      "\n",
      "university, cambridge, massachusetts. \n",
      "\n",
      "ROSEN, C. (1999) SPEECH HAS INDUSTRY TALKING. \n",
      "\n",
      "business travel news, november. \n",
      "\n",
      "ROSSHEIM, J. (1999) GIVING VOICE TO CUSTOMER \n",
      "\n",
      "service. datamation, november 1. \n",
      "\n",
      "36 \n",
      "\n",
      "translation using information on dialogue participants \n",
      "\n",
      "SETSUO YAMADA, E I I CH I RO  SUMI TA  AND  H IDEK I  KASHIOKA \n",
      "\n",
      "atr interpreting telecommunications research laboratories* \n",
      "\n",
      "2-2, HIKARIDAI, SEIKA-CHO, SORAKU-GUN, \n",
      "\n",
      "kyoto, 619-0288, japan \n",
      "\n",
      "{ SYAMADA, SUMITA, KASHIOKA} @ITL.ATR.CO.JP T \n",
      "\n",
      "abstract \n",
      "\n",
      "THIS PAPER PROPOSES A WAY TO IMPROVE THE TRANS- \n",
      "\n",
      "lation quality by using information on dialogue \n",
      "\n",
      "PARTICIPANTS THAT IS EASILY OBTAINED FROM OUT- \n",
      "\n",
      "side the translation component. we incorpo- \n",
      "\n",
      "RATED INFORMATION ON PARTICIPANTS' OCIAL ROLES \n",
      "\n",
      "and genders into transfer ules and dictionary \n",
      "\n",
      "ENTRIES. AN EXPERIMENT WITH 23 UNSEEN DIA- \n",
      "\n",
      "logues demonstrated a recall of 65% and a preci- \n",
      "\n",
      "SION OF 86%. THESE RESULTS HOWED THAT OUR SIM- \n",
      "\n",
      "ple and easy-to-implement method is effective, \n",
      "\n",
      "AND IS A KEY TECHNOLOGY ENABLING SMOOTH CON- \n",
      "\n",
      "versation with a dialogue translation system. \n",
      "\n",
      "1 I N T RODUCT ION  \n",
      "\n",
      "recently, various dialogue translation systems \n",
      "\n",
      "HAVE BEEN PROPOSED (BUB AND OTHERS, 1997; \n",
      "\n",
      "kurematsu and morimoto, 1996; rayner and \n",
      "\n",
      "CARTER, 1997; ROS~ AND LEVIN, 1998; SUMITA \n",
      "\n",
      "and others, 1999; yang and park, 1997; vi- \n",
      "\n",
      "DAL, 1997). IF WE WANT TO MAKE A CONVERSATION \n",
      "\n",
      "proceed smoothly using these translation sys- \n",
      "\n",
      "TEMS, IT IS IMPORTANT O USE NOT ONLY LINGUIS- \n",
      "\n",
      "tic information, which comes from the source \n",
      "\n",
      "LANGUAGE, BUT ALSO EXTRA-LINGUISTIC NFORMATION, \n",
      "\n",
      "which does not come from the source language, \n",
      "\n",
      "BUT, IS SHARED BETWEEN THE PARTICIPANTS OF THE \n",
      "\n",
      "conversation. \n",
      "\n",
      "SEVERAL DIALOGUE TRANSLATION METHODS THAT \n",
      "\n",
      "use extra-linguistic information have been pro- \n",
      "\n",
      "POSED. HORIGUCHI OUTLINED HOW \"SPOKEN LAN- \n",
      "\n",
      "guage pragmatic information\" can be trans- \n",
      "\n",
      "LATED (HORIGUCHI, 1997). HOWEVER, SHE DID NOT \n",
      "\n",
      "apply this idea to a dialogue translation system. \n",
      "\n",
      "LUPERFOY ET AL. PROPOSED A SOFTWARE ARCHITEC- \n",
      "\n",
      "*current affiliation is atr spoken language trans- \n",
      "\n",
      "LATION RESEARCH LABORATORIES \n",
      "\n",
      "current mail addresses are \n",
      "\n",
      "{ SETSUO.YARNADA, EIICHIRO.SUMITA, HIDEKI.KASHIOKA} \n",
      "\n",
      "@slt. atr. co.jp \n",
      "\n",
      "TURE THAT USES '% PRAGMATIC ADAPTATION\" (LU- \n",
      "\n",
      "perfoy and others, 1998), and mima et al. pro- \n",
      "\n",
      "POSED A METHOD THAT USES \"SITUATIONAL INFORMA- \n",
      "\n",
      "tion\" (mima and others, 1997). luperfoy et al. \n",
      "\n",
      "SIMULATED THEIR METHOD ON MAN-MACHINE INTER- \n",
      "\n",
      "faces and mima et al. preliminarily evaluated \n",
      "\n",
      "THEIR METHOD. NEITHER STUDY, HOWEVER, APPLIED \n",
      "\n",
      "its proposals to an actual dialogue translation \n",
      "\n",
      "SYSTEM. \n",
      "\n",
      "the above mentioned methods will need time \n",
      "\n",
      "TO WORK IN PRACTICE, SINCE IT IS HARD TO OBTAIN \n",
      "\n",
      "the extra-linguistic nformation on which they \n",
      "\n",
      "DEPEND. \n",
      "\n",
      "we have been paying special attention to \"po- \n",
      "\n",
      "LITENESS,\" BECAUSE A LACK OF POLITENESS CAN INTER- \n",
      "\n",
      "fere with a smooth conversation between two \n",
      "\n",
      "PARTICIPANTS, UCH AS A CLERK AND A CUSTOMER. IT \n",
      "\n",
      "is easy for a dialogue translation system to know \n",
      "\n",
      "WHICH PARTICIPANT IS THE CLERK AND WHICH IS THE \n",
      "\n",
      "customer from the interface (such as the wires \n",
      "\n",
      "TO THE MICROPHONES). \n",
      "\n",
      "this paper describes a method of \"polite- \n",
      "\n",
      "NESS\" SELECTION ACCORDING TO A PARTICIPANT'S SO- \n",
      "\n",
      "cial role (a clerk or a customer), which is eas- \n",
      "\n",
      "ILY OBTAINED FROM THE EXTRA-LINGUISTIC ENVIRON- \n",
      "\n",
      "ment. we incorporated each participant's so- \n",
      "\n",
      "CIAL ROLE INTO TRANSFER ULES AND TRANSFER DICTIO- \n",
      "\n",
      "nary entries. we then conducted an experiment \n",
      "\n",
      "WITH 23 UNSEEN DIALOGUES (344 UTTERANCES). OUR \n",
      "\n",
      "method achieved a recall of 65% and a preci- \n",
      "\n",
      "SION OF 86%. THESE RATES COULD BE IMPROVED TO \n",
      "\n",
      "86% and 96%, respectively (see section 4). it \n",
      "\n",
      "IS THEREFORE POSSIBLE TO USE A \"PARTICIPANT'S SO- \n",
      "\n",
      "cial role\" (a clerk or a customer in this case) \n",
      "\n",
      "TO APPROPRIATELY MAKE THE TRANSLATION RESULTS \n",
      "\n",
      "\"polite,\" and to make the conversation proceed \n",
      "\n",
      "SMOOTHLY WITH A DIALOGUE TRANSLATION SYSTEM. \n",
      "\n",
      "section 2 analyzes the relationship between a\n",
      "\n",
      "PARTICULAR PARTICIPANT'S SOCIAL ROLE (A CLERK) AND \n",
      "\n",
      "politeness in japanese. section 3 describes our \n",
      "\n",
      "PROPOSAL IN DETAIL USING AN ENGLISH-TO-JAPANESE \n",
      "\n",
      "37 \n",
      "\n",
      "TRANSLATION SYSTEM. SECTION 4 SHOWS AN EXPER- \n",
      "\n",
      "iment and results, followed by a discussion in \n",
      "\n",
      "SECTION 5. FINALLY, SECTION 6 CONCLUDES THIS PA- \n",
      "\n",
      "per. \n",
      "\n",
      "2 A PAR T I C IPANT ' S  SOC IA L  RO LE  AND  \n",
      "\n",
      "po l i teness  \n",
      "\n",
      "THIS SECTION FOCUSES ON ONE PARTICIPANT'S SOCIAL \n",
      "\n",
      "role. we investigated japanese outputs of a di- \n",
      "\n",
      "ALOGUE TRANSLATION SYSTEM TO SEE HOW MANY UT- \n",
      "\n",
      "terances hould be polite expressions in a cur- \n",
      "\n",
      "RENT TRANSLATION SYSTEM FOR TRAVEL ARRANGEMENT. \n",
      "\n",
      "we input 1,409 clerk utterances into a transfer \n",
      "\n",
      "DRIVEN MACHINE TRANSLATION SYSTEM (SUMITA \n",
      "\n",
      "and others, 1999) (tdmt for short). the in- \n",
      "\n",
      "PUTS WERE CLOSED UTTERANCES, MEANING THE SYS- \n",
      "\n",
      "tem already knew the utterances, enabling the \n",
      "\n",
      "UTTERANCES TO BE TRANSFERRED AT A GOOD QUALITY. \n",
      "\n",
      "therefore, we used closed utterances as the in- \n",
      "\n",
      "PUTS TO AVOID TRANSLATION ERRORS. \n",
      "\n",
      "as a result, it was shown that about 70% \n",
      "\n",
      "(952) OF ALL UTTERANCES SHOULD BE IMPROVED TO USE \n",
      "\n",
      "polite expressions. this result shows that a cur- \n",
      "\n",
      "RENT TRANSLATION SYSTEM IS NOT ENOUGH TO MAKE \n",
      "\n",
      "a conversation smoothly. not surprisingly, if all \n",
      "\n",
      "EXPRESSIONS WERE POLITE, SOME JAPANESE SPEAKERS \n",
      "\n",
      "would feel insulted. therefore, japanese speak- \n",
      "\n",
      "ERS DO NOT HAVE TO USE POLITE EXPRESSION IN ALL \n",
      "\n",
      "utterances. \n",
      "\n",
      "WE CLASSIFIED THE INVESTIGATED ATA INTO DIF- \n",
      "\n",
      "ferent ypes of english expressions for japanese \n",
      "\n",
      "POLITENESS, I.E., INTO HONORIFIC TITLES, PARTS OF \n",
      "\n",
      "speech such as verbs, and canned phrases, \n",
      "\n",
      "AS SHOWN IN TABLE 1; HOWEVER, NOT ALL TYPES \n",
      "\n",
      "appeared in the data. for example, when \n",
      "\n",
      "THE CLERK SAID \"HOW WILL YOU BE PAYING, MR. \n",
      "\n",
      "suzuki,\" the japanese translation was made \n",
      "\n",
      "POLITE AS \"DONOYOUNI OSHIHARAININARIMASU-KA \n",
      "\n",
      "suzuki-sama\" in place of the standard expres- \n",
      "\n",
      "SION \"DONOYOUNI SHIHARAIMASU-KA SUZUKI-SAN.\" \n",
      "\n",
      "table 1 shows that there is a difference in \n",
      "\n",
      "HOW EXPRESSIONS SHOULD BE MADE MORE POLITE AC- \n",
      "\n",
      "cording to the type, and that many polite ex- \n",
      "\n",
      "PRESSIONS CAN BE TRANSLATED BY USING ONLY LOCAL \n",
      "\n",
      "information, i.e., transfer rules and dictionary \n",
      "\n",
      "ENTRIES. IN THE NEXT SECTION, WE DESCRIBE HOW TO \n",
      "\n",
      "incorporate the information on dialogue partic- \n",
      "\n",
      "IPANTS, SUCH AS ROLES AND GENDERS, INTO TRANSFER \n",
      "\n",
      "rules and dictionary entries in a dialogue trans- \n",
      "\n",
      "LATION SYSTEM. \n",
      "\n",
      "3 a method  of  us ing  in fo rmat ion  \n",
      "\n",
      "ON  D IA LOGUE  PAR T I C IPANTS  \n",
      "\n",
      "this section describes how to use information \n",
      "\n",
      "ON DIALOGUE PARTICIPANTS, SUCH AS PARTICIPANTS' \n",
      "\n",
      "social roles and genders. first, we describe \n",
      "\n",
      "TDMT, WHICH WE ALSO USED IN OUR EXPERIMENT. \n",
      "\n",
      "second, we mention how to modify transfer \n",
      "\n",
      "RULES AND TRANSFER DICTIONARY ENTRIES ACCORDING \n",
      "\n",
      "to information on dialogue participants. \n",
      "\n",
      "3.1 TRANSFER  DR IVEN  MACH INE  \n",
      "\n",
      "trans la t ion  \n",
      "\n",
      "TDMT USES BOTTOM-UP LEFT-TO-RIGHT CHART PARS- \n",
      "\n",
      "ing with transfer rules as shown in figure 1. \n",
      "\n",
      "THE PARSING DETERMINES THE BEST STRUCTURE AND \n",
      "\n",
      "best transferred result locally by performing \n",
      "\n",
      "STRUCTURAL DISAMBIGUATION USING SEMANTIC DIS- \n",
      "\n",
      "tance calculations, in parallel with the deriva- \n",
      "\n",
      "TION OF POSSIBLE STRUCTURES. THE SEMANTIC DIS- \n",
      "\n",
      "tance is defined by a thesaurus. \n",
      "\n",
      "(SOURCE PATTERN) \n",
      "\n",
      "==~ \n",
      "\n",
      "J ((TARGET PATTERN 1) \n",
      "\n",
      "((source xample 1) \n",
      "\n",
      "(SOURCE XAMPLE 2) \n",
      "\n",
      "Ã¢â‚¬Â¢ \"- ) \n",
      "\n",
      "(TARGET PATTERN 2) \n",
      "\n",
      "Ã¢Â°o* ) \n",
      "\n",
      "FIGURE 1: TRANSFER ULE FORMAT \n",
      "\n",
      "a transfer ule consists of a source pattern, \n",
      "\n",
      "A TARGET PATTERN, AND A SOURCE EXAMPLE. THE \n",
      "\n",
      "source pattern consists of variables and con- \n",
      "\n",
      "STITUENT BOUNDARIES (FURUSE AND IIDA, 1996). \n",
      "\n",
      "a constituent boundary is either a functional \n",
      "\n",
      "WORD OR THE PART-OF-SPEECH OF A LEFT CONSTITUENT'S \n",
      "\n",
      "last word and the part-of-speech of a right con- \n",
      "\n",
      "STITUENT'S FIRST WORD. IN EXAMPLE (1), THE CON- \n",
      "\n",
      "stituent boundary iv-cn) is inserted between \n",
      "\n",
      "\"ACCEPT\" AND \"PAYMENT,\" BECAUSE \"ACCEPT\" IS \n",
      "\n",
      "a verb and \"payment\" is a common noun. \n",
      "\n",
      "THE TARGET PATTERN CONSISTS OF VARIABLES THAT COR- \n",
      "\n",
      "respond to variables in the source pattern and \n",
      "\n",
      "WORDS OF THE TARGET LANGUAGE. THE SOURCE EXAM- \n",
      "\n",
      "ple consists of words that come from utterances \n",
      "\n",
      "REFERRED TO WHEN A PERSON CREATES TRANSFER ULES \n",
      "\n",
      "(we call such utterances closed utterances). \n",
      "\n",
      "FIGURE 2 SHOWS A TRANSFER ULE WHOSE SOURCE \n",
      "\n",
      "pattern is (x (v-cn) y). variable x corre- \n",
      "\n",
      "SPONDS TO X, WHICH IS USED IN THE TARGET PAT- \n",
      "\n",
      "tern, and y corresponds to y, which is also \n",
      "\n",
      "38 \n",
      "\n",
      "table 1: examples of polite expressions \n",
      "\n",
      "TYPE: VERB, TITLE \n",
      "\n",
      "eng: how will you be paying, mr. suzuki \n",
      "\n",
      "STANDARD: DONOYOUNI SHIHARAIMASU-KA SUZUKI-SAN \n",
      "\n",
      "polite: donoyouni o_shiharaininarimasu-ka suzuki-sama \n",
      "\n",
      "GLOSS: HOW PAY-QUESTION SUZUKI-MR. \n",
      "\n",
      "type: verb, common noun \n",
      "\n",
      "ENG: WE HAVE TWO TYPES OF ROOMS AVAILABLE \n",
      "\n",
      "standard: aiteiru ni-shurui-no heya-ga ariraasu \n",
      "\n",
      "POLITE: AITEIRU NI-SHURUI-NO OHEYA-GA GOZAIMASU \n",
      "\n",
      "gloss: available two-types-of room-top have \n",
      "\n",
      "TYPE: AUXILIARY VERB \n",
      "\n",
      "eng: you can shop for hours \n",
      "\n",
      "STANDARD: SUUJIKAN KAIMONO-WO SURUKOTOGADEKIMASU \n",
      "\n",
      "polite: suujikan kaimono-wo shiteitadakemasu \n",
      "\n",
      "GLOSS: FOR HOURS MAKE-OBJ CAN \n",
      "\n",
      "type: pronoun \n",
      "\n",
      "ENG: YOUR ROOM NUMBER, PLEASE \n",
      "\n",
      "standard: anatano heya bangou-wo \n",
      "\n",
      "POLITE: OKYAKUSAMANO HEYA BANGOU-WO \n",
      "\n",
      "gloss: your room number-so obj \n",
      "\n",
      "ONEGAISHIRNASU \n",
      "\n",
      "onegaishimasu \n",
      "\n",
      "PLEASE \n",
      "\n",
      "type: canned phrase \n",
      "\n",
      "ENG: HOW CAN I HELP YOU \n",
      "\n",
      "standard: dou shimashitaka \n",
      "\n",
      "POLITE: DOUITTA GOYOUKENDESHOUKA \n",
      "\n",
      "gloss: how can i help you \n",
      "\n",
      "EXAMPLE (1) \n",
      "\n",
      "eng: we accept payment by credit card \n",
      "\n",
      "STANDARD: WATASHITACHI-WA KUREJITLO-KAADO-DENO SHIHARAI-WO UKELSUKEMASU \n",
      "\n",
      "polite: watashidomo-wa kurejitto-kaado-deno o_shiharai-wo ukeshimasu \n",
      "\n",
      "GLOSS: WE-TOP CREDIT-CARD-BY PAYMENT-OBJ ACCEPT \n",
      "\n",
      "used in the target pattern. the source exam- \n",
      "\n",
      "PLE ((\"ACCEPT\") (\"PAYMENT\")) COMES FROM EX- \n",
      "\n",
      "ample (1), and the other source examples come \n",
      "\n",
      "FROM THE OTHER CLOSED UTTERANCES. THIS TRANSFER \n",
      "\n",
      "rule means that if the source pattern is (x (v- \n",
      "\n",
      "CN) Y) THEN (Y \"WO\" X) OR (Y \"NI\" X) IS SELECTED \n",
      "\n",
      "as the target pattern, where an input word pair \n",
      "\n",
      "CORRESPONDING TO X AND Y IS SEMANTICALLY THE \n",
      "\n",
      "most similar in a thesaurus to, or exactly the \n",
      "\n",
      "SAME AS, THE SOURCE EXAMPLE. FOR EXAMPLE, IF \n",
      "\n",
      "an input word pair corresponding to x and y \n",
      "\n",
      "IS SEMANTICALLY THE MOST SIMILAR IN A THESAURUS \n",
      "\n",
      "to, or exactly the same as, ((\"accept\") (\"pay- \n",
      "\n",
      "MENT\")), THEN THE TARGET PATTERN (Y \"WO\" X) IS \n",
      "\n",
      "selected in figure 2. as a result, an appropriate \n",
      "\n",
      "TARGET PATTERN IS SELECTED. \n",
      "\n",
      "after a target pattern is selected, tdmt cre- \n",
      "\n",
      "ATES A TARGET STRUCTURE ACCORDING TO THE PATTERN \n",
      "\n",
      "(x (v-cn) y) \n",
      "\n",
      "((Y \"WO\" X) \n",
      "\n",
      "(((\"accept\") (\"payment\")) \n",
      "\n",
      "((\"TAKE\") (\"PICTURE\"))) \n",
      "\n",
      "(y \"hi\" x) \n",
      "\n",
      "(((\"TAKE\") (\"BUS\")) \n",
      "\n",
      "((\"get\") (\"sunstroke\"))) \n",
      "\n",
      ") \n",
      "\n",
      "figure 2: transfer ule example \n",
      "\n",
      "BY REFERRING TO A TRANSFER DICTIONARY, AS SHOWN \n",
      "\n",
      "in figure 3. if the input is \"accept (v -cn)  \n",
      "\n",
      "PAYMENT,\" THEN THIS PART IS TRANSLATED INTO \"SHI- \n",
      "\n",
      "harai wo uketsukeru.\" \"wo\" is derived from the \n",
      "\n",
      "TARGET PATTERN (Y \"WO\" X), AND \"SHIHARAI\" AND \n",
      "\n",
      "\"uketsukeru\" are derived from the transfer dic- \n",
      "\n",
      "TIONARY, AS SHOWN IN FIGURE 4. \n",
      "\n",
      "39 \n",
      "\n",
      "(SOURCE PATTERN) \n",
      "\n",
      "(((target pattern 11) :pattern-cond 11\n",
      "\n",
      "(TARGET PATTERN 12) :PATTERN-COND 12 \n",
      "\n",
      "itarget pattern in) :default) \n",
      "\n",
      "((SOURCE XAMPLE 1) \n",
      "\n",
      "Ã¢â‚¬Â¢ oo ) \n",
      "\n",
      "(((SOURCE XAMPLE 1) ~ (TARGET WORD LT) :WORD-COND 11 \n",
      "\n",
      "(source example 1) --* (target word 12) :word-cond 12 \n",
      "\n",
      "Ã‚Â°Ã‚Â° .  \n",
      "\n",
      "(source example 1) --* (target word lm) :default) \n",
      "\n",
      "O . \"  ) \n",
      "\n",
      "(((target pattern 21) :pattern-cond 21 \n",
      "\n",
      ". . .  ) ) )  \n",
      "\n",
      "figure 5: transfer ule format with information on dialogue participants \n",
      "\n",
      "(((SOURCE WORD 1) --* (TARGET WORD 11) :COND 11 I \n",
      "\n",
      "(source word 1) -* (target word 12) :cond 12 i \n",
      "\n",
      "I . . .  \n",
      "\n",
      "(source word 1) -~ (target word lk) :default)\\[ \n",
      "\n",
      "O*.  ) I \n",
      "\n",
      "figure 6: dictionary format with information on dialogue participants \n",
      "\n",
      "((SOURCE WORD) ~ (TARGET WORD) \n",
      "\n",
      "Ã¢â‚¬Â¢ \" .  ) \n",
      "\n",
      "FIGURE 3: TRANSFER DICTIONARY FORMAT \n",
      "\n",
      "((\"accept\") --* (\"uketsukeru') i (\"payment\") --* (\"shiharai\"))  \n",
      "\n",
      "FIGURE 4: TRANSFER DICTIONARY EXAMPLE \n",
      "\n",
      "(x \"sama\") \n",
      "\n",
      "(((\"MR.\" X) :H-GENDER MALE \n",
      "\n",
      "(\"ms.\" x) :h-gender female \n",
      "\n",
      "(\"MR-MS.\" X)) \n",
      "\n",
      "((\"room number\"))) \n",
      "\n",
      ") \n",
      "\n",
      "figure 7: transfer ule example with the par- \n",
      "\n",
      "TICIPANT'S GENDER \n",
      "\n",
      "3.2 transfer rules and entr ies \n",
      "\n",
      "ACCORDING TO INFORMATION ON \n",
      "\n",
      "dialogue part ic ipants \n",
      "\n",
      "FOR THIS RESEARCH, WE MODIFIED THE TRANSFER ULES \n",
      "\n",
      "and the transfer dictionary entries, as shown in \n",
      "\n",
      "FIGURES 5 AND 6. IN FIGURE 5, THE TARGET PATTERN \n",
      "\n",
      "\"target pattern 11\" and the source word \"source \n",
      "\n",
      "EXAMPLE 1\" ARE USED TO CHANGE THE TRANSLATION \n",
      "\n",
      "according to information on dialogue partici- \n",
      "\n",
      "PANTS. FOR EXAMPLE, IF \":PATTERN-COND 11\" IS DE- \n",
      "\n",
      "fined as \":h-gender male\" as shown in figure 7, \n",
      "\n",
      "THEN \"TARGET PATTERN 11\" IS SELECTED WHEN THE \n",
      "\n",
      "hearer is a male, that is, \"(\"mr.\" x)\" is selected. \n",
      "\n",
      "MOREOVER, IF \":WORD-COND 11\" IS DEFINED AS \":S- \n",
      "\n",
      "role clerk\" as shown in figure 8, then \"source \n",
      "\n",
      "EXAMPLE 1\" IS TRANSLATED INTO \"TARGET WORD 11\" \n",
      "\n",
      "when the speaker is a clerk, that is, \"accept\" is \n",
      "\n",
      "TRANSLATED INTO \"OUKESURU.\" TRANSLATIONS UCH \n",
      "\n",
      "as \"target word 11\" are valid only in the source \n",
      "\n",
      "PATTERN; THAT IS, A SOURCE EXAMPLE MIGHT NOT \n",
      "\n",
      "always be translated into one of these target \n",
      "\n",
      "WORDS. IF WE ALWAYS WANT TO PRODUCE TRANSLA- \n",
      "\n",
      "tions according to information on dialogue par- \n",
      "\n",
      "TICIPANTS, THEN WE NEED TO MODIFY THE ENTRIES \n",
      "\n",
      "in the transfer dictionary like figure 6 shows. \n",
      "\n",
      "CONVERSELY, IF WE DO NOT WANT TO ALWAYS CHANGE \n",
      "\n",
      "the translation, then we should not modify the \n",
      "\n",
      "ENTRIES BUT MODIFY THE TRANSFER ULES. SEVERAL \n",
      "\n",
      "conditions can also be given to \":word-cond\" \n",
      "\n",
      "AND \":PATTERN-COND.\" FOR EXAMPLE, \":S-ROLE CUS- \n",
      "\n",
      "tomer and :s-gender female,\" which means the \n",
      "\n",
      "SPEAKER IS A CUSTOMER AND A FEMALE, CAN BE \n",
      "\n",
      "given. in figure 5, \":default\" means the de- \n",
      "\n",
      "40 \n",
      "\n",
      "fault target pattern or word if no condition is \n",
      "\n",
      "MATCHED. THE CONDITION IS CHECKED FROM UP TO \n",
      "\n",
      "down in order; that is, first, \":pattern-cond 11,\" \n",
      "\n",
      "SECOND, \":PATTERN-COND 1~,\" ... AND SO ON. \n",
      "\n",
      "(x (v-cn) y) \n",
      "\n",
      "((Y \"WO\" X) \n",
      "\n",
      "(((\"accept\") (\"payment\")) \n",
      "\n",
      "((\"TAKE\") (\"PICTURE\"))) \n",
      "\n",
      "(((\"accept\") -~ (\"oukesuru\"):s-role clerk \n",
      "\n",
      "( \"ACCEPT\" ) --+ ( \"UKETSUKERU\" ) )) \n",
      "\n",
      ") \n",
      "\n",
      "FIGURE 8: TRANSFER ULE EXAMPLE WITH A PARTICI- \n",
      "\n",
      "pant's role \n",
      "\n",
      "(((\"PAYMENT\") --~ (\"OSHIHARAI\") :S-ROLE CLERK \n",
      "\n",
      "( \"payment\" ) ---* ( \"shiharai\" )) \n",
      "\n",
      "((\"WE\") --* (\"WATASHIDOMO\") :S-ROLE CLERK \n",
      "\n",
      "(\"we\") --~ (\"watashltachi\"))) \n",
      "\n",
      "FIGURE 9: TRANSFER DICTIONARY EXAMPLE WITH A \n",
      "\n",
      "speaker's role \n",
      "\n",
      "EVEN THOUGH WE DO NOT HAVE RULES AND EN- \n",
      "\n",
      "tries for pattern conditions and word condi- \n",
      "\n",
      "TIONS ACCORDING TO ANOTHER PARTICIPANT'S INFOR- \n",
      "\n",
      "mation, such as \":s-role customer'(which means \n",
      "\n",
      "THE SPEAKER'S ROLE IS A CUSTOMER) AND \":S-GENDER \n",
      "\n",
      "male\" (which means the speaker's gender is \n",
      "\n",
      "MALE), TDMT CAN TRANSLATE XPRESSIONS CORRE- \n",
      "\n",
      "sponding to this information too. for example, \n",
      "\n",
      "\"VERY GOOD, PLEASE LET ME CONFIRM THEM\" WILL \n",
      "\n",
      "be translated into \"shouchiitashimasita kakunin \n",
      "\n",
      "SASETE ITADAKIMASU\" WHEN THE SPEAKER IS A CLERK \n",
      "\n",
      "or \"soredekekkoudesu kakunin sasete kudasai\" \n",
      "\n",
      "WHEN THE SPEAKER IS A CUSTOMER, AS SHOWN IN \n",
      "\n",
      "example (2). \n",
      "\n",
      "BY MAKING A RULE AND AN ENTRY LIKE THE EX- \n",
      "\n",
      "amples shown in figures 8 and 9, the utter- \n",
      "\n",
      "ANCE OF EXAMPLE (1) WILL BE TRANSLATED INTO \n",
      "\n",
      "\"watashidomo wa kurejitto kaado deno oshi- \n",
      "\n",
      "HARAI WO OUKESHIMASU\" WHEN THE SPEAKER IS A \n",
      "\n",
      "clerk. \n",
      "\n",
      "4 AN  EXPER IMENT  \n",
      "\n",
      "the tdmt system for english-to-japanese at \n",
      "\n",
      "THE TIME OF THE EXPERIMENT HAD ABOUT 1,500 \n",
      "\n",
      "transfer ules and 8,000 transfer dictionary en- \n",
      "\n",
      "TRIES. IN OTHER WORDS, THIS TDMT SYSTEM WAS \n",
      "\n",
      "capable of translating 8,000 english words into \n",
      "\n",
      "JAPANESE WORDS. ABOUT 300 TRANSFER ULES AND \n",
      "\n",
      "40 transfer dictionary entries were modified to \n",
      "\n",
      "IMPROVE THE LEVEL OF \"POLITENESS.\" \n",
      "\n",
      "we conducted an experiment using the trans- \n",
      "\n",
      "FER RULES AND TRANSFER DICTIONARY FOR A CLERK WITH \n",
      "\n",
      "23 unseen dialogues (344 utterances). our input \n",
      "\n",
      "WAS OFF-LINE, I.E., A TRANSCRIPTION OF DIALOGUES, \n",
      "\n",
      "which was encoded with the participant's social \n",
      "\n",
      "ROLE. IN THE ON-LINE SITUATION, OUR SYSTEM CAN \n",
      "\n",
      "not infer whether the participant's social role is \n",
      "\n",
      "A CLERK OR A CUSTOMER, BUT CAN INSTEAD ETERMINE \n",
      "\n",
      "the role without error from the interface (such \n",
      "\n",
      "AS A MICROPHONE OR A BUTTON). \n",
      "\n",
      "in order to evaluate the experiment, we clas- \n",
      "\n",
      "SIFTED THE JAPANESE TRANSLATION RESULTS OBTAINED \n",
      "\n",
      "for the 23 unseen dialogues (199 utterances from \n",
      "\n",
      "A CLERK, AND 145 UTTERANCES FROM A CUSTOMER, \n",
      "\n",
      "making 344 utterances in total) into two types: \n",
      "\n",
      "EXPRESSIONS THAT HAD TO BE CHANGED TO MORE PO- \n",
      "\n",
      "lite expressions, and expressions that did not. \n",
      "\n",
      "TABLE 2 SHOWS THE NUMBER OF UTTERANCES THAT IN- \n",
      "\n",
      "cluded an expression which had to be changed \n",
      "\n",
      "INTO A MORE POLITE ONE (INDICATED BY \"YES\") AND \n",
      "\n",
      "those that did not (indicated by \"no\"). we ne- \n",
      "\n",
      "GLECTED 74 UTTERANCES WHOSE TRANSLATIONS WERE \n",
      "\n",
      "too poor to judge whether to assign a \"yes\" or \n",
      "\n",
      "\"NO.\" \n",
      "\n",
      "table 2: the number of utterances to be \n",
      "\n",
      "CHANGED OR NOT \n",
      "\n",
      "necessity | the number \n",
      "\n",
      "OF CHANGE I OF UTTERANCES \n",
      "\n",
      "yes 104 \n",
      "\n",
      "NO 166 \n",
      "\n",
      "out of scope 74 \n",
      "\n",
      "TOTAL \\[ 344 \n",
      "\n",
      "* 74 translations were too poor to handle for the \n",
      "\n",
      "\"POLITENESS\" PROBLEM, AND SO THEY ARE IGNORED IN THIS \n",
      "\n",
      "paper. \n",
      "\n",
      "THE TRANSLATION RESULTS WERE EVALUATED TO SEE \n",
      "\n",
      "whether the impressions of the translated re- \n",
      "\n",
      "SULTS WERE IMPROVED OR NOT WITH/WITHOUT MOD- \n",
      "\n",
      "ification for the clerk from the viewpoint of \n",
      "\n",
      "\"POLITENESS.\" TABLE 3 SHOWS THE IMPRESSIONS \n",
      "\n",
      "obtained according to the necessity of change \n",
      "\n",
      "SHOWN IN TABLE 2. \n",
      "\n",
      "the evaluation criteria are recall and preci- \n",
      "\n",
      "SION, WHICH ARE DEFINED AS FOLLOWS: \n",
      "\n",
      "recall = \n",
      "\n",
      "NUMBER OF UTTERANCES WHOSE IMPRESSION IS BETTER \n",
      "\n",
      "number of utterances which should be more polite \n",
      "\n",
      "41 \n",
      "\n",
      "example (2) \n",
      "\n",
      "ENG: VERY GOOD, PLEASE LET ME CONFIRM THEM \n",
      "\n",
      "standard: wakarimasita kakunin sasete \n",
      "\n",
      "CLERK: SHOUCHIITASHIMASITA KAKUNIN SASE~E \n",
      "\n",
      "customer: soredekekkoudesu kakunin sasete \n",
      "\n",
      "GLOSS: VERY GOOD CON:FIRM LET ME \n",
      "\n",
      "kudasai \n",
      "\n",
      "ITADAKIMASU \n",
      "\n",
      "kudasai \n",
      "\n",
      "PLEASE \n",
      "\n",
      "table 3: evaluation on using the speaker's role \n",
      "\n",
      "NECESSITY \n",
      "\n",
      "of change \n",
      "\n",
      "YES \n",
      "\n",
      "(lo4) \n",
      "\n",
      "NO \n",
      "\n",
      "(166) \n",
      "\n",
      "~ IMPRESSION \n",
      "\n",
      "better \n",
      "\n",
      "SAME \n",
      "\n",
      "worse  \n",
      "\n",
      "NO-DIFF \n",
      "\n",
      "better \n",
      "\n",
      "S ALTLE \n",
      "\n",
      "worse  \n",
      "\n",
      "NO-DIFF \n",
      "\n",
      "the number \n",
      "\n",
      "OF UTTERANCES \n",
      "\n",
      "68 \n",
      "\n",
      "5 \n",
      "\n",
      "3 \n",
      "\n",
      "28 \n",
      "\n",
      "0 \n",
      "\n",
      "3 \n",
      "\n",
      "0 \n",
      "\n",
      "163 \n",
      "\n",
      "bet ter :  impression of a translation is better. \n",
      "\n",
      "SAME:  IMPRESSION OF A TRANSLATION HAS NOT CHANGED. \n",
      "\n",
      "worse: impression of a translation is worse. \n",
      "\n",
      "NO-DIFF: THERE IS NO DIFFERENCE BETWEEN THE TWO \n",
      "\n",
      "translations. \n",
      "\n",
      "PRECISION = \n",
      "\n",
      "number of utterances whose impression is better \n",
      "\n",
      "NUMBER OF UTTERANCES WHOSE EXPRESSION HAS BEEN \n",
      "\n",
      "changed by the modified rules and entries \n",
      "\n",
      "THE RECALL WAS 65% (= 68 - (68 + 5 + 3 + 28)) \n",
      "\n",
      "and the precision was 86% (= 68 -: (68 + 5 + 3 + \n",
      "\n",
      "0+3+0)).  \n",
      "\n",
      "there are two main reasons which bring down \n",
      "\n",
      "THESE RATES. ONE REASON IS THAT TDMT DOES NOT \n",
      "\n",
      "know who or what the agent of the action in \n",
      "\n",
      "THE UTTERANCE IS; AGENTS ARE ALSO NEEDED TO SE- \n",
      "\n",
      "lect polite expressions. the other reason is that \n",
      "\n",
      "THERE ARE NOT ENOUGH RULES AND TRANSFER DICTIO- \n",
      "\n",
      "nary entries for the clerk. \n",
      "\n",
      "IT IS EASIER TO TAKE CARE OF THE LATTER PROBLEM \n",
      "\n",
      "than the former problem. if we resolve the lat- \n",
      "\n",
      "TER PROBLEM, THAT IS, IF WE EXPAND THE TRANSFER \n",
      "\n",
      "rules and the transfer dictionary entries accord- \n",
      "\n",
      "ING TO THE \"PARTICIPANT'S SOCIAL ROLE\" (A CLERK AND \n",
      "\n",
      "a customer), then the recall rate and the preci- \n",
      "\n",
      "SION RATE CAN BE IMPROVED (TO 86% AND 96%, \n",
      "\n",
      "respectively, as we have found). as a result, we \n",
      "\n",
      "CAN SAY THAT OUR METHOD IS EFFECTIVE FOR SMOOTH \n",
      "\n",
      "conversation with a dialogue translation system. \n",
      "\n",
      "5 D ISCUSS ION  \n",
      "\n",
      "in general, extra-linguistic information is hard \n",
      "\n",
      "TO OBTAIN. HOWEVER, SOME EXTRA-LINGUISTIC INFOR- \n",
      "\n",
      "mation can be easily obtained: \n",
      "\n",
      "(1) ONE PIECE OF INFORMATION IS THE PARTICIPANT'S \n",
      "\n",
      "social role, which can be obtained from the in- \n",
      "\n",
      "TERFACE SUCH AS THE MICROPHONE USED. IT WAS \n",
      "\n",
      "proven that a clerk and customer as the social \n",
      "\n",
      "ROLES OF PARTICIPANTS ARE USEFUL FOR TRANSLATION \n",
      "\n",
      "into japanese. however, more research is re- \n",
      "\n",
      "QUIRED ON ANOTHER PARTICIPANT'S SOCIAL ROLE. \n",
      "\n",
      "(2) another piece of information is the par- \n",
      "\n",
      "TICIPANT'S GENDER, WHICH CAN BE OBTAINED BY A \n",
      "\n",
      "speech recognizer with high accuracy (takezawa \n",
      "\n",
      "AND OTHERS, 1998; NAITO AND OTHERS, 1998). WE \n",
      "\n",
      "have considered how expressions can be useful \n",
      "\n",
      "BY USING THE HEARER'S GENDER FOR JAPANESE-TO- \n",
      "\n",
      "english translation. \n",
      "\n",
      "LET US CONSIDER THE JAPANESE HONORIFIC TITLE \n",
      "\n",
      "\"sama\" or \"san.\" if the heater's gender is male, \n",
      "\n",
      "THEN IT SHOULD BE TRANSLATED \"MR.\" AND IF THE \n",
      "\n",
      "hearer's gender is female, then it should be \n",
      "\n",
      "TRANSLATED \"MS.\" AS SHOWN IN FIGURE 7. AD- \n",
      "\n",
      "ditionally, the participant's gender is useful for \n",
      "\n",
      "TRANSLATING TYPICAL EXPRESSIONS FOR MALES OR FE- \n",
      "\n",
      "males. for example, japanese \"wa\" is often at- \n",
      "\n",
      "TACHED AT THE END OF THE UTTERANCE BY FEMALES. \n",
      "\n",
      "it is also important for a dialogue translation \n",
      "\n",
      "SYSTEM TO USE EXTRA-LINGUISTIC INFORMATION WHICH \n",
      "\n",
      "the system can obtain easily, in order to make \n",
      "\n",
      "A CONVERSATION PROCEED SMOOTHLY AND COMFORT- \n",
      "\n",
      "ably for humans using the translation system. \n",
      "\n",
      "WE EXPECT HAT OTHER PIECES OF USABLE INFORMA- \n",
      "\n",
      "tion can be easily obtained in the future. for \n",
      "\n",
      "EXAMPLE, AGE MIGHT BE OBTAINED FROM A CELLULAR \n",
      "\n",
      "telephone if it were always carried by the same \n",
      "\n",
      "PERSON AND PROVIDED WITH PERSONAL INFORMATION. \n",
      "\n",
      "in this case, if the system knew the hearer was a \n",
      "\n",
      "CHILD, IT COULD CHANGE COMPLEX EXPRESSIONS INTO \n",
      "\n",
      "easier ones. \n",
      "\n",
      "6 CONC LUS ION  \n",
      "\n",
      "we have proposed a method of translation us- \n",
      "\n",
      "ING INFORMATION ON DIALOGUE PARTICIPANTS, WHICH \n",
      "\n",
      "42 \n",
      "\n",
      "IS EASILY OBTAINED FROM OUTSIDE THE TRANSLATION \n",
      "\n",
      "component, and applied it to a dialogue trans- \n",
      "\n",
      "LATION SYSTEM FOR TRAVEL ARRANGEMENT. THIS \n",
      "\n",
      "method can select a polite expression for an \n",
      "\n",
      "UTTERANCE ACCORDING TO THE \"PARTICIPANT'S SOCIAL \n",
      "\n",
      "role,\" which is easily determined by the inter- \n",
      "\n",
      "FACE (SUCH AS THE WIRES TO THE MICROPHONES). FOR \n",
      "\n",
      "example, if the microphone is for the clerk (the \n",
      "\n",
      "SPEAKER IS A CLERK), THEN THE DIALOGUE TRANSLATION \n",
      "\n",
      "system can select a more polite expression. \n",
      "\n",
      "IN AN ENGLISH-TO-JAPANESE TRANSLATION SYSTEM, \n",
      "\n",
      "we added additional transfer ules and transfer \n",
      "\n",
      "DICTIONARY ENTRIES FOR THE CLERK TO BE MORE PO- \n",
      "\n",
      "lite than the customer. then, we conducted an \n",
      "\n",
      "EXPERIMENT WITH 23 UNSEEN DIALOGUES (344 UT- \n",
      "\n",
      "terances). we evaluated the translation results \n",
      "\n",
      "TO SEE WHETHER THE IMPRESSIONS OF THE RESULTS IM- \n",
      "\n",
      "proved or not. our method achieved a recall of \n",
      "\n",
      "65% AND A PRECISION OF 86%. THESE RATES COULD \n",
      "\n",
      "easily be improved to 86% and 96%, respec- \n",
      "\n",
      "TIVELY. THEREFORE, WE CAN SAY THAT OUR METHOD \n",
      "\n",
      "is effective for smooth conversation with a dia- \n",
      "\n",
      "LOGUE TRANSLATION SYSTEM. \n",
      "\n",
      "our proposal has a limitation in that if the \n",
      "\n",
      "SYSTEM DOES NOT KNOW WHO OR WHAT THE AGENT \n",
      "\n",
      "of an action in an utterance is, it cannot ap- \n",
      "\n",
      "PROPRIATELY SELECT A POLITE EXPRESSION. WE ARE \n",
      "\n",
      "considering ways to enable identification of the \n",
      "\n",
      "AGENT OF AN ACTION IN AN UTTERANCE AND TO EX- \n",
      "\n",
      "pand the current framework to improve the level \n",
      "\n",
      "OF POLITENESS EVEN MORE. IN ADDITION, WE INTEND \n",
      "\n",
      "to apply other extra-linguistic nformation to a \n",
      "\n",
      "DIALOGUE TRANSLATION SYSTEM. \n",
      "\n",
      "references  \n",
      "\n",
      "THOMAS BUB ET AL. 1997. VERBMOBIH THE \n",
      "\n",
      "combination of deep and shallow processing \n",
      "\n",
      "FOR SPONTANEOUS SPEECH TRANSLATION. IN THE \n",
      "\n",
      "1997 international conference on acoustics, \n",
      "\n",
      "SPEECH, AND SIGNAL PROCESSING: ICASSP 97, \n",
      "\n",
      "pages 71-74, munich. \n",
      "\n",
      "OSAMU FURUSE AND HITOSHI IIDA. 1996. IN- \n",
      "\n",
      "cremental translation utilizing constituent \n",
      "\n",
      "BOUNDARY PATTERNS. IN PROCEEDINGS OF \n",
      "\n",
      "coling-96, pages 412-417, copenhagen. \n",
      "\n",
      "KEIKO HORIGUCHI. 1997. TOWARDS TRANSLATING \n",
      "\n",
      "spoken language pragmatics in an analogical \n",
      "\n",
      "FRAMEWORK. IN PROCEEDINGS OFA CL/EA CL-97 \n",
      "\n",
      "workshop on spoken language translation, \n",
      "\n",
      "PAGES 16-23, MADRID. \n",
      "\n",
      "akira kurematsu and tsuyoshi morimoto. \n",
      "\n",
      "1996. AUTOMATIC SPEECH TRANSLATION. GORDON \n",
      "\n",
      "and breach publishers. \n",
      "\n",
      "SUSANN LUPERFOY ET AL. 1998. AN ARCHITECTURE \n",
      "\n",
      "for dialogue management, context tracking, \n",
      "\n",
      "AND PRAGMATIC ADAPTATION I  SPOKEN DIALOGUE \n",
      "\n",
      "system. in proceedings of coling-a cl'98, \n",
      "\n",
      "PAGES 794-801, MONTREAL. \n",
      "\n",
      "hideki mima et al. 1997. a situation-based \n",
      "\n",
      "APPROACH TO SPOKEN DIALOGUE TRANSLATION BE- \n",
      "\n",
      "tween different social roles. in proceedings of\n",
      "\n",
      "TMI-97, PAGES 176-183, SANTA FE. \n",
      "\n",
      "masaki naito et al. 1998. acoustic and lan- \n",
      "\n",
      "GUAGE MODEL FOR SPEECH TRANSLATION SYSTEM \n",
      "\n",
      "atr-matrix. in the proceedings of the \n",
      "\n",
      "1998 SPRING MEETING OF THE ACOUSTICAL SOCI- \n",
      "\n",
      "ety of japan, pages 159-160 (in japanese). \n",
      "\n",
      "MANNY RAYNER AND DAVID CARTER. 1997. HY- \n",
      "\n",
      "brid language processing in the spoken lan- \n",
      "\n",
      "GUAGE TRANSLATOR. IN THE 1997 INTERNATIONAL \n",
      "\n",
      "conference on acoustics, speech, and signal \n",
      "\n",
      "PROCESSING: ICASSP 97, PAGES 107-110, MU- \n",
      "\n",
      "nich. \n",
      "\n",
      "CAROLYN PENSTEIN ROS~ AND LORI S. LEVIN. 1998. \n",
      "\n",
      "an interactive domain independent approach \n",
      "\n",
      "TO ROBUST DIALOGUE INTERPRETATION. IN PROCEED- \n",
      "\n",
      "ings of coling-acl'98, pages 1129-1135, \n",
      "\n",
      "MONTREAL. \n",
      "\n",
      "eiichiro sumita et al. 1999. solutions to prob- \n",
      "\n",
      "LEMS INHERENT IN SPOKEN-LANGUAGE TRANSLATION: \n",
      "\n",
      "the atr-matrix approach. in the ma- \n",
      "\n",
      "CHINE TRANSLATION SUMMIT VII, PAGES 229- \n",
      "\n",
      "235, singapore. \n",
      "\n",
      "TOSHIYUKI TAKEZAWA ET AL. 1998. A JAPANESE- \n",
      "\n",
      "to-english speech translation system: atr- \n",
      "\n",
      "MATRIX. IN THE 5TH INTERNATIONAL CON- \n",
      "\n",
      "ference on spoken language processing: \n",
      "\n",
      "ICSLP-98, PAGES 2779-2782, SYDNEY. \n",
      "\n",
      "enrique vidal. 1997. finite-state speech-to- \n",
      "\n",
      "SPEECH TRANSLATION. IN THE 1997 INTERNATIONAL \n",
      "\n",
      "conference on acoustics, speech, and signal \n",
      "\n",
      "PROCESSING: ICASSP 97, PAGES 111-114, MU- \n",
      "\n",
      "nich. \n",
      "\n",
      "JAE-WOO YANG AND JUN PARK. 1997. AN EXPER- \n",
      "\n",
      "iment on korean-to-english and korean-to- \n",
      "\n",
      "JAPANESE SPOKEN LANGUAGE TRANSLATION. IN THE \n",
      "\n",
      "1997 international conference on acoustics, \n",
      "\n",
      "SPEECH, AND SIGNAL PROCESSING: ICASSP 97, \n",
      "\n",
      "pages 87-90, munich. \n",
      "\n",
      "43 \n",
      "\n",
      "disti l l ing dialogues - a method using natural dialogue \n",
      "\n",
      "DIALOGUE SYSTEMS DEVELOPMENT \n",
      "\n",
      "arne  jsnsson  and  n i l s  dah lb~ick  \n",
      "\n",
      "DEPAR TMENT  OF COMPUTER  AND  IN FORMAT ION  SC IENCE \n",
      "\n",
      "l inksp ing  un ivers i ty  \n",
      "\n",
      "S-581 83, L INKOPING \n",
      "\n",
      "sweden \n",
      "\n",
      "NILDA@IDA.LIU.SE, ARNJO@IDA.LIU.SE \n",
      "\n",
      "corpora for \n",
      "\n",
      "ABST RACT  \n",
      "\n",
      "we report on a method for utilising corpora col- \n",
      "\n",
      "LECTED IN NATURAL SETTINGS. IT IS BASED ON DISTILLING \n",
      "\n",
      "(re-writing) natural dialogues to elicit the type of \n",
      "\n",
      "DIALOGUE THAT WOULD OCCUR IF ONE THE DIALOGUE PAR- \n",
      "\n",
      "ticipants was a computer instead of a human. the \n",
      "\n",
      "METHOD IS A COMPLEMENT TOOTHER MEANS UCH AS WIZ- \n",
      "\n",
      "ard of oz-studies and un-distilled natural dialogues. \n",
      "\n",
      "WE PRESENT HE DISTILLING METHOD AND GUIDELINES FOR \n",
      "\n",
      "distillation. we also illustrate how the method af- \n",
      "\n",
      "FECTS A CORPUS OF DIALOGUES AND DISCUSS THE PROS AND \n",
      "\n",
      "cons of three approaches in different phases of dia- \n",
      "\n",
      "LOGUE SYSTEMS DEVELOPMENT. \n",
      "\n",
      "1 in t roduct ion  \n",
      "\n",
      "IT HAS BEEN KNOWN FOR QUITE SOME TIME NOW, THAT \n",
      "\n",
      "the language used when interacting with a comput- \n",
      "\n",
      "ER IS DIFFERENT FROM THE ONE USED IN DIALOGUES BETWEEN \n",
      "\n",
      "people, (c.f. jsnsson and dahlb~ick (1988)). given \n",
      "\n",
      "THAT WE KNOW THAT THE LANGUAGE WILL BE DIFFERENT, \n",
      "\n",
      "but not how it will be different, we need to base \n",
      "\n",
      "OUR DEVELOPMENT OF NATURAL LANGUAGE DIALOGUE SYS- \n",
      "\n",
      "tems on a relevant set of dialogue corpora. it is our \n",
      "\n",
      "BELIEF THAT WE NEED TO CLARIFY A NUMBER OF DIFFERENT \n",
      "\n",
      "issues regarding the collection and use of corpora in \n",
      "\n",
      "THE DEVELOPMENT OF SPEECH-ONLY AND MULTIMODAL DIA- \n",
      "\n",
      "logue systems. exchanging experiences and develop- \n",
      "\n",
      "ING GUIDELINES IN THIS AREA ARE AS IMPORTANT AS, AND IN \n",
      "\n",
      "some sense a necessary pre-requisite to, the develop- \n",
      "\n",
      "MENT OF COMPUTATIONAL MODELS OF SPEECH, LANGUAGE, \n",
      "\n",
      "and dialogue/discourse. it is interesting to note the \n",
      "\n",
      "DIFFERENCE IN THE STATE OF ART IN THE FIELD OF NATU- \n",
      "\n",
      "ral language dialogue systems with that of corpus \n",
      "\n",
      "LINGUISTICS, WHERE ISSUES OF THE USEFULNESS OF DIFFERENT \n",
      "\n",
      "samples, the necessary sampling size, representative- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NESS IN CORPUS DESIGN AND OTHER HAVE BEEN DISCUSSED \n",
      "\n",
      "for quite some time (e.g. (garside t al., 1997; atkins \n",
      "\n",
      "ET AL., 1992; CROWDY, 1993; BIBER, 1993)). ALSO THE \n",
      "\n",
      "neighboring area of evaluation of nlp systems (for \n",
      "\n",
      "AN OVERVIEW, SEE SPARCK JONES AND GALLIERS (1996)) \n",
      "\n",
      "seems to have advanced further. \n",
      "\n",
      "SOME WORK HAVE BEEN DONE IN THE AREA OF NATU- \n",
      "\n",
      "ral language dialogue systems, e.g. on the design \n",
      "\n",
      "OF WIZARD OF OZ-STUDIES (DAHLB~CK ET AL., 1998), \n",
      "\n",
      "on measures for inter-rater eliability (carletta, \n",
      "\n",
      "1996), ON FRAMEWORKS FOR EVALUATING SPOKEN DIALOGUE \n",
      "\n",
      "agents (walker et al., 1998) and on the use of differ- \n",
      "\n",
      "ENT CORPORA IN THE DEVELOPMENT OF A PARTICULAR SYS- \n",
      "\n",
      "tem (the carnegie-mellon communicator, eskenazi \n",
      "\n",
      "ET AL. (1999)). \n",
      "\n",
      "the question we are addressing in this paper is \n",
      "\n",
      "HOW TO COLLECT AND ANALYSE RELEVANT CORPORA. WE BE- \n",
      "\n",
      "gin by describing what we consider to be the main \n",
      "\n",
      "ADVANTAGES AND DISADVANTAGES OF THE TWO CURRENTLY \n",
      "\n",
      "used methods; studies of human dialogues and wiz- \n",
      "\n",
      "ARD OF OZ-DIALOGUES, ESPECIALLY FOCUSING ON THE ECO- \n",
      "\n",
      "logical validity of the methods. we then describe a \n",
      "\n",
      "METHOD CALLED 'DISTILLING DIALOGUES', WHICH CAN SERVE \n",
      "\n",
      "as a supplement to the other two. \n",
      "\n",
      "2 NATURAL AND WIZARD OF \n",
      "\n",
      "oz-dialogues \n",
      "\n",
      "THE ADVANTAGE OF USING REAL DIALOGUES BETWEEN PEO- \n",
      "\n",
      "ple is that they will illustrate which tasks and needs \n",
      "\n",
      "THAT PEOPLE ACTUALLY BRING TO A PARTICULAR SERVICE \n",
      "\n",
      "provider. thus, on the level of the users' general \n",
      "\n",
      "GOALS, SUCH DIALOGUES HAVE A HIGH VALIDITY. BUT THERE \n",
      "\n",
      "are two drawbacks here. first; it is not self-evident \n",
      "\n",
      "THAT USERS WILL HAVE THE SAME TASK EXPECTATIONS FROM \n",
      "\n",
      "a computer system as they have with a person. sec- \n",
      "\n",
      "OND, THE LANGUAGE USED WILL DIFFER FROM THE LANGUAGE \n",
      "\n",
      "used when interacting with a computer. \n",
      "\n",
      "THESE TWO DISADVANTAGES HAVE BEEN THE MAJOR \n",
      "\n",
      "force behind the development of wizard of oz- \n",
      "\n",
      "METHODS. THE ADVANTAGE HERE IS THAT THE SETTING WILL \n",
      "\n",
      "be human-computer interaction. but there are im- \n",
      "\n",
      "PORTANT DISADVANTAGES, TOO. FIRST, ON THE PRACTICAL \n",
      "\n",
      "side, the task of setting up a high quality simulation \n",
      "\n",
      "ENVIRONMENT AND TRAINING THE OPERATORS ('WIZARDS') \n",
      "\n",
      "to use this is a resource consuming task (dahlb~ck et \n",
      "\n",
      "AL., 1998). SECOND, AND PROBABLY EVEN MORE IMPOR- \n",
      "\n",
      "tant, is that we cannot hen observe real users using \n",
      "\n",
      "A SYSTEM FOR REAL LIFE TASKS, WHERE THEY BRING THEIR \n",
      "\n",
      "own needs, motivations, resources, and constraints \n",
      "\n",
      "TO BEAR. TO SOME EXTENT THIS PROBLEM CAN BE OVER- \n",
      "\n",
      "come using well-designed so called 'scenarios'. as \n",
      "\n",
      "POINTED OUT IN DAHLB~CK (1991), ON MANY LEVELS OF \n",
      "\n",
      "analysis the artificiality of the situation will not af- \n",
      "\n",
      "44 \n",
      "\n",
      "fect the language used. an example of this is the \n",
      "\n",
      "PATTERN OF PRONOUN-ANTECEDENT RELATIONS. BUT SINCE \n",
      "\n",
      "the tasks given to the users are often pre-described \n",
      "\n",
      "BY THE RESEARCHERS, THIS MEANS THAT THIS IS NOT A GOOD \n",
      "\n",
      "way of finding out which tasks the users actually \n",
      "\n",
      "WANT TO PERFORM. NOR DOES IT PROVIDE A CLEAR ENOUGH \n",
      "\n",
      "picture on how the users will act to find something \n",
      "\n",
      "THAT SATISFIES THEIR REQUIREMENTS. IF E.G. THE TASK IS \n",
      "\n",
      "one of finding a charter holiday trip or buying a tv- \n",
      "\n",
      "SET WITHIN A SPECIFIED SET OF CONSTRAINTS (ECONOMICAL \n",
      "\n",
      "and other), it is conceivable that people will stay \n",
      "\n",
      "WITH THE FIRST ITEM THAT MATCHES THE SPECIFICATION, \n",
      "\n",
      "whereas in real life they would probably look for \n",
      "\n",
      "ALTERNATIVES. IN OUR EXPERIENCE, THIS IS PRIMARILY A \n",
      "\n",
      "concern if the focus is on the users' goals and plans, \n",
      "\n",
      "BUT IS LESS A PROBLEM WHEN THE INTEREST IS ON LOWER- \n",
      "\n",
      "level aspects, such as, syntax or patterns of pronoun- \n",
      "\n",
      "ANTECEDENT RELATIONSHIP (C.F. DAHLB~ICK (1991)). \n",
      "\n",
      "to summarize; real life dialogues will provide a \n",
      "\n",
      "REASONABLY CORRECT PICTURE OF THE WAY USERS' AP- \n",
      "\n",
      "proach their tasks, and what tasks they bring to \n",
      "\n",
      "THE SERVICE PROVIDER, BUT THE LANGUAGE USED WILL NOT \n",
      "\n",
      "give a good approximation of what the system un- \n",
      "\n",
      "DER CONSTRUCTION WILL NEED TO HANDLE. WIZARD OF OZ- \n",
      "\n",
      "dialogues, on the other hand, will give a reasonable \n",
      "\n",
      "APPROXIMATION OF SOME ASPECTS OF THE LANGUAGE USED, \n",
      "\n",
      "but in an artificial context. \n",
      "\n",
      "THE USUAL APPROACH HAS BEEN TO WORK IN THREE \n",
      "\n",
      "steps. first analyse real human dialogues, and based \n",
      "\n",
      "ON THESE, IN THE SECOND PHASE, DESIGN ONE OR MORE \n",
      "\n",
      "wizard of oz-studies. the final step is to fine-tune \n",
      "\n",
      "THE SYSTEM'S PERFORMANCE ON REAL USERS. A GOOD EX- \n",
      "\n",
      "ample of this method is presented in eskenazi et al. \n",
      "\n",
      "(1999). BUT THERE ARE ALSO POSSIBLE PROBLEMS WITH \n",
      "\n",
      "this approach (though we are not claiming that this \n",
      "\n",
      "WAS THE CASE IN THEIR PARTICULAR PROJECT). ESKENAZI ET \n",
      "\n",
      "al. (1999) asked a human operator to act 'computer- \n",
      "\n",
      "LIKE' IN THEIR WIZARD OF OZ-PHASE. THE ADVANTAGE \n",
      "\n",
      "is of course that the human operator will be able \n",
      "\n",
      "TO PERFORM ALL THE TASKS THAT IS USUALLY PROVIDED BY \n",
      "\n",
      "this service. the disadvantage is that it puts a heavy \n",
      "\n",
      "BURDEN ON THE HUMAN OPERATOR TO ACT AS A COMPUT- \n",
      "\n",
      "er. since we know that lay-persons' ideas of what \n",
      "\n",
      "COMPUTERS CAN AND CANNOT DO ARE IN MANY RESPECTS \n",
      "\n",
      "far removed from what is actually the case, we risk \n",
      "\n",
      "INTRODUCING SOME SYSTEMATIC DISTORTION HERE. AND \n",
      "\n",
      "since it is difficult to perform consistently in similar \n",
      "\n",
      "SITUATIONS, WE ALSO RISK INTRODUCING NON-SYSTEMATIC \n",
      "\n",
      "distortion here, even in those cases when the 'wiz- \n",
      "\n",
      "ARD' IS AN NLP-PROFESSIONAL. \n",
      "\n",
      "our suggestion is therefore to supplement he \n",
      "\n",
      "ABOVE MENTIONED METHODS, AND BRIDGE THE GAP BE- \n",
      "\n",
      "tween them, by post-processing human dialogues to \n",
      "\n",
      "GIVE THEM A COMPUTER-LIKE QUALITY. THE ADVANTAGE, \n",
      "\n",
      "compared to having people do the simulation on the \n",
      "\n",
      "FLY, IS BOTH THAT IT CAN BE DONE WITH MORE CONSIS- \n",
      "\n",
      "tency, and also that it can be done by researchers \n",
      "\n",
      "THAT ACTUALLY KNOW WHAT HUMAN-COMPUTER NATURAL \n",
      "\n",
      "language dialogues can look like. a possible dis- \n",
      "\n",
      "ADVANTAGE WITH USING BOTH WIZARD OF OZ-AND REAL \n",
      "\n",
      "computer dialogues, is that users will quickly adapt \n",
      "\n",
      "TO WHAT THE SYSTEM CAN PROVIDE THEM WITH, AND WILL \n",
      "\n",
      "therefore not try to use it for tasks they know it \n",
      "\n",
      "CANNOT PERFORM. CONSEQUENTLY, WE WILL NOT GET A FULL \n",
      "\n",
      "picture of the different services they would like the \n",
      "\n",
      "SYSTEM TO PROVIDE. \n",
      "\n",
      "a disadvantage with this method is, of course, \n",
      "\n",
      "THAT POST-PROCESSING TAKES SOME TIME COMPARED TO \n",
      "\n",
      "using the natural dialogues as they are. there is al- \n",
      "\n",
      "SO A CONCERN ON THE ECOLOGICAL VALIDITY OF THE RESULTS, \n",
      "\n",
      "as discussed later. \n",
      "\n",
      "3 DISTILLING DIALOGUES \n",
      "\n",
      "distilling dialogues, i.e. re-writing human interac- \n",
      "\n",
      "TIONS IN ORDER TO HAVE THEM REFLECT WHAT A HUMAN- \n",
      "\n",
      "computer interaction could look like involves a num- \n",
      "\n",
      "BER OF CONSIDERATIONS. THE MAIN ISSUE IS THAT IN COR- \n",
      "\n",
      "pora of natural dialogues one of the interlocutors i\n",
      "\n",
      "NOT A DIALOGUE SYSTEM. THE SYSTEM'S TASK IS INSTEAD \n",
      "\n",
      "performed by a human and the problem is how to \n",
      "\n",
      "ANTICIPATE THE BEHAVIOUR OF A SYSTEM THAT DOES NOT \n",
      "\n",
      "exist based on the performance of an agent with dif- \n",
      "\n",
      "FERENT PERFORMANCE CHARACTERISTICS. ONE IMPORTANT \n",
      "\n",
      "aspect is how to deal with human features that are \n",
      "\n",
      "NOT PART OF WHAT THE SYSTEM IS SUPPOSED TO BE ABLE  \n",
      "\n",
      "to handle, for instance if the user talks about things \n",
      "\n",
      "OUTSIDE OF THE DOMAIN, SUCH AS DISCUSSING AN EPISODE \n",
      "\n",
      "of a recent tv show. it also involves issues on how \n",
      "\n",
      "TO HANDLE SITUATIONS WHERE ONE OF THE INTERLOCUTERS \n",
      "\n",
      "discusses with someone lse on a different opic, e.g. \n",
      "\n",
      "DISCUSSING THE UP-COMING FRIDAY PARTY WITH A FRIEND \n",
      "\n",
      "in the middle of an information providing dialogue \n",
      "\n",
      "WITH A CUSTOMER. \n",
      "\n",
      "it is important for the distilling process to have at \n",
      "\n",
      "LEAST AN OUTLINE OF THE DIALOGUE SYSTEM THAT IS UNDER \n",
      "\n",
      "development: will it for instance have the capacity \n",
      "\n",
      "TO RECOGNISE USERS' GOALS, EVEN IF NOT EXPLICITLY STAT- \n",
      "\n",
      "ed? will it be able to reason about the discourse \n",
      "\n",
      "DOMAIN? WHAT SERVICES WILL IT PROVIDE, AND WHAT \n",
      "\n",
      "will be outside its capacity to handle? \n",
      "\n",
      "IN OUR CASE, WE ASSUME THAT THE PLANNED DIALOGUE \n",
      "\n",
      "system has the ability to reason on various aspects \n",
      "\n",
      "OF DIALOGUE AND PROPERTIES OF THE APPLICATION. IN OUR \n",
      "\n",
      "current work, and in the examples used for illustra- \n",
      "\n",
      "TION IN THIS PAPER, WE ASSUME A DIALOGUE MODEL THAT \n",
      "\n",
      "can handle any relevant dialogue phenomenon and \n",
      "\n",
      "ALSO AN INTERPRETER AND SPEECH RECOGNISER BEING ABLE \n",
      "\n",
      "to understand any user input that is relevant o the \n",
      "\n",
      "TASK. THERE IS IS ALSO A POWERFUL DOMAIN REASON- \n",
      "\n",
      "ing module allowing for more or less any knowledge \n",
      "\n",
      "REASONING ON ISSUES THAT CAN BE ACCOMPLISHED WITH- \n",
      "\n",
      "in the domain (flycht-eriksson, 1999). our current \n",
      "\n",
      "SYSTEM DOES, HOWEVER, NOT HAVE AN EXPLICIT USER TASK \n",
      "\n",
      "model, as opposed to a system task model (dahlb~ick \n",
      "\n",
      "45 \n",
      "\n",
      "and jsnsson, 1999), which is included, and thus, we \n",
      "\n",
      "CAN NOT ASSUME THAT THE 'SYSTEM' REMEMBERS UTTER- \n",
      "\n",
      "ances where the user explains its task. furthermore, \n",
      "\n",
      "AS OUR AIM IS SYSTEM DEVELOPMENT WE WILL NOT CON- \n",
      "\n",
      "sider interaction outside the systems capabilities as \n",
      "\n",
      "RELEVANT O INCLUDE IN THE DISTILLED DIALOGUES. \n",
      "\n",
      "the context of our work is the development a \n",
      "\n",
      "MULTI-MODAL DIALOGUE SYSTEM. HOWEVER, IN OUR CUR- \n",
      "\n",
      "rent work with distilling dialogues, the abilities of \n",
      "\n",
      "A MULTI-MODAL SYSTEM WERE NOT FULLY ACCOUNTED FOR. \n",
      "\n",
      "the reason for this is that the dialogues would be \n",
      "\n",
      "SIGNIFICANTLY AFFECTED, E.G. A TELEPHONE CONVERSATION \n",
      "\n",
      "where the user always likes to have the next con- \n",
      "\n",
      "NECTION, PLEASE WILL RESULT IN A TABLE IF MULTI-MODAL \n",
      "\n",
      "output is possible and hence a fair amount of the di- \n",
      "\n",
      "ALOGNE IS REMOVED. WE HAVE THEREFORE IN THIS PAPER \n",
      "\n",
      "analysed the corpus assuming a speech-only system, \n",
      "\n",
      "SINCE THIS IS CLOSER TO THE ORIGINAL TELEPHONE CONVERSA- \n",
      "\n",
      "tions, and hence needs fewer assumptions on system \n",
      "\n",
      "PERFORMANCE WHEN DISTILLING THE DIALOGUES. \n",
      "\n",
      "4 dis t i l l a t ion  gu ide l ines  \n",
      "\n",
      "DISTILLING DIALOGUES REQUIRES GUIDELINES FOR HOW TO \n",
      "\n",
      "handle various types of utterances. in this section \n",
      "\n",
      "WE WILL PRESENT OUR GUIDELINES FOR DISTILLING A CORPUS \n",
      "\n",
      "of telephone conversations between a human infor- \n",
      "\n",
      "MATION PROVIDER ON LOCAL BUSES 1TO BE USED FOR DEVEL- \n",
      "\n",
      "oping a multimodal dialogue system (qvarfordt and \n",
      "\n",
      "JSNSSON, 1998; FLYCHT-ERIKSSON AND JSNSSON, 1998; \n",
      "\n",
      "dahlb~ick et al., 1999; qvarfordt, 1998). similar \n",
      "\n",
      "GUIDELINES ARE USED WITHIN ANOTHER PROJECT ON DEVEL- \n",
      "\n",
      "oping swedish dialogue systems where the domain \n",
      "\n",
      "IS TRAVEL BUREAU INFORMATION. \n",
      "\n",
      "we can distinguish three types of contributors: \n",
      "\n",
      "'SYSTEM' (I.E. A FUTURE SYSTEMS) UTTERANCES, USER UT- \n",
      "\n",
      "terances, and other types, such as moves by other \n",
      "\n",
      "SPEAKERS, AND NOISE. \n",
      "\n",
      "4.1 modifying system utterances \n",
      "\n",
      "THE PROBLEM OF MODIFYING 'SYSTEM' UTTERANCES CAN \n",
      "\n",
      "be divided into two parts: how to change and when \n",
      "\n",
      "TO CHANGE. THEY ARE IN SOME RESPECTS INTERTWINED, \n",
      "\n",
      "but as the how-part affects the when-part more we \n",
      "\n",
      "WILL TAKE THIS AS A STARTING POINT. \n",
      "\n",
      "Ã¢â‚¬Â¢ the 'system' provides as much relevant infor- \n",
      "\n",
      "MATION AS POSSIBLE AT ONCE. THIS DEPENDS ON \n",
      "\n",
      "the capabilities of the systems output modal- \n",
      "\n",
      "ITIES. IF WE HAVE A SCREEN OR SIMILAR OUTPUT \n",
      "\n",
      "device we present as much as possible which \n",
      "\n",
      "NORMALLY IS ALL RELEVANT INFORMATION. IF WE, ON \n",
      "\n",
      "the other hand, only have spoken output the \n",
      "\n",
      "AMOUNT OF INFORMATION THAT THE HEARER CAN INTER- \n",
      "\n",
      "pret in one utterance must be considered when \n",
      "\n",
      "1THE BUS TIME TABLE DIALOGUES ARE COLLECTED AT \n",
      "\n",
      "linksping university and are available (in swedish) on \n",
      "\n",
      "HTTP://WWW.IDA.L IU.SE/~ARNJO/KFB/DIALOGER.HTML \n",
      "\n",
      "distilling. the system might in such cases pro- \n",
      "\n",
      "VIDE LESS INFORMATION. THE PRINCIPLE OF PROVID- \n",
      "\n",
      "ing all relevant information is based on the as- \n",
      "\n",
      "SUMPTION THAT A COMPUTER SYSTEM OFTEN HAS AC- \n",
      "\n",
      "cess to all relevant information when querying \n",
      "\n",
      "THE BACKGROUND SYSTEM AND CAN ALSO PRESENT IT \n",
      "\n",
      "more conveniently, especially in a multimodal \n",
      "\n",
      "SYSTEM (AHRENBERG ET AL., 1996). A TYPICAL EX- \n",
      "\n",
      "ample is the dialogue fragment in figure 1. in \n",
      "\n",
      "THIS FRAGMENT HE SYSTEM PROVIDES INFORMATION \n",
      "\n",
      "on what train to take and how to change to a \n",
      "\n",
      "BUS. THE RESULT OF DISTILLING THIS FRAGMENT PRO- \n",
      "\n",
      "vides the revised fragment of figure 2. as seen in \n",
      "\n",
      "THE FRAGMENT OF FIGURE 2 WE ALSO REMOVE A NUM- \n",
      "\n",
      "ber of utterances typical for human interaction, \n",
      "\n",
      "AS DISCUSSED BELOW. \n",
      "\n",
      "* system utterances are made more computer-l ike \n",
      "\n",
      "AND DO NOT INCLUDE IRRELEVANT INFORMATION. THE \n",
      "\n",
      "latter is seen in $9 in the dialogue in figure 3 \n",
      "\n",
      "WHERE THE PROVIDED INFORMATION IS NOT RELEVANT. \n",
      "\n",
      "it could also be possible to remove $5 and re- \n",
      "\n",
      "SPOND WITH $7 AT ONCE. THIS, HOWEVER, DEPENDS \n",
      "\n",
      "on if the information grounded in $5-u6 is need- \n",
      "\n",
      "ED FOR THE 'SYSTEM' IN ORDER TO KNOW THE ARRIVAL \n",
      "\n",
      "time or if that could be concluded from u4. \n",
      "\n",
      "THIS IN TURN DEPENDS ON THE SYSTEM'S CAPABILI- \n",
      "\n",
      "ties. if we assume that the dialogue system has \n",
      "\n",
      "A MODEL OF USER TASKS, THE INFORMATION IN $5-U6 \n",
      "\n",
      "could have been concluded from that. we will, \n",
      "\n",
      "IN THIS CASE, RETAIN $5-U6 AS WE DO NOT ASSUME A\n",
      "\n",
      "user task model (dahlb/ick and jsnsson, 1999) \n",
      "\n",
      "AND IN ORDER TO STAY AS CLOSE TO THE ORIGINAL DI- \n",
      "\n",
      "alogue as possible. \n",
      "\n",
      "THE NEXT PROBLEM CONCERNS THE CASE WHEN 'SYSTEM' \n",
      "\n",
      "utterances are changed or removed. \n",
      "\n",
      "Ã‚â‚¬Â¢ DIALOGUE CONTRIBUTIONS PROVIDED BY SOMETHING OR \n",
      "\n",
      "someone other than the user or the 'system' are \n",
      "\n",
      "REMOVED. THESE ARE REGARDED AS NOT BEING PART \n",
      "\n",
      "of the interaction. this means that if some- \n",
      "\n",
      "ONE INTERRUPTS THE CURRENT INTERACTION, SAY THAT \n",
      "\n",
      "the telephone rings during a face-to-face inter- \n",
      "\n",
      "ACTION, THE INTERRUPTING INTERACTION IS NORMALLY \n",
      "\n",
      "removed from the corpus. \n",
      "\n",
      "FURTHERMORE, 'SYSTEM' INTERRUPTIONS ARE RE- \n",
      "\n",
      "moved. a human can very well interrupt anoth- \n",
      "\n",
      "ER HUMAN INTERLOCUTER, BUT A COMPUTER SYSTEM \n",
      "\n",
      "will not do that. \n",
      "\n",
      "HOWEVER, THIS GUIDELINE COULD LEAD TO PROBLEMS, \n",
      "\n",
      "for instance, when users follow up such interrup- \n",
      "\n",
      "TIONS. IF NO INFORMATION IS PROVIDED OR THE IN- \n",
      "\n",
      "terrupted sequence does not affect the dialogue, \n",
      "\n",
      "WE HAVE NO PROBLEMS REMOVING THE INTERRUPTION. \n",
      "\n",
      "the problem is what to do when information \n",
      "\n",
      "FROM THE 'SYSTEM' IS USED IN THE CONTINUING DIA- \n",
      "\n",
      "logue. for such cases we have no fixed strategy, \n",
      "\n",
      "46 \n",
      "\n",
      "u4: \n",
      "\n",
      "$5: \n",
      "\n",
      "u6: \n",
      "\n",
      "$7: \n",
      "\n",
      "u8: \n",
      "\n",
      "$9: \n",
      "\n",
      "u10: \n",
      "\n",
      "$11: \n",
      "\n",
      "u12: \n",
      "\n",
      "S13: \n",
      "\n",
      "u14: \n",
      "\n",
      "$15: \n",
      "\n",
      "yes i wonder if you have any mm buses or (.) like express buses leaving from linksping \n",
      "\n",
      "TO VADSTENA (.) ON SUNDAY \n",
      "\n",
      "ja ville undra om ni hade ndgra 5h bussar euer (.) typ expressbussar sore dkte frdn linksping \n",
      "\n",
      "TILL VADSTENA (.) PD SSNDA \n",
      "\n",
      "no the bus does not run on sundays \n",
      "\n",
      "NEJ BUSSEN G~R INTE PD SSNDAGAR \n",
      "\n",
      "how can you (.) can you take the train and then change some way (.) because (.) \n",
      "\n",
      "TO MJSLBY 'N' SO \n",
      "\n",
      "hur kan man (.) kan man ta tdg d sen byta p~ ndtt sstt (.) fsr de (.) \n",
      "\n",
      "TILL MJSLBY ~ SD \n",
      "\n",
      "that you can do too yes \n",
      "\n",
      "DE KAN DU GSRA OCKSD JA \n",
      "\n",
      "how (.) do you have any such suggestions \n",
      "\n",
      "HUT (.) HAR DU N~RA N~GRA S~NA FSRSLAG \n",
      "\n",
      "yes let's see (4s) a moment (15s) now let us see here (.) was it on the sunday you should travel \n",
      "\n",
      "JA SKA SE H~IR (4S) EFT 5GONBLICK (15S) NU SKA VISE HSR (.) VA DE P~ SSNDAGEN DU SKULLE DKA PD \n",
      "\n",
      "yes right afternoon preferably \n",
      "\n",
      "JA JUST DE EFTERMIDDA GGIRNA \n",
      "\n",
      "afternoon preferable (.) you have train from linksping fourteen twenty nine \n",
      "\n",
      "EFTERMIDDA GSRNA (.) DU HAT T~G FRDN LINKSPING FJORTON D TJUGONIE \n",
      "\n",
      "mm \n",
      "\n",
      "MM \n",
      "\n",
      "and then you will change from mjslby station six hundred sixty \n",
      "\n",
      "SD BYTER DU FRDN MJSLBY STATION SEXHUNDRASEXTI \n",
      "\n",
      "sixhundred sixty \n",
      "\n",
      "SEXHUNDRASEXTI \n",
      "\n",
      "fifteen and ten \n",
      "\n",
      "FEMTON ~ TIE \n",
      "\n",
      "figure 1: dialogue fragment from a real interaction on bus time-table information \n",
      "\n",
      "U4: I WONDER IF YOU HAVE ANY BUSES OR (.) LIKE EXPRESS BUSES GOING FROM LINKSPING \n",
      "\n",
      "to vadstena (.) on sunday \n",
      "\n",
      "S5: NO THE BUS DOES NOT RUN ON SUNDAYS \n",
      "\n",
      "u6: how can you (.) can you take the train and then change some way (.) because (.) \n",
      "\n",
      "TO MJSLBY AND SO \n",
      "\n",
      "$7: you can take the train from linksping fourteen and twenty nine and then you will \n",
      "\n",
      "CHANGE AT MJSLBY STATION TO BUS SIX HUNDRED SIXTY AT FIFTEEN AND TEN \n",
      "\n",
      "figure 2: a distilled version of the dialogue in figure 1 \n",
      "\n",
      "THE DIALOGUE NEEDS TO BE REARRANGED EPENDING \n",
      "\n",
      "on how the information is to be used (c.f. the \n",
      "\n",
      "DISCUSSION IN THE FINAL SECTION OF THIS PAPER). \n",
      "\n",
      "Ã¢â‚¬Â¢ 'system' utterances which are no longer valid \n",
      "\n",
      "ARE REMOVED. TYPICAL EXAMPLES OF THIS ARE THE \n",
      "\n",
      "utterances $7, $9, $11 and $13 in the dialogue \n",
      "\n",
      "FRAGMENT OF FIGURE 1. \n",
      "\n",
      "* remove sequences of utterances where the 'sys- \n",
      "\n",
      "TEM' BEHAVES IN A WAY A COMPUTER WOULD NOT DO. \n",
      "\n",
      "for instance jokes, irony, humor, commenting \n",
      "\n",
      "ON THE OTHER DIALOGUE PARTICIPANT, OR DROPPING \n",
      "\n",
      "the telephone (or whatever is going on in $7 \n",
      "\n",
      "IN FIGURE 4). A COMMON CASE OF THIS IS WHEN \n",
      "\n",
      "the 'system' is talking while looking for infor- \n",
      "\n",
      "MATION, $5 IN THE DIALOGUE FRAGMENT OF FIGURE 4 \n",
      "\n",
      "is an example of this. related to this is when \n",
      "\n",
      "THE SYSTEM PROVIDES ITS OWN COMMENTS. IF WE \n",
      "\n",
      "can assume that it has such capabilities they \n",
      "\n",
      "ARE INCLUDED, OTHERWISE WE REMOVE THEM. \n",
      "\n",
      "the system does not repeat information that has \n",
      "\n",
      "ALREADY BEEN PROVIDED UNLESS EXPLICITLY ASKED TO \n",
      "\n",
      "do so. in human interaction it is not uncommon \n",
      "\n",
      "TO REPEAT WHAT HAS BEEN UTTERED FOR PURPOSES \n",
      "\n",
      "other than to provide grounding information or \n",
      "\n",
      "FEEDBACK. THIS IS FOR INSTANCE COMMON DURING \n",
      "\n",
      "47  \n",
      "\n",
      "U4: 'N' I MUST BE AT RESECENTRUM BEFORE FOURTEEN AND THIRTY FIVE (.) 'CAUSE WE WILL GOING TO THE \n",
      "\n",
      "interstate buses \n",
      "\n",
      "JA SKA VA P~ RECECENTRUM INNAN \\]JORTON ~ TRETTIFEM (.) F5 VI SKA TILL \n",
      "\n",
      "l~ngf~irdsbussarna \n",
      "\n",
      "$5: AHA (.) 'N' THEN YOU MUST BE THERE AROUND TWENTY PAST TWO SOMETHING THEN \n",
      "\n",
      "jaha (.) ~ dd behhver du va here strax e~ter tjuge 5vet tvd n~nting d~ \n",
      "\n",
      "U6: YES AROUND THAT \n",
      "\n",
      "ja ungefgir \n",
      "\n",
      "$7: LET'S SEE HERE ( L LS)  TWO HUNDRED AND FOURTEEN RYD END STATION LEAVES FORTY SIX (.) THIRTEEN 'N' \n",
      "\n",
      "forty six then you will be down fourteen oh seven (.) \n",
      "\n",
      "D~ SKA VISE HSR (11S) TV~HUNDRAFJORTON RYD 5NDH~LLPLATSEN GDR ~5RTISEX (.) TRETTON D \n",
      "\n",
      "\\]srtisex d~ dr du nere ~jorton noll sju 5) \n",
      "\n",
      "U8: AHA \n",
      "\n",
      "jaha \n",
      "\n",
      "$9: 'N' (.) THE NEXT ONE TAKES YOU THERE (.) FOURTEEN THIRTY SEVEN (.) BUT THAT IS TOO LATE \n",
      "\n",
      "(.) ndsta dr du nere 5) ~jorton d trettisju (.) men de 5 ju ~sr sent \n",
      "\n",
      "FIGURE 3: DIALOGUE FRAGMENT FROM A REAL INTERACTION ON BUS TIME-TABLE INFORMATION \n",
      "\n",
      "u2: well, hi (.) i am going to ugglegatan eighth \n",
      "\n",
      "JA HEJ (.) JA SKA TILL UGGLEGATAN DTTA \n",
      "\n",
      "$3: yes \n",
      "\n",
      "JA \n",
      "\n",
      "u4: and (.) i wonder (.) it is somewhere in tannefors \n",
      "\n",
      "OCH (.) JAG UNDRAR (.) DET LIGGER NDNSTANS I TANNEFORS \n",
      "\n",
      "$5: yes (.) i will see here one one i will look exactly where it is one moment please \n",
      "\n",
      "JA (.) JAG SKA SE HHR EFT EFT JAG SKA TITTA EXAKT VAT DET LIGGER EFT 6GONBLICK BARN \n",
      "\n",
      "u6: oh yeah \n",
      "\n",
      "JAR~ \n",
      "\n",
      "$7: (operator disconnects) (25s) mm (.) okey (hs) what the hell (2s) \n",
      "\n",
      "(OPERATOR CONNECTS AGAIN) HELLO YES \n",
      "\n",
      "((telefonisten kopplar ur sig)) (25s) iihh (.) okey (hs) de va sore \\]aan (2s) \n",
      "\n",
      "((TELEFONISTEN KOPPLAR IN SIG IGEN)) HALLD JA \n",
      "\n",
      "u8: yes hello \n",
      "\n",
      "JA HEJ \n",
      "\n",
      "$9: it is bus two hundred ten which runs on old tannefors road that you have to take and get off at \n",
      "\n",
      "THE BUS STOP AT THAT BUS STOP NAMED VETEGATAN \n",
      "\n",
      "det ~i buss tv~hundratio sore g~r gamla tanne~orsvsgen som du ~r  ~ka ~ g~ av rid \n",
      "\n",
      "DEN HDLLPLATSEN RID DEN HDLLPLATSEN SORE HETER VETEGATAN. \n",
      "\n",
      "figure 4: dialogue fragment from a natural bus timetable interaction \n",
      "\n",
      "SEARCH PROCEDURES AS DISCUSSED ABOVE. \n",
      "\n",
      "Ã¢â‚¬Â¢ the system does not ask for information it has \n",
      "\n",
      "ALREADY ACHIEVED. FOR INSTANCE ASKING AGAIN IF IT \n",
      "\n",
      "is on sunday as in $9 in figure 1. this is not un- \n",
      "\n",
      "COMMON IN HUMAN INTERACTION AND SUCH UTTER- \n",
      "\n",
      "ances from the user are not removed. however, \n",
      "\n",
      "WE CAN ASSUME THAT THE DIALOGUE SYSTEM DOES \n",
      "\n",
      "not forget what has been talked about before. \n",
      "\n",
      "4.2 MOD I FY ING  USER  U T TE RANCES  \n",
      "\n",
      "the general rule is to change user utterances as lit- \n",
      "\n",
      "TLE AS POSSIBLE. THE REASON FOR THIS IS THAT WE DO NOT \n",
      "\n",
      "want to develop systems where the user needs to \n",
      "\n",
      "RESTRICT HIS/HER BEHAVIOUR TO THE CAPABILITIES OF THE \n",
      "\n",
      "dialogue system. however, there are certain changes \n",
      "\n",
      "MADE TO USER UTTERANCES, IN MOST CASES AS A CONSE- \n",
      "\n",
      "quence of changes of system utterances. \n",
      "\n",
      "UTTERANCES THAT ARE NO LONGER VALID ARE REMOVED. \n",
      "\n",
      "the most common cases are utterances whose \n",
      "\n",
      "REQUEST HAS ALREADY BEEN ANSWERED, AS SEEN IN \n",
      "\n",
      "the distilled dialogue in figure 2 of the dialogue \n",
      "\n",
      "IN FIGURE 1. \n",
      "\n",
      "48 \n",
      "\n",
      "SL1: SIXTEEN FIFTY FIVE \n",
      "\n",
      "sexton \\]emti/em \n",
      "\n",
      "U12: SIXTEEN FIFTY FIVE (.) AHA \n",
      "\n",
      "sexton femti/em (.) jaha \n",
      "\n",
      "S13: BUS LINE FOUR HUNDRED THIRTY FIVE \n",
      "\n",
      "linje \\]yrahundra tretti/em \n",
      "\n",
      "FIGURE 5: DIALOGUE FRAGMENT FROM A NATURAL BUS \n",
      "\n",
      "timetable interaction \n",
      "\n",
      "Ã‚â‚¬Â¢ UTTERANCES ARE REMOVED WHERE THE USER DISCUSS- \n",
      "\n",
      "es things that are in the environment. for \n",
      "\n",
      "INSTANCE COMMENTING THE 'SYSTEMS' CLOTHES OR \n",
      "\n",
      "hair. this also includes other types of commu- \n",
      "\n",
      "NICATIVE SIGNALS SUCH AS LAUGHTER BASED ON THINGS \n",
      "\n",
      "outside the interaction, for instance, in the en- \n",
      "\n",
      "VIRONMENT OF THE INTERLOCUTERS. \n",
      "\n",
      "Ã¢â‚¬Â¢ user utterances can also be added in order to \n",
      "\n",
      "MAKE THE DIALOGUE CONTINUE. IN THE DIALOGUE IN \n",
      "\n",
      "figure 5 there is nothing in the dialogue xplain- \n",
      "\n",
      "ING WHY THE SYSTEM UTTERS S13. IN SUCH CASES \n",
      "\n",
      "we need to add a user utterance, e.g. which \n",
      "\n",
      "BUS IS THAT?. HOWEVER, IT MIGHT TURN OUT THAT \n",
      "\n",
      "there are cues, such as intonation, found when \n",
      "\n",
      "LISTENING TO THE TAPES. IF  SUCH DETAILED ANALYSES \n",
      "\n",
      "are carried out, we will, of course, not need to \n",
      "\n",
      "ADD UTTERANCES. FURTHERMORE, IT IS SOMETIMES \n",
      "\n",
      "the case that the telephone operator deliberate- \n",
      "\n",
      "LY SPLITS THE INFORMATION INTO CHUNKS THAT CAN \n",
      "\n",
      "be comprehended by the user, which then must \n",
      "\n",
      "BE CONSIDERED IN THE DISTILLATION. \n",
      "\n",
      "5 app ly ing  the  method \n",
      "\n",
      "TO ILLUSTRATE THE METHOD WE WILL IN THIS SECTION TRY TO \n",
      "\n",
      "characterise the results from our distillations. the \n",
      "\n",
      "ILLUSTRATION IS BASED ON 39 DISTILLED DIALOGUES FROM \n",
      "\n",
      "the previously mentioned corpus collected with a \n",
      "\n",
      "TELEPHONE OPERATOR HAVING INFORMATION ON LOCAL BUS \n",
      "\n",
      "time-tables and persons calling the information ser- \n",
      "\n",
      "VICE. \n",
      "\n",
      "the distillation took about three hours for all 39 \n",
      "\n",
      "DIALOGUES, I.E. IT IS REASONABLY FAST. THE DISTILLED \n",
      "\n",
      "dialogues are on the average 27% shorter. however, \n",
      "\n",
      "THIS VARIES BETWEEN THE DIALOGUES, AT MOST 73% WAS \n",
      "\n",
      "removed but there were also seven dialogues that \n",
      "\n",
      "WERE NOT CHANGED AT ALL. \n",
      "\n",
      "at the most 34 utterances where removed from \n",
      "\n",
      "ONE SINGLE DIALOGUE AND THAT WAS FROM A DIALOGUE \n",
      "\n",
      "with discussions on where to find a parking lot, i.e. \n",
      "\n",
      "DISCUSSIONS OUTSIDE THE CAPABILITIES OF THE APPLICA- \n",
      "\n",
      "tion. there was one more dialogue where more than \n",
      "\n",
      "30 UTTERANCES WERE REMOVED AND THAT DIALOGUE IS A \n",
      "\n",
      "typical example of dialogues where distillation actu- \n",
      "\n",
      "ALLY IS VERY USEFUL AND ALSO INDICATES WHAT IS NORMAL- \n",
      "\n",
      "ly removed from the dialogues. this particular dia- \n",
      "\n",
      "LOGUE BEGINS WITH THE USER ASKING FOR THE TELEPHONE \n",
      "\n",
      "number to 'the lost property office' for a specific bus \n",
      "\n",
      "OPERATOR. HOWEVER, THE OPERATOR STARTS A DISCUSSION \n",
      "\n",
      "on what bus the traveller traveled on before provid- \n",
      "\n",
      "ING THE REQUESTED TELEPHONE NUMBER. THE REASON FOR \n",
      "\n",
      "this discussion is probably that the operator knows \n",
      "\n",
      "THAT DIFFERENT BUS COMPANIES ARE UTILISED AND WOULD \n",
      "\n",
      "like to make sure that the user really understands \n",
      "\n",
      "HIS/HER REQUEST. THE INTERACTION THAT FOLLOWS CAN, \n",
      "\n",
      "thus, in that respect be relevant, but for our pur- \n",
      "\n",
      "POSE OF DEVELOPING SYSTEMS BASED ON AN OVERALL GOAL \n",
      "\n",
      "of providing information, not to understand human \n",
      "\n",
      "INTERACTION, OUR DIALOGUE SYSTEM WILL NOT ABLE TO HAN- \n",
      "\n",
      "dle such phenomenon (jsnsson, 1996). \n",
      "\n",
      "THE DIALOGUES CAN ROUGHLY BE DIVIDED INTO FIVE DIF- \n",
      "\n",
      "ferent categories based on the users task. the dis- \n",
      "\n",
      "CUSSION IN TWENTY FIVE DIALOGUES WERE ON BUS TIMES \n",
      "\n",
      "between various places, often one departure and one \n",
      "\n",
      "ARRIVAL BUT FIVE DIALOGUES INVOLVED MORE PLACES. IN \n",
      "\n",
      "five dialogues the discussion was one price and var- \n",
      "\n",
      "IOUS TYPES OF DISCOUNTS. FIVE USERS WANTED TO KNOW \n",
      "\n",
      "the telephone number to 'the lost property office', \n",
      "\n",
      "TWO DISCUSSED ONLY BUS STOPS AND TWO DISCUSSED HOW \n",
      "\n",
      "they could utilise their season ticket to travel out- \n",
      "\n",
      "SIDE THE TRAFFICKING AREA OF THE BUS COMPANY. IT IS \n",
      "\n",
      "interesting to note that there is no correspondence \n",
      "\n",
      "BETWEEN THE TASK BEING PERFORMED URING THE INTER- \n",
      "\n",
      "action and the amount of changes made to the dia-  \n",
      "\n",
      "LOGUE. THUS, IF WE CAN ASSUME THAT THE AMOUNT OF \n",
      "\n",
      "distillation indicates omething about a user's inter- \n",
      "\n",
      "ACTION STYLE, OTHER FACTORS THAN THE TASK ARE IMPOR- \n",
      "\n",
      "tant when characterising user behaviour. \n",
      "\n",
      "LOOKING AT WHAT IS ALTERED WE FIND THAT THE MOST \n",
      "\n",
      "important distilling principle is that the 'system' \n",
      "\n",
      "PROVIDES ALL RELEVANT INFORMATION AT ONCE, C.F. FIG- \n",
      "\n",
      "ures 1 and 2. this in turn removes utterances pro- \n",
      "\n",
      "VIDED BY BOTH 'SYSTEM' AND USER. \n",
      "\n",
      "most added utterances, both from the user and \n",
      "\n",
      "THE 'SYSTEM', PROVIDE EXPLICIT REQUESTS FOR INFORMA- \n",
      "\n",
      "tion that is later provided in the dialogue, e.g. ut- \n",
      "\n",
      "TERANCE $3 IN FIGURE 6. WE HAVE ADDED TEN UTTERANCES \n",
      "\n",
      "in all 39 dialogues, five 'system' utterances and five \n",
      "\n",
      "USER UTTERANCES. NOTE, HOWEVER, THAT WE UTILISED THE \n",
      "\n",
      "transcribed ialogues, without information on into- \n",
      "\n",
      "NATION. WE WOULD PROBABLY NOT HAVE NEEDED TO ADD \n",
      "\n",
      "this many utterances if we had utilised the tapes. \n",
      "\n",
      "OUR REASON FOR NOT USING INFORMATION ON INTONATION \n",
      "\n",
      "is that we do not assume that our system's peech \n",
      "\n",
      "RECOGNISER CAN RECOGNISE INTONATION. \n",
      "\n",
      "finally, as discussed above, we did not utilise the \n",
      "\n",
      "FULL POTENTIAL OF MULTI-MODALITY WHEN DISTILLING THE \n",
      "\n",
      "dialogues. for instance, some dialogues could be \n",
      "\n",
      "FURTHER DISTILLED IF WE HAD ASSUMED THAT THE SYSTEM \n",
      "\n",
      "had presented a time-table. one reason for this is \n",
      "\n",
      "THAT WE WANTED TO CAPTURE AS MANY INTERESTING AS- \n",
      "\n",
      "pects intact as possible. the advantage is, thus, that \n",
      "\n",
      "WE HAVE A BETTER CORPUS FOR UNDERSTANDING HUMAN- \n",
      "\n",
      "49 \n",
      "\n",
      "U2: YEES HI ANNA NILSSON IS MY NAME AND I WOULD LIKE TO TAKE THE BUS FROM RYD CENTER TO RESECENTRUM \n",
      "\n",
      "in linksping \n",
      "\n",
      "JAA HEJ ANNA NILSSON HETER JAG OCH JAG RILL ~KA BUSS ~R~N RYDS CENTRUM TILL RESECENTRUM \n",
      "\n",
      "i linksping. \n",
      "\n",
      "$3: MM WHEN DO YOU  WANT  TO  LEAVE? \n",
      "\n",
      "mm n~ir r i l l  du  Ã¢Â£ka? \n",
      "\n",
      "U4: 'N' I MUST BE AT RESECENTRUM BEFORE FOURTEEN AND THIRTY FIVE (.) 'CAUSE WE WILL GOING TO THE \n",
      "\n",
      "interstate buses \n",
      "\n",
      "JA SKA VA P~ RECECENTRUM INNAN FJORTON D TRETTIFEM (.) F5 VI SKA TILL \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l~ngfiirdsbussarna \n",
      "\n",
      "FIGURE 6: DISTILLED DIALOGUE FRAGMENT WITH ADDED UTTERANCE \n",
      "\n",
      "computer interaction and can from that corpus do \n",
      "\n",
      "A SECOND DISTILLATION WHERE WE FOCUS MORE ON MULTI- \n",
      "\n",
      "modal interaction. \n",
      "\n",
      "6 DISCUSS ION \n",
      "\n",
      "we have been presenting a method for distilling hu- \n",
      "\n",
      "MAN DIALOGUES TO MAKE THEM RESEMBLE HUMAN COM- \n",
      "\n",
      "puter interaction, in order to utilise such dialogues \n",
      "\n",
      "AS A KNOWLEDGE SOURCE WHEN DEVELOPING DIALOGUE SYS- \n",
      "\n",
      "tems. our own main purpose has been to use them \n",
      "\n",
      "FOR DEVELOPING MULTIMODAL SYSTEMS, HOWEVER, AS DIS- \n",
      "\n",
      "cussed above, we have in this paper rather assumed \n",
      "\n",
      "A SPEECH-ONLY SYSTEM. BUT WE BELIEVE THAT THE BASIC \n",
      "\n",
      "approach can be used also for multi-modal systems \n",
      "\n",
      "AND OTHER KINDS OF NATURAL LANGUAGE DIALOGUE SYS- \n",
      "\n",
      "tems. \n",
      "\n",
      "IT IS IMPORTANT O BE AWARE OF THE LIMITATIONS OF \n",
      "\n",
      "the method, and how 'realistic' the produced result \n",
      "\n",
      "WILL BE, COMPARED TO A DIALOGUE WITH THE FINAL SYS- \n",
      "\n",
      "tem. since we are changing the dialogue moves, by \n",
      "\n",
      "FOR INSTANCE PROVIDING ALL REQUIRED INFORMATION IN ONE \n",
      "\n",
      "move, or never asking to be reminded of what the us- \n",
      "\n",
      "ER HAS PREVIOUSLY REQUESTED, IT IS OBVIOUS THAT WHAT \n",
      "\n",
      "follows after the changed sequence would probably \n",
      "\n",
      "BE AFFECTED ONE WAY OR ANOTHER. A CONSEQUENCE OF \n",
      "\n",
      "this is that the resulting dialogue is less accurate as \n",
      "\n",
      "A MODEL OF THE ENTIRE DIALOGUE. IT IS THEREFORE NOT AN \n",
      "\n",
      "ideal candidate for trying out the systems over-all \n",
      "\n",
      "PERFORMANCE DURING SYSTEM DEVELOPMENT. BUT FOR \n",
      "\n",
      "the smaller sub-segments or sub-dialogues, we be- \n",
      "\n",
      "LIEVE THAT IT CREATES A GOOD APPROXIMATION OF WHAT \n",
      "\n",
      "will take place once the system is up and running. \n",
      "\n",
      "FURTHERMORE, WE BELIEVE DISTILLED DIALOGUES IN SOME \n",
      "\n",
      "respects to be more realistic than wizard of oz- \n",
      "\n",
      "DIALOGUES COLLECTED WITH A WIZARD ACTING AS A COM- \n",
      "\n",
      "puter. \n",
      "\n",
      "ANOTHER ISSUE, THAT HAS BEEN DISCUSSED PREVIOUSLY \n",
      "\n",
      "in the description of the method, is that the distilling \n",
      "\n",
      "IS MADE BASED ON A PARTICULAR VIEW OF WHAT A DIALOGUE \n",
      "\n",
      "with a computer will look like. while not necessari- \n",
      "\n",
      "LY BEING A DETAILED AND SPECIFIC MODEL, IT IS AT LEAST \n",
      "\n",
      "an instance of a class of computer dialogue models. \n",
      "\n",
      "ONE EXAMPLE OF THIS IS WHETHER THE SYSTEM IS MEANT \n",
      "\n",
      "to acquire information on the user's underlying mo- \n",
      "\n",
      "TIVATIONS OR GOALS OR NOT. IN THE EXAMPLES PRESENTED, \n",
      "\n",
      "we have not assumed such capabilities, but this as- \n",
      "\n",
      "SUMPTION IS NOT AN ABSOLUTE NECESSITY. WE BELIEVE, \n",
      "\n",
      "however, that the distilling process should be based \n",
      "\n",
      "ON ONE SUCH MODEL, NOT THE LEAST TO ENSURE A CON- \n",
      "\n",
      "sistent treatment of similar recurring phenomena t \n",
      "\n",
      "DIFFERENT PLACES IN THE CORPORA. \n",
      "\n",
      "the validity of the results based on analysing dis- \n",
      "\n",
      "TILLED DIALOGUES DEPENDS PART LY ON HOW THE DISTILLA- \n",
      "\n",
      "tion has been carried out. even when using natural \n",
      "\n",
      "DIALOGUES WE CAN HAVE SITUATIONS WHERE THE INTERAC- \n",
      "\n",
      "tion is somewhat mysterious, for instance, if some of \n",
      "\n",
      "THE DIALOGUE PARTICIPANTS BEHAVES IRRATIONAL SUCH AS \n",
      "\n",
      "not providing feedback or being too elliptical. how- \n",
      "\n",
      "EVER, IF CAREFUL CONSIDERATIONS HAVE BEEN MADE TO STAY \n",
      "\n",
      "as close to the original dialogues as possible, we be- \n",
      "\n",
      "LIEVE THAT DISTILLED DIALOGUES WILL REFLECT WHAT A HU- \n",
      "\n",
      "man would consider to be a natural interaction. \n",
      "\n",
      "ACKNOWLEDGMENTS  \n",
      "\n",
      "this work results from a number of projects on de- \n",
      "\n",
      "VELOPMENT OF NATURAL LANGUAGE INTERFACES UPPORTED \n",
      "\n",
      "by the swedish transport & communications re- \n",
      "\n",
      "SEARCH BOARD (KFB) AND THE JOINT RESEARCH PROGRAM \n",
      "\n",
      "for language technology (hsfr/nutek) .  we are \n",
      "\n",
      "INDEBTED TO THE PARTICIPANTS OF THE SWEDISH DIALOGUE \n",
      "\n",
      "systems project, especially to staffan larsson, lena \n",
      "\n",
      "SANTAMARTA, AND ANNIKA FLYCHT-ERIKSSON FOR INTER- \n",
      "\n",
      "esting discussions on this topic. \n",
      "\n",
      "RE FERENCES  \n",
      "\n",
      "lars ahrenberg, nils dahlb~ck, arne jsnsson, \n",
      "\n",
      "AND /~KE THUR~E. 1996. CUSTOMIZING INTERAC- \n",
      "\n",
      "tion for natural language interfaces. linkspin9 \n",
      "\n",
      "ELECTRONIC ARTICLES IN COMPUTER AND INFORMA- \n",
      "\n",
      "tion science, also in notes from workshop on \n",
      "\n",
      "PRAGMATICS IN DIALOGUE, THE XIV:TH SCANDI- \n",
      "\n",
      "navian conference of linguistics and the vi- \n",
      "\n",
      "II:TH CONFERENCE OF NORDIC AND GENERAL LINGUIS- \n",
      "\n",
      "50 \n",
      "\n",
      "TICS, GSTEBORG, SWEDEN, 1993, 1(1), OCTOBER, 1. \n",
      "\n",
      "http :/ / www.ep.liu.se / ea /cis /1996 / o01/. \n",
      "\n",
      "SUE ATKINS, JEREMY CLEAR, AND NICHOLAS OSTLER. \n",
      "\n",
      "1992. corpus design criteria. literary and lin- \n",
      "\n",
      "GUISTIC COMPUTING, 7(1):1-16. \n",
      "\n",
      "douglas biber. 1993. representativeness in cor- \n",
      "\n",
      "PUS DESIGN. LITERARY AND LINGUISTIC COMPUTING, \n",
      "\n",
      "8(4):244-257. \n",
      "\n",
      "JEAN CARLETTA. 1996. ASSESSING AGREEMENT ON CLASSI- \n",
      "\n",
      "fication tasks: the kappa statistic. computation- \n",
      "\n",
      "AL LINGUISTICS, 22(2):249-254. \n",
      "\n",
      "steve crowdy. 1993. spoken corpus design. literary \n",
      "\n",
      "AND LINGUISTIC COMPUTING, 8(4):259-265. \n",
      "\n",
      "nils dahlb/ick and arne jsnsson. 1999. knowledge \n",
      "\n",
      "SOURCES IN SPOKEN DIALOGUE SYSTEMS. IN PROCEED- \n",
      "\n",
      "ings of eurospeech'99, budapest, hungary. \n",
      "\n",
      "NILS DAHLB/ICK, ARNE JSNSSON, AND LARS AHRENBERG. \n",
      "\n",
      "1998. wizard of oz studies - why and how. \n",
      "\n",
      "IN MARK MAYBURY & WOLFGANG WAHLSTER, EDITOR, \n",
      "\n",
      "readings in intelligent user interfaces. morgan \n",
      "\n",
      "KAUFMANN. \n",
      "\n",
      "ntis dahlb/ick, annika flycht-eriksson, arne \n",
      "\n",
      "JSNSSON, AND PERNILLA QVARFORDT. 1999. AN AR- \n",
      "\n",
      "chitecture for multi-modal natural dialogue sys- \n",
      "\n",
      "TEMS. IN PROCEEDINGS OF ESCA TUTORIAL AND RE- \n",
      "\n",
      "search workshop (etrw) on interactive dialogue \n",
      "\n",
      "IN MULTI-MODAL SYSTEMS, GERMANY. \n",
      "\n",
      "nils dahlb/ick. 1991. representations ofdiscourse, \n",
      "\n",
      "COGNITIVE AND COMPUTATIONAL ASPECTS. PH.D. THE- \n",
      "\n",
      "sis, linksping university. \n",
      "\n",
      "MAXINE ESKENAZI, ALEXANDER RUDNICKI, KARIN GREGO- \n",
      "\n",
      "ry, paul constantinides, robert brennan, christi- \n",
      "\n",
      "NA BENNETT, AND JWAN ALLEN. 1999. DATA COLLEC- \n",
      "\n",
      "tion and processing in the carnegie mellon com- \n",
      "\n",
      "MUNICATOR. IN PROCEEDINGS OF EUROSPEECH'99, BU- \n",
      "\n",
      "dapest, hungary. \n",
      "\n",
      "ANNIKA FLYCHT-ERIKSSON AND ARNE JSNSSON. 1998. A \n",
      "\n",
      "spoken dialogue system utilizing spatial informa- \n",
      "\n",
      "TION. IN PROCEEDINGS OF ICSLP'98, SYDNEY, AUS- \n",
      "\n",
      "tralia. \n",
      "\n",
      "ANNIKA FLYCHT-ERIKSSON. 1999. A SURVEY OF KNOWL- \n",
      "\n",
      "edge sources in dialogue systems. in proceedings \n",
      "\n",
      "OF LJCAI-99 WORKSHOP ON KNOWLEDGE AND REASON- \n",
      "\n",
      "ing in practical dialogue systems, august, stock- \n",
      "\n",
      "HOLM. \n",
      "\n",
      "roger garside, geoffrey leech, and anthony \n",
      "\n",
      "MEENERY. 1997. CORPUS ANNOTATION. LONGMAN. \n",
      "\n",
      "arne jsnsson and nils dahlb/ick. 1988. talking to a \n",
      "\n",
      "COMPUTER IS NOT LIKE TALKING TO YOUR BEST FRIEND. IN \n",
      "\n",
      "proceedings of the first scandinavian conference \n",
      "\n",
      "ON ARTIFICIAL INTERUIGENCE, TVOMSÃ‚Â¢. \n",
      "\n",
      "arne jsnsson. 1996. natural language generation \n",
      "\n",
      "WITHOUT INTENTIONS. IN PROCEEDINGS OF ECAI'96 \n",
      "\n",
      "workshop gaps and bridges: new directions \n",
      "\n",
      "IN PLANNING AND NATURAL LANGUAGE GENERATION, \n",
      "\n",
      "pages 102-104. \n",
      "\n",
      "PERNILLA QVARFORDT AND ARNE JSNSSON. 1998. EFFECTS \n",
      "\n",
      "of using speech in timetable information systems \n",
      "\n",
      "FOR WWW. IN PROCEEDINGS OF ICSLP'98, SYDNEY, \n",
      "\n",
      "australia. \n",
      "\n",
      "PERNILLA QVARFORDT. 1998. USABILITY OF MULTIMODAL \n",
      "\n",
      "timetables: effects of different levels of do- \n",
      "\n",
      "MAIN KNOWLEDGE ON USABILITY. MASTER'S THESIS, \n",
      "\n",
      "linksping university. \n",
      "\n",
      "KAREN SPARCK JONES AND JULIA R. GALLIERS. 1996. \n",
      "\n",
      "evaluating natural language processing systems. \n",
      "\n",
      "SPRINGER VERLAG. \n",
      "\n",
      "marilyn a. walker, diane j. litman, candace a. \n",
      "\n",
      "KAMM, AND ALICIA ABELLA. 1998. PARADISE: A \n",
      "\n",
      "framework for evaluating spoken dialogue agents. \n",
      "\n",
      "IN MARK MAYBURY & WOLFGANG WAHLSTER, EDITOR, \n",
      "\n",
      "readings in intelligent user interfaces. morgan \n",
      "\n",
      "KAUFMANN. \n",
      "\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "alter_Upper(\"Text_File.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYediyB6ynU3"
   },
   "source": [
    "#                             GOOD LUCK!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "RollNumber01.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
