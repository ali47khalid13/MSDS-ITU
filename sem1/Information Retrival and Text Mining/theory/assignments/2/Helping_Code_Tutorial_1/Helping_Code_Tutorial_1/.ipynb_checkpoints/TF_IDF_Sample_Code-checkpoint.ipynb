{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bV8aJD9yo7CD"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xAi85czDo7CH"
   },
   "source": [
    "### TF-IDF Weightage Sample Code\n",
    "This is a sample code to give students an idea of how TF-IDF weightage model can be applied to calculate relevance score of documents.\n",
    "\n",
    "The example is taken from **lecture 3.2**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZVkz_YRo7CH"
   },
   "source": [
    "**P.S Do not get confused with the answers provided for TF-IDF in lecture 3.2, since the example shown had documents from d1-d5 but in actual the collection was large, hence M and k are actually unknown in that solved solution.** <br>\n",
    "**In this example, M = 5 as it is assumed that the collection has 5 docs only.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cnuaEhqo7CI"
   },
   "source": [
    "<h3 style = 'color:purple;'>Vector Space Model (TF-IDF Weightage Model)</h3>\n",
    "\n",
    "$$ f(q,d) = sim(q,d) =  \\sum_{i=1}^n x_iy_i $$ \n",
    "q = (x_1,.....,x_n) <br>\n",
    "d = (y_1,.....,y_n) <br>\n",
    "x_i = count of word W_i in query. <br>\n",
    "y_i = TF-IDF of word W_i in doc i.e $$ y_i = C(W_i,doc) * log_2 \\frac {M+1} {k} $$\n",
    "M = number of documents in the collection <br>\n",
    "k = document frequency for every word in corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PD0sZeVIo7CJ"
   },
   "outputs": [],
   "source": [
    "#lets say we have the following documents\n",
    "documents = {\n",
    "    \"d1\" : \"news about\",\n",
    "    \"d2\" : \"news about organic food campaign\",\n",
    "    \"d3\" : \"news of presidential campaign\",\n",
    "    \"d4\" : \"news of presidential campaign presidential candidate\",\n",
    "    \"d5\" : \"news of organic food campaign campaign campaign campaign\"\n",
    "} # a dictionary with doc# as key and doc content as value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tywh-LX4o7CP",
    "outputId": "8c9f4527-b37e-4908-fba8-8ee43e37fff0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d1': 'news about',\n",
       " 'd2': 'news about organic food campaign',\n",
       " 'd3': 'news of presidential campaign',\n",
       " 'd4': 'news of presidential campaign presidential candidate',\n",
       " 'd5': 'news of organic food campaign campaign campaign campaign'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualize the dictionary\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BC3nCQGAo7CS"
   },
   "outputs": [],
   "source": [
    "#create a corpus ccontaining the vocabulary of words in the documents\n",
    "corpus = [] # a list that will store words of the vocabulary\n",
    "for doc in documents.values(): #iterate through documents \n",
    "    for word in doc.split(): #go through each word in the current doc\n",
    "        if not word in corpus: \n",
    "            corpus.append(word) #add word in corpus if not already added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q6BWkOMAo7CU",
    "outputId": "fe359cb1-2097-4a2f-c6c3-67d9cf58b797"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['news',\n",
       " 'about',\n",
       " 'organic',\n",
       " 'food',\n",
       " 'campaign',\n",
       " 'of',\n",
       " 'presidential',\n",
       " 'candidate']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualize the corpus \n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-wKx5ximo7CX"
   },
   "outputs": [],
   "source": [
    "#lets create a dictionary that will store document frequency for each word in the corpus\n",
    "df_corpus = {} #document frequency for every word in corpus\n",
    "for word in corpus:\n",
    "    k = 0 #initial document frequency set to 0\n",
    "    for doc in documents.values(): #iterate through documents\n",
    "        if word in doc.split(): #check if word in doc\n",
    "            k+=1 \n",
    "    df_corpus[word] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8KUYj1iCo7CZ",
    "outputId": "251b22ec-6b96-4ed9-f9aa-6a30b2191a27"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'about': 2,\n",
       " 'campaign': 4,\n",
       " 'candidate': 1,\n",
       " 'food': 2,\n",
       " 'news': 5,\n",
       " 'of': 3,\n",
       " 'organic': 2,\n",
       " 'presidential': 2}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify the document frequency values\n",
    "df_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evrsElsio7Cc"
   },
   "outputs": [],
   "source": [
    "#since we have calculated k (document frequency) for all the words in the corpus, next step is to calculate idf\n",
    "M = len(documents) #number of documents in the collection\n",
    "idf_corpus = {} #inverse_document frequency for every word in corpus\n",
    "for word in corpus:\n",
    "    idf_corpus[word] = np.log2((M+1) / df_corpus[word]) #log_2 ((M+1)/k) i.e inverse document frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-zqu-Od0o7Cf",
    "outputId": "8865a3d2-b973-48a5-a3ab-33cee0a7844c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'about': 1.584962500721156,\n",
       " 'campaign': 0.5849625007211562,\n",
       " 'candidate': 2.584962500721156,\n",
       " 'food': 1.584962500721156,\n",
       " 'news': 0.2630344058337938,\n",
       " 'of': 1.0,\n",
       " 'organic': 1.584962500721156,\n",
       " 'presidential': 1.584962500721156}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualize idf values\n",
    "idf_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ksTOOZgeo7Ci"
   },
   "source": [
    "We have successfully calculated inverse_document_frequency for all the words in the corpus. Now, using the idf values, we need to calculate tf-idf for each word with respect to a particular document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MbTGhfJuo7Ci"
   },
   "outputs": [],
   "source": [
    "#calculating tf_idf\n",
    "tf_idf_docs = {} #will store tf_idf scores for document words\n",
    "for doc_id in documents.keys():\n",
    "    tf_idf_docs[doc_id] = {} #initialize empty dictionary for each doc_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wI1-7jRuo7Ck",
    "outputId": "d82acfc2-e144-4953-eac2-8d0940ccf451"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d1': {}, 'd2': {}, 'd3': {}, 'd4': {}, 'd5': {}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualize tf_idf initial state\n",
    "tf_idf_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tjIg5jajo7Cn"
   },
   "outputs": [],
   "source": [
    "#finalizing the tf_idf calculations\n",
    "for word in corpus:\n",
    "    for doc_id,doc in documents.items(): #iterate through key,value pairs where key = doc_id and value = doc content\n",
    "        tf_idf_docs[doc_id][word] = doc.split().count(word) * idf_corpus[word] #C(W_i,doc) * IDF(W_i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oz9d1OB4o7Cp",
    "outputId": "709e74d8-f7c8-477f-bec6-465f6cdc8493"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d1': {'about': 1.584962500721156,\n",
       "  'campaign': 0.0,\n",
       "  'candidate': 0.0,\n",
       "  'food': 0.0,\n",
       "  'news': 0.2630344058337938,\n",
       "  'of': 0.0,\n",
       "  'organic': 0.0,\n",
       "  'presidential': 0.0},\n",
       " 'd2': {'about': 1.584962500721156,\n",
       "  'campaign': 0.5849625007211562,\n",
       "  'candidate': 0.0,\n",
       "  'food': 1.584962500721156,\n",
       "  'news': 0.2630344058337938,\n",
       "  'of': 0.0,\n",
       "  'organic': 1.584962500721156,\n",
       "  'presidential': 0.0},\n",
       " 'd3': {'about': 0.0,\n",
       "  'campaign': 0.5849625007211562,\n",
       "  'candidate': 0.0,\n",
       "  'food': 0.0,\n",
       "  'news': 0.2630344058337938,\n",
       "  'of': 1.0,\n",
       "  'organic': 0.0,\n",
       "  'presidential': 1.584962500721156},\n",
       " 'd4': {'about': 0.0,\n",
       "  'campaign': 0.5849625007211562,\n",
       "  'candidate': 2.584962500721156,\n",
       "  'food': 0.0,\n",
       "  'news': 0.2630344058337938,\n",
       "  'of': 1.0,\n",
       "  'organic': 0.0,\n",
       "  'presidential': 3.169925001442312},\n",
       " 'd5': {'about': 0.0,\n",
       "  'campaign': 2.3398500028846247,\n",
       "  'candidate': 0.0,\n",
       "  'food': 1.584962500721156,\n",
       "  'news': 0.2630344058337938,\n",
       "  'of': 1.0,\n",
       "  'organic': 1.584962500721156,\n",
       "  'presidential': 0.0}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualize final tf_idf scores for each doc\n",
    "tf_idf_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0qeVZh1Do7Cs"
   },
   "source": [
    "### Querying the documents for relevance scores\n",
    "Since we have calculated the term frequencies for all the documents in our collection, let us calcualte the relevance score of each document for a given query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "YQbLWueKo7Cs",
    "outputId": "fc1edb76-fb46-42da-9a68-ce63325ee141"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'news about presidential campaign'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"news about presidential campaign\" #the query\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xQOo4-Zso7Cv"
   },
   "outputs": [],
   "source": [
    "query_vocab = [] # will store the unique words that occur in the query\n",
    "for word in query.split():\n",
    "    if word not in query_vocab:\n",
    "        query_vocab.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W3NqsUaLo7Cx",
    "outputId": "30615ffd-7be6-4294-b4a7-024f7fe804b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['news', 'about', 'presidential', 'campaign']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_vocab # the unique words in the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j-t1ncfxo7Cz"
   },
   "outputs": [],
   "source": [
    "query_wc = {} # a dictionary to store count of a word in the query (i.e x_i according to lecture slides terminology)\n",
    "for word in query_vocab:\n",
    "    query_wc[word] = query.split().count(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S5V4XU4Yo7C1",
    "outputId": "ff48f7d7-7d84-4edf-8b1c-6085fbfa8bc5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'about': 1, 'campaign': 1, 'news': 1, 'presidential': 1}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_wc # the count of each word that occurs in the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oxnp-cUXo7C3"
   },
   "outputs": [],
   "source": [
    "relevance_scores = {} # a dictionary that will store the relevance score for each doc\n",
    "# doc_id will be the key and relevance score the value for this dictionary\n",
    "for doc_id in documents.keys():\n",
    "    score = 0 #initialze the score for the doc to 0 at the start\n",
    "    for word in query_vocab:\n",
    "        score += query_wc[word] * tf_idf_docs[doc_id][word] # count of word in query * term_freq of the word\n",
    "    relevance_scores[doc_id] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CF1xhuzTo7C5",
    "outputId": "32a06822-d958-46c3-87a9-efe174417961"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Relevancy Scores\n",
      " {'d1': 1.84799690655495, 'd2': 2.432959407276106, 'd3': 2.432959407276106, 'd4': 4.017921907997263, 'd5': 2.6028844087184186}\n"
     ]
    }
   ],
   "source": [
    "# lets print the relevance scores for the query\n",
    "print(\"Document Relevancy Scores\\n\",relevance_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bi5P0Zyno7C8"
   },
   "source": [
    "### What next ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYijS2Smo7C8"
   },
   "source": [
    "<img src = \"https://media.makeameme.org/created/brace-yourself-assignment-5bb85a.jpg\" alt = \"Assignment is ccoming\" />"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TF_IDF_Sample_Code.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
