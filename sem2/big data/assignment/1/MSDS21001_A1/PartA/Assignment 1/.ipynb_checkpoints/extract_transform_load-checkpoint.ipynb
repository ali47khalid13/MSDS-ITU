{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicate key value violates unique constraint \"youtubers_dim_pkey\"\n",
      "DETAIL:  Key (youtuber_id)=(ARNTLGG11E2835DDB9) already exists.\n",
      "\n",
      "duplicate key value violates unique constraint \"youtubers_dim_pkey\"\n",
      "DETAIL:  Key (youtuber_id)=(ARD7TVE1187B99BFB1) already exists.\n",
      "\n",
      "duplicate key value violates unique constraint \"users_dim_pkey\"\n",
      "DETAIL:  Key (user_id)=(101) already exists.\n",
      "\n",
      "duplicate key value violates unique constraint \"users_dim_pkey\"\n",
      "DETAIL:  Key (user_id)=(101) already exists.\n",
      "\n",
      "duplicate key value violates unique constraint \"users_dim_pkey\"\n",
      "DETAIL:  Key (user_id)=(10) already exists.\n",
      "\n",
      "duplicate key value violates unique constraint \"users_dim_pkey\"\n",
      "DETAIL:  Key (user_id)=(69) already exists.\n",
      "\n",
      "duplicate key value violates unique constraint \"users_dim_pkey\"\n",
      "DETAIL:  Key (user_id)=(26) already exists.\n",
      "\n",
      "insert or update on table \"videoplay_fact\" violates foreign key constraint \"fk_user\"\n",
      "DETAIL:  Key (user_id)=(30) is not present in table \"users_dim\".\n",
      "\n",
      "duplicate key value violates unique constraint \"users_dim_pkey\"\n",
      "DETAIL:  Key (user_id)=(8) already exists.\n",
      "\n",
      "duplicate key value violates unique constraint \"users_dim_pkey\"\n",
      "DETAIL:  Key (user_id)=(43) already exists.\n",
      "\n",
      "duplicate key value violates unique constraint \"users_dim_pkey\"\n",
      "DETAIL:  Key (user_id)=(6) already exists.\n",
      "\n",
      "duplicate key value violates unique constraint \"users_dim_pkey\"\n",
      "DETAIL:  Key (user_id)=(26) already exists.\n",
      "\n",
      "duplicate key value violates unique constraint \"users_dim_pkey\"\n",
      "DETAIL:  Key (user_id)=(69) already exists.\n",
      "\n",
      "insert or update on table \"videoplay_fact\" violates foreign key constraint \"fk_user\"\n",
      "DETAIL:  Key (user_id)=(80) is not present in table \"users_dim\".\n",
      "\n",
      "duplicate key value violates unique constraint \"users_dim_pkey\"\n",
      "DETAIL:  Key (user_id)=(10) already exists.\n",
      "\n",
      "duplicate key value violates unique constraint \"users_dim_pkey\"\n",
      "DETAIL:  Key (user_id)=(51) already exists.\n",
      "\n",
      "duplicate key value violates unique constraint \"users_dim_pkey\"\n",
      "DETAIL:  Key (user_id)=(10) already exists.\n",
      "\n",
      "insert or update on table \"videoplay_fact\" violates foreign key constraint \"fk_user\"\n",
      "DETAIL:  Key (user_id)=(34) is not present in table \"users_dim\".\n",
      "\n",
      "duplicate key value violates unique constraint \"users_dim_pkey\"\n",
      "DETAIL:  Key (user_id)=(26) already exists.\n",
      "\n",
      "duplicate key value violates unique constraint \"users_dim_pkey\"\n",
      "DETAIL:  Key (user_id)=(44) already exists.\n",
      "\n",
      "duplicate key value violates unique constraint \"users_dim_pkey\"\n",
      "DETAIL:  Key (user_id)=(49) already exists.\n",
      "\n",
      "insert or update on table \"videoplay_fact\" violates foreign key constraint \"fk_user\"\n",
      "DETAIL:  Key (user_id)=(73) is not present in table \"users_dim\".\n",
      "\n",
      "duplicate key value violates unique constraint \"users_dim_pkey\"\n",
      "DETAIL:  Key (user_id)=(61) already exists.\n",
      "\n",
      "duplicate key value violates unique constraint \"users_dim_pkey\"\n",
      "DETAIL:  Key (user_id)=(66) already exists.\n",
      "\n",
      "duplicate key value violates unique constraint \"users_dim_pkey\"\n",
      "DETAIL:  Key (user_id)=(25) already exists.\n",
      "\n",
      "duplicate key value violates unique constraint \"users_dim_pkey\"\n",
      "DETAIL:  Key (user_id)=(80) already exists.\n",
      "\n",
      "insert or update on table \"videoplay_fact\" violates foreign key constraint \"fk_user\"\n",
      "DETAIL:  Key (user_id)=(15) is not present in table \"users_dim\".\n",
      "\n",
      "duplicate key value violates unique constraint \"users_dim_pkey\"\n",
      "DETAIL:  Key (user_id)=(26) already exists.\n",
      "\n",
      "duplicate key value violates unique constraint \"users_dim_pkey\"\n",
      "DETAIL:  Key (user_id)=(66) already exists.\n",
      "\n",
      "duplicate key value violates unique constraint \"users_dim_pkey\"\n",
      "DETAIL:  Key (user_id)=(26) already exists.\n",
      "\n",
      "insert or update on table \"videoplay_fact\" violates foreign key constraint \"fk_user\"\n",
      "DETAIL:  Key (user_id)=(88) is not present in table \"users_dim\".\n",
      "\n",
      "duplicate key value violates unique constraint \"users_dim_pkey\"\n",
      "DETAIL:  Key (user_id)=(9) already exists.\n",
      "\n",
      "duplicate key value violates unique constraint \"users_dim_pkey\"\n",
      "DETAIL:  Key (user_id)=(37) already exists.\n",
      "\n",
      "duplicate key value violates unique constraint \"users_dim_pkey\"\n",
      "DETAIL:  Key (user_id)=(8) already exists.\n",
      "\n",
      "duplicate key value violates unique constraint \"users_dim_pkey\"\n",
      "DETAIL:  Key (user_id)=(80) already exists.\n",
      "\n",
      "duplicate key value violates unique constraint \"users_dim_pkey\"\n",
      "DETAIL:  Key (user_id)=(24) already exists.\n",
      "\n",
      "duplicate key value violates unique constraint \"users_dim_pkey\"\n",
      "DETAIL:  Key (user_id)=(73) already exists.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Create_Table_queries import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def process_youtubedata_file(cur, conn, filepath): \n",
    "    \"\"\"\n",
    "        This function reads one JSON file and read information of videos and youtuber data and saves into video_data and youtuber_data\n",
    "        Arguments:\n",
    "        cur: Database Cursor\n",
    "        filepath: location of JSON files\n",
    "        Return: None\n",
    "    \"\"\"\n",
    "    # open JSON file\n",
    "    df = pd.read_json(filepath)\n",
    "    df.fillna('')\n",
    "    \n",
    "    # ---------insert youtuber record----------\n",
    "    # write your code here that reads youtuber data from JSON file and insert it into Youtubers_dim table \n",
    "    # write your code here\n",
    "    \n",
    "    youtuber_data = df[['youtuber_id', 'youtuber_name', 'youtuber_location', 'youtuber_latitude', 'youtuber_longitude']]\n",
    "    youtuber_data = youtuber_data.drop_duplicates()\n",
    "    youtuber_data = youtuber_data.values.tolist()\n",
    "\n",
    "    try: \n",
    "        cur.executemany(Youtubers_table_insert, youtuber_data)\n",
    "    except psycopg2.Error as e:\n",
    "        print(e)\n",
    "    \n",
    "\n",
    "    \n",
    "    # ---------insert video record--------------\n",
    "    # write your code here that reads youtube videos data from JSON file and insert it into Videos_dim table \n",
    "    # write your code here\n",
    "    \n",
    "    video_data = df[['video_id', 'title', 'youtuber_id', 'year', 'duration']]\n",
    "    video_data = video_data.drop_duplicates(keep='first')\n",
    "    video_data = video_data.values.tolist()\n",
    "    \n",
    "    try: \n",
    "        cur.executemany(Videos_table_insert, video_data)\n",
    "    except psycopg2.Error as e:\n",
    "        print(e)\n",
    "\n",
    "def process_log_file(cur, conn, filepath):\n",
    "    \"\"\"\n",
    "        This function reads Log files and reads information of time, user and videoplay data and saves into time, user, videoplay\n",
    "        Arguments:\n",
    "        cur: Database Cursor\n",
    "        filepath: location of Log files\n",
    "        Return: None\n",
    "    \"\"\"\n",
    "\n",
    "    # open log file\n",
    "    df = pd.read_json(filepath, lines=True)\n",
    "\n",
    "    # filter by NextVideo action\n",
    "    df = df[(df['page'] == 'NextVideo')]\n",
    "\n",
    "    # convert timestamp column to datetime with 'pd.to_datetime(df[\"ts\"], unit=\"ms\")' \n",
    "    df['ts'] = pd.to_datetime(df[\"ts\"], unit=\"ms\")\n",
    "    \n",
    "    # insert time data records to Time_dim table\n",
    "    # write your code here\n",
    "    df['year'] =  pd.to_datetime(df['ts']).dt.year\n",
    "    df['month'] =  pd.to_datetime(df['ts']).dt.month\n",
    "    df['day'] =  pd.to_datetime(df['ts']).dt.day\n",
    "    df['hour'] =  pd.to_datetime(df['ts']).dt.hour\n",
    "    df['week'] =  pd.to_datetime(df['ts']).dt.week\n",
    "    df['weekday'] =  pd.to_datetime(df['ts']).dt.weekday\n",
    "    df['start_time'] =  pd.to_datetime(df['ts'])\n",
    "    \n",
    "    time_data = df[['start_time', 'hour', 'day', 'week', 'month', 'year', 'weekday']]\n",
    "    time_data = time_data.drop_duplicates(keep='first')\n",
    "    time_data = time_data.values\n",
    "    try: \n",
    "        cur.executemany(Time_table_insert, time_data)\n",
    "    except psycopg2.Error as e:\n",
    "        print(e)\n",
    "\n",
    "    \n",
    "    # load user table\n",
    "    # insert user records into Users_dim table\n",
    "    # write your code here\n",
    "    user_data = df[['userId', 'firstName', 'lastName', 'gender', 'level']]\n",
    "    user_data = user_data.drop_duplicates(keep='first')\n",
    "    user_data = user_data.values\n",
    "    try: \n",
    "        cur.executemany(Users_table_insert, user_data)\n",
    "    except psycopg2.Error as e:\n",
    "        print(e)\n",
    "\n",
    "    \n",
    "    # insert Videoplay records in Videoplay_fact table\n",
    "    # write your code here\n",
    "    \n",
    "    # reading videos data\n",
    "    query = 'SELECT * from videos_dim;'\n",
    "    videos = pd.read_sql_query(query,conn)\n",
    "    \n",
    "    # reading youtuber data\n",
    "    query = 'SELECT * from youtubers_dim;'\n",
    "    youtubers = pd.read_sql_query(query,conn)\n",
    "    \n",
    "    # merging tables to get information of video_id and youtuber_id\n",
    "    df1 = pd.merge(df, videos, how='inner', left_on = 'video', right_on = 'title')\n",
    "    #df2 = pd.merge(df1, videos, how='inner', left_on = 'youtuber_id', right_on = 'youtuber_id')\n",
    "    \n",
    "    videoplay_data = df1[['start_time', 'userId', 'level','video_id', 'youtuber_id', 'sessionId','location_x','userAgent']]\n",
    "    videoplay_data = videoplay_data.drop_duplicates(keep='first')\n",
    "    videoplay_data = videoplay_data.values\n",
    "    try: \n",
    "        cur.executemany(Videoplay_table_insert, videoplay_data)\n",
    "    except psycopg2.Error as e:\n",
    "        print(e)\n",
    "    \n",
    "def getListOfFiles(dirName):\n",
    "    # create a list of file and sub directories \n",
    "    # names in the given directory \n",
    "    listOfFile = os.listdir(dirName)\n",
    "    allFiles = list()\n",
    "    # Iterate over all the entries\n",
    "    for entry in listOfFile:\n",
    "        # Create full path\n",
    "        fullPath = os.path.join(dirName, entry)\n",
    "        # If entry is a directory then get the list of files in this directory \n",
    "        if os.path.isdir(fullPath):\n",
    "            allFiles = allFiles + getListOfFiles(fullPath)\n",
    "        else:\n",
    "            allFiles.append(fullPath)\n",
    "                \n",
    "    return allFiles \n",
    "\n",
    "def process_data(cur, conn, filepath, func):\n",
    "    \"\"\"\n",
    "        This function get all JSON files in given directory by exploring all sub directories, and process all files that were found using the given function.\n",
    "        Example: if I give it the path to youtube_data directory which resides in data folder of this assignment,\n",
    "        and func given is process_youtubedata_file it should get all JSON files in this directories and process each file using process_youtubedata_file function. \n",
    "        Arguments:\n",
    "        cur: Database Cursor\n",
    "        conn: Database\n",
    "        filepath: location of JSON files\n",
    "        func: function to process all files in the directory\n",
    "        Return: None\n",
    "    \"\"\"\n",
    "    file_list = getListOfFiles(filepath)\n",
    "    for file in file_list:\n",
    "        func(cur,conn,file)\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    conn = psycopg2.connect(\"host=127.0.0.1 dbname=youtubedb user=postgres password=ali123ali\")\n",
    "    cur = conn.cursor()\n",
    "    conn.set_session(autocommit=True)\n",
    "\n",
    "    process_data(cur, conn, filepath='data/youtube_data', func=process_youtubedata_file)\n",
    "    process_data(cur, conn, filepath='data/log_data', func=process_log_file)\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
